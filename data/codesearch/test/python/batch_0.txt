1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _set_attrs_to_values ( self , response = { } ) : if isinstance ( response , dict ) : for key in response . keys ( ) : if not hasattr ( self , key ) or not callable ( getattr ( self , key ) ) : setattr ( self , key , response [ key ] )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SmokinCaterpillar/pypet/blob/97ad3e80d46dbdea02deeb98ea41f05a19565826/pypet/trajectory.py#L3074-L3104<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def f_start_run ( self , run_name_or_idx = None , turn_into_run = True ) : if self . _run_started : return self if run_name_or_idx is None : if self . v_idx == - 1 : raise ValueError ( 'Cannot start run if trajectory is not set to a particular run' ) else : self . f_set_crun ( run_name_or_idx ) self . _run_started = True if turn_into_run : self . _make_single_run ( ) self . _set_start ( ) return self

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Azure/azure-sdk-for-python/blob/d7306fde32f60a293a7567678692bdad31e4b667/azure-servicemanagement-legacy/azure/servicemanagement/schedulermanagementservice.py#L204-L219<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_job_collection ( self , cloud_service_id , job_collection_id ) : _validate_not_none ( 'cloud_service_id' , cloud_service_id ) _validate_not_none ( 'job_collection_id' , job_collection_id ) path = self . _get_job_collection_path ( cloud_service_id , job_collection_id ) return self . _perform_get ( path , Resource )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_function_hook.py#L161-L172<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def delete_function ( self , name ) : response = self . get_conn ( ) . projects ( ) . locations ( ) . functions ( ) . delete ( name = name ) . execute ( num_retries = self . num_retries ) operation_name = response [ "name" ] self . _wait_for_operation_to_complete ( operation_name = operation_name )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/avelino/bottle-auth/blob/db07e526864aeac05ee68444b47e5db29540ce18/bottle_auth/core/auth.py#L202-L214<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def async_callback ( self , callback , * args , * * kwargs ) : if callback is None : return None if args or kwargs : callback = functools . partial ( callback , * args , * * kwargs ) #FIXME what about the exception wrapper? return callback

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/automl/autoh2o.py#L281-L412<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def train ( self , x = None , y = None , training_frame = None , fold_column = None , weights_column = None , validation_frame = None , leaderboard_frame = None , blending_frame = None ) : ncols = training_frame . ncols names = training_frame . names #Set project name if None if self . project_name is None : self . project_name = "automl_" + training_frame . frame_id self . build_control [ "project_name" ] = self . project_name # Minimal required arguments are training_frame and y (response) if y is None : raise ValueError ( 'The response column (y) is not set; please set it to the name of the column that you are trying to predict in your data.' ) else : assert_is_type ( y , int , str ) if is_type ( y , int ) : if not ( - ncols <= y < ncols ) : raise H2OValueError ( "Column %d does not exist in the training frame" % y ) y = names [ y ] else : if y not in names : raise H2OValueError ( "Column %s does not exist in the training frame" % y ) input_spec = { 'response_column' : y , } if training_frame is None : raise ValueError ( 'The training frame is not set!' ) else : assert_is_type ( training_frame , H2OFrame ) input_spec [ 'training_frame' ] = training_frame . frame_id if fold_column is not None : assert_is_type ( fold_column , int , str ) input_spec [ 'fold_column' ] = fold_column if weights_column is not None : assert_is_type ( weights_column , int , str ) input_spec [ 'weights_column' ] = weights_column if validation_frame is not None : assert_is_type ( validation_frame , H2OFrame ) input_spec [ 'validation_frame' ] = validation_frame . frame_id if leaderboard_frame is not None : assert_is_type ( leaderboard_frame , H2OFrame ) input_spec [ 'leaderboard_frame' ] = leaderboard_frame . frame_id if blending_frame is not None : assert_is_type ( blending_frame , H2OFrame ) input_spec [ 'blending_frame' ] = blending_frame . frame_id if self . sort_metric is not None : assert_is_type ( self . sort_metric , str ) sort_metric = self . sort_metric . lower ( ) # Changed the API to use "deviance" to be consistent with stopping_metric values # TO DO: let's change the backend to use "deviance" since we use the term "deviance" # After that we can take this `if` statement out if sort_metric == "deviance" : sort_metric = "mean_residual_deviance" input_spec [ 'sort_metric' ] = sort_metric if x is not None : assert_is_type ( x , list ) xset = set ( ) if is_type ( x , int , str ) : x = [ x ] for xi in x : if is_type ( xi , int ) : if not ( - ncols <= xi < ncols ) : raise H2OValueError ( "Column %d does not exist in the training frame" % xi ) xset . add ( names [ xi ] ) else : if xi not in names : raise H2OValueError ( "Column %s not in the training frame" % xi ) xset . add ( xi ) x = list ( xset ) ignored_columns = set ( names ) - { y } - set ( x ) if fold_column is not None and fold_column in ignored_columns : ignored_columns . remove ( fold_column ) if weights_column is not None and weights_column in ignored_columns : ignored_columns . remove ( weights_column ) if ignored_columns is not None : input_spec [ 'ignored_columns' ] = list ( ignored_columns ) automl_build_params = dict ( input_spec = input_spec ) # NOTE: if the user hasn't specified some block of parameters don't send them! # This lets the back end use the defaults. automl_build_params [ 'build_control' ] = self . build_control automl_build_params [ 'build_models' ] = self . build_models resp = h2o . api ( 'POST /99/AutoMLBuilder' , json = automl_build_params ) if 'job' not in resp : print ( "Exception from the back end: " ) print ( resp ) return self . _job = H2OJob ( resp [ 'job' ] , "AutoML" ) self . _job . poll ( ) self . _fetch ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/wheel/install.py#L368-L410<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def verify ( self , zipfile = None ) : sig = None if zipfile is None : zipfile = self . zipfile zipfile . strict = True record_name = '/' . join ( ( self . distinfo_name , 'RECORD' ) ) sig_name = '/' . join ( ( self . distinfo_name , 'RECORD.jws' ) ) # tolerate s/mime signatures: smime_sig_name = '/' . join ( ( self . distinfo_name , 'RECORD.p7s' ) ) zipfile . set_expected_hash ( record_name , None ) zipfile . set_expected_hash ( sig_name , None ) zipfile . set_expected_hash ( smime_sig_name , None ) record = zipfile . read ( record_name ) record_digest = urlsafe_b64encode ( hashlib . sha256 ( record ) . digest ( ) ) try : sig = from_json ( native ( zipfile . read ( sig_name ) ) ) except KeyError : # no signature pass if sig : headers , payload = signatures . verify ( sig ) if payload [ 'hash' ] != "sha256=" + native ( record_digest ) : msg = "RECORD.sig claimed RECORD hash {0} != computed hash {1}." raise BadWheelFile ( msg . format ( payload [ 'hash' ] , native ( record_digest ) ) ) reader = csv . reader ( ( native ( r ) for r in record . splitlines ( ) ) ) for row in reader : filename = row [ 0 ] hash = row [ 1 ] if not hash : if filename not in ( record_name , sig_name ) : sys . stderr . write ( "%s has no hash!\n" % filename ) continue algo , data = row [ 1 ] . split ( '=' , 1 ) assert algo == "sha256" , "Unsupported hash algorithm" zipfile . set_expected_hash ( filename , urlsafe_b64decode ( binary ( data ) ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/adapter/mongo/variant.py#L387-L408<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def other_causatives ( self , case_obj , variant_obj ) : # variant id without "*_[variant_type]" variant_id = variant_obj [ 'display_name' ] . rsplit ( '_' , 1 ) [ 0 ] institute_causatives = self . get_causatives ( variant_obj [ 'institute' ] ) for causative_id in institute_causatives : other_variant = self . variant ( causative_id ) if not other_variant : continue not_same_case = other_variant [ 'case_id' ] != case_obj [ '_id' ] same_variant = other_variant [ 'display_name' ] . startswith ( variant_id ) if not_same_case and same_variant : yield other_variant

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/bloomreach/s4cmd/blob/bb51075bf43703e7cd95aa39288cf7732ec13a6d/s4cmd.py#L592-L603<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def join ( self ) : self . tasks . join ( ) # Force each thread to break loop. for worker in self . workers : self . tasks . put ( None ) # Wait for all thread to terminate. for worker in self . workers : worker . join ( ) worker . s3 = None

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/OpenKMIP/PyKMIP/blob/b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e/kmip/services/server/engine.py#L189-L310<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def process_request ( self , request , credential = None ) : self . _client_identity = [ None , None ] header = request . request_header # Process the protocol version self . _set_protocol_version ( header . protocol_version ) # Process the maximum response size max_response_size = None if header . maximum_response_size : max_response_size = header . maximum_response_size . value # Process the time stamp now = int ( time . time ( ) ) if header . time_stamp : then = header . time_stamp . value if ( now >= then ) and ( ( now - then ) < 60 ) : self . _logger . info ( "Received request at time: {0}" . format ( time . strftime ( "%Y-%m-%d %H:%M:%S" , time . gmtime ( then ) ) ) ) else : if now < then : self . _logger . warning ( "Received request with future timestamp. Received " "timestamp: {0}, Current timestamp: {1}" . format ( then , now ) ) raise exceptions . InvalidMessage ( "Future request rejected by server." ) else : self . _logger . warning ( "Received request with old timestamp. Possible " "replay attack. Received timestamp: {0}, Current " "timestamp: {1}" . format ( then , now ) ) raise exceptions . InvalidMessage ( "Stale request rejected by server." ) else : self . _logger . info ( "Received request at time: {0}" . format ( time . strftime ( "%Y-%m-%d %H:%M:%S" , time . gmtime ( now ) ) ) ) # Process the asynchronous indicator self . is_asynchronous = False if header . asynchronous_indicator is not None : self . is_asynchronous = header . asynchronous_indicator . value if self . is_asynchronous : raise exceptions . InvalidMessage ( "Asynchronous operations are not supported." ) # Process the authentication credentials if header . authentication : if header . authentication . credentials : auth_credentials = header . authentication . credentials [ 0 ] else : auth_credentials = None else : auth_credentials = None self . _verify_credential ( auth_credentials , credential ) # Process the batch error continuation option batch_error_option = enums . BatchErrorContinuationOption . STOP if header . batch_error_cont_option is not None : batch_error_option = header . batch_error_cont_option . value if batch_error_option == enums . BatchErrorContinuationOption . UNDO : raise exceptions . InvalidMessage ( "Undo option for batch handling is not supported." ) # Process the batch order option batch_order_option = False if header . batch_order_option : batch_order_option = header . batch_order_option . value response_batch = self . _process_batch ( request . batch_items , batch_error_option , batch_order_option ) response = self . _build_response ( header . protocol_version , response_batch ) return response , max_response_size , header . protocol_version

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ekmmetering/ekmmeters/blob/b3748bdf30263bfa46ea40157bdf8df2522e1904/ekmmeters.py#L2494-L2544<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def setSeasonSchedules ( self , cmd_dict = None , password = "00000000" ) : result = False self . setContext ( "setSeasonSchedules" ) if not cmd_dict : cmd_dict = self . m_seasons_sched_params try : if not self . request ( False ) : self . writeCmdMsg ( "Bad read CRC on setting" ) else : if not self . serialCmdPwdAuth ( password ) : self . writeCmdMsg ( "Password failure" ) else : req_table = "" req_table += binascii . hexlify ( str ( cmd_dict [ "Season_1_Start_Month" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_1_Start_Day" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_1_Schedule" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_2_Start_Month" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_2_Start_Day" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_2_Schedule" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_3_Start_Month" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_3_Start_Day" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_3_Schedule" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_4_Start_Month" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_4_Start_Day" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( cmd_dict [ "Season_4_Schedule" ] ) . zfill ( 2 ) ) req_table += binascii . hexlify ( str ( 0 ) . zfill ( 24 ) ) req_str = "015731023030383028" + req_table + "2903" req_str += self . calc_crc16 ( req_str [ 2 : ] . decode ( "hex" ) ) self . m_serial_port . write ( req_str . decode ( "hex" ) ) if self . m_serial_port . getResponse ( self . getContext ( ) ) . encode ( "hex" ) == "06" : self . writeCmdMsg ( "Success(setSeasonSchedules): 06 returned." ) result = True self . serialPostEnd ( ) except : ekm_log ( traceback . format_exc ( sys . exc_info ( ) ) ) self . setContext ( "" ) return result

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/urinieto/msaf/blob/9dbb57d77a1310465a65cc40f1641d083ca74385/msaf/features.py#L336-L347<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def compute_features ( self ) : return librosa . feature . tempogram ( self . _audio , sr = self . sr , hop_length = self . hop_length , win_length = self . win_length ) . T

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/eyeseast/python-frontmatter/blob/c318e583c48599eb597e0ad59c5d972258c3febc/frontmatter/__init__.py#L133-L159<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def dump ( post , fd , encoding = 'utf-8' , handler = None , * * kwargs ) : content = dumps ( post , handler , * * kwargs ) if hasattr ( fd , 'write' ) : fd . write ( content . encode ( encoding ) ) else : with codecs . open ( fd , 'w' , encoding ) as f : f . write ( content )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/boundary/pulse-api-cli/blob/b01ca65b442eed19faac309c9d62bbc3cb2c098f/boundary/hostgroup_search.py#L31-L37<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_arguments ( self ) : ApiCli . get_arguments ( self ) if self . args . hostGroupName is not None : self . url_parameters = { "name" : self . args . hostGroupName }

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mohan3d/PyOpenload/blob/7f9353915ca5546926ef07be9395c6de60e761b1/openload/openload.py#L202-L225<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def upload_link ( self , folder_id = None , sha1 = None , httponly = False ) : kwargs = { 'folder' : folder_id , 'sha1' : sha1 , 'httponly' : httponly } params = { key : value for key , value in kwargs . items ( ) if value } return self . _get ( 'file/ul' , params = params )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/openmicroscopy/yaclifw/blob/a01179fefb2c2c4260c75e6d1dc6e19de9979d64/yaclifw/main.py#L37-L59<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def entry_point ( items = tuple ( ) ) : try : if not items : from . example import ExampleCommand from . version import Version items = [ ( ExampleCommand . NAME , ExampleCommand ) , ( Version . NAME , Version ) ] main ( "yaclifw" , items = items ) except Stop as stop : print ( stop ) sys . exit ( stop . rc ) except SystemExit : raise except KeyboardInterrupt : print ( "Cancelled" ) sys . exit ( 1 ) except Exception : traceback . print_exc ( ) sys . exit ( 1 )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/server/blueprints/variants/controllers.py#L788-L807<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def cosmic_link ( variant_obj ) : cosmic_ids = variant_obj . get ( 'cosmic_ids' ) if not cosmic_ids : return None else : cosmic_id = cosmic_ids [ 0 ] url_template = ( "https://cancer.sanger.ac.uk/cosmic/mutation/overview?id={}" ) return url_template . format ( cosmic_id )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/appknox/google-chartwrapper/blob/3769aecbef6c83b6cd93ee72ece478ffe433ac57/GChartWrapper/GChart.py#L378-L386<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def color ( self , * args ) : args = color_args ( args , * range ( len ( args ) ) ) self [ 'chco' ] = ',' . join ( args ) return self

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neurodata/ndio/blob/792dd5816bc770b05a3db2f4327da42ff6253531/ndio/remote/resources.py#L415-L487<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_channel ( self , channel_name , project_name , dataset_name , channel_type , dtype , startwindow , endwindow , readonly = 0 , start_time = 0 , end_time = 0 , propagate = 0 , resolution = 0 , channel_description = '' ) : self . _check_channel ( channel_name ) if channel_type not in [ 'image' , 'annotation' , 'timeseries' ] : raise ValueError ( 'Channel type must be ' + 'neurodata.IMAGE or neurodata.ANNOTATION.' ) if readonly * 1 not in [ 0 , 1 ] : raise ValueError ( "readonly must be 0 (False) or 1 (True)." ) # Good job! You supplied very nice arguments. url = self . url ( ) + "/nd/resource/dataset/{}" . format ( dataset_name ) + "/project/{}" . format ( project_name ) + "/channel/{}/" . format ( channel_name ) json = { "channel_name" : channel_name , "channel_type" : channel_type , "channel_datatype" : dtype , "startwindow" : startwindow , "endwindow" : endwindow , 'starttime' : start_time , 'endtime' : end_time , 'readonly' : readonly , 'propagate' : propagate , 'resolution' : resolution , 'channel_description' : channel_description } req = self . remote_utils . post_url ( url , json = json ) if req . status_code is not 201 : raise RemoteDataUploadError ( 'Could not upload {}' . format ( req . text ) ) if req . content == "" or req . content == b'' : return True else : return False

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/werkzeug/debug/tbtools.py#L433-L436<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def render_source ( self ) : return SOURCE_TABLE_HTML % u'\n' . join ( line . render ( ) for line in self . get_annotated_lines ( ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/connectordb/connectordb-python/blob/2092b0cb30898139a247176bcf433d5a4abde7cb/connectordb/_stream.py#L305-L314<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def schema ( self , schema ) : if isinstance ( schema , basestring ) : strschema = schema schema = json . loads ( schema ) else : strschema = json . dumps ( schema ) Draft4Validator . check_schema ( schema ) self . set ( { "schema" : strschema } )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/solvebio/solvebio-python/blob/b29614643043afd19c1d8074e8f25c6700d51a73/solvebio/client.py#L164-L258<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def request ( self , method , url , * * kwargs ) : opts = { 'allow_redirects' : True , 'auth' : self . _auth , 'data' : { } , 'files' : None , 'headers' : dict ( self . _headers ) , 'params' : { } , 'timeout' : 80 , 'verify' : True } raw = kwargs . pop ( 'raw' , False ) debug = kwargs . pop ( 'debug' , False ) opts . update ( kwargs ) method = method . upper ( ) if opts [ 'files' ] : # Don't use application/json for file uploads or GET requests opts [ 'headers' ] . pop ( 'Content-Type' , None ) else : opts [ 'data' ] = json . dumps ( opts [ 'data' ] ) if not url . startswith ( self . _host ) : url = urljoin ( self . _host , url ) logger . debug ( 'API %s Request: %s' % ( method , url ) ) if debug : self . _log_raw_request ( method , url , * * opts ) try : response = self . _session . request ( method , url , * * opts ) except Exception as e : _handle_request_error ( e ) if 429 == response . status_code : delay = int ( response . headers [ 'retry-after' ] ) + 1 logger . warn ( 'Too many requests. Retrying in {0}s.' . format ( delay ) ) time . sleep ( delay ) return self . request ( method , url , * * kwargs ) if not ( 200 <= response . status_code < 400 ) : _handle_api_error ( response ) # 204 is used on deletion. There is no JSON here. if raw or response . status_code in [ 204 , 301 , 302 ] : return response return response . json ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/UCBerkeleySETI/blimpy/blob/b8822d3e3e911944370d84371a91fa0c29e9772e/blimpy/calib_utils/stokescal.py#L183-L264<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def calibrate_pols ( cross_pols , diode_cross , obsI = None , onefile = True , feedtype = 'l' , * * kwargs ) : #Obtain time sample length, frequencies, and noise diode data obs = Waterfall ( diode_cross , max_load = 150 ) cross_dat = obs . data tsamp = obs . header [ 'tsamp' ] #Calculate number of coarse channels in the noise diode measurement (usually 8) dio_ncoarse = obs . calc_n_coarse_chan ( ) dio_nchans = obs . header [ 'nchans' ] dio_chan_per_coarse = dio_nchans / dio_ncoarse obs = None Idat , Qdat , Udat , Vdat = get_stokes ( cross_dat , feedtype ) cross_dat = None #Calculate differential gain and phase from noise diode measurements print ( 'Calculating Mueller Matrix variables' ) gams = gain_offsets ( Idat , Qdat , Udat , Vdat , tsamp , dio_chan_per_coarse , feedtype , * * kwargs ) psis = phase_offsets ( Idat , Qdat , Udat , Vdat , tsamp , dio_chan_per_coarse , feedtype , * * kwargs ) #Clear data arrays to save memory Idat = None Qdat = None Udat = None Vdat = None #Get corrected Stokes parameters print ( 'Opening ' + cross_pols ) cross_obs = Waterfall ( cross_pols , max_load = 150 ) obs_ncoarse = cross_obs . calc_n_coarse_chan ( ) obs_nchans = cross_obs . header [ 'nchans' ] obs_chan_per_coarse = obs_nchans / obs_ncoarse print ( 'Grabbing Stokes parameters' ) I , Q , U , V = get_stokes ( cross_obs . data , feedtype ) print ( 'Applying Mueller Matrix' ) I , Q , U , V = apply_Mueller ( I , Q , U , V , gams , psis , obs_chan_per_coarse , feedtype ) #Use onefile (default) to produce one filterbank file containing all Stokes information if onefile == True : cross_obs . data [ : , 0 , : ] = np . squeeze ( I ) cross_obs . data [ : , 1 , : ] = np . squeeze ( Q ) cross_obs . data [ : , 2 , : ] = np . squeeze ( U ) cross_obs . data [ : , 3 , : ] = np . squeeze ( V ) cross_obs . write_to_fil ( cross_pols [ : - 15 ] + '.SIQUV.polcal.fil' ) print ( 'Calibrated Stokes parameters written to ' + cross_pols [ : - 15 ] + '.SIQUV.polcal.fil' ) return #Write corrected Stokes parameters to four filterbank files if onefile==False obs = Waterfall ( obs_I , max_load = 150 ) obs . data = I obs . write_to_fil ( cross_pols [ : - 15 ] + '.SI.polcal.fil' ) #assuming file is named *.cross_pols.fil print ( 'Calibrated Stokes I written to ' + cross_pols [ : - 15 ] + '.SI.polcal.fil' ) obs . data = Q obs . write_to_fil ( cross_pols [ : - 15 ] + '.Q.polcal.fil' ) #assuming file is named *.cross_pols.fil print ( 'Calibrated Stokes Q written to ' + cross_pols [ : - 15 ] + '.Q.polcal.fil' ) obs . data = U obs . write_to_fil ( cross_pols [ : - 15 ] + '.U.polcal.fil' ) #assuming file is named *.cross_pols.fil print ( 'Calibrated Stokes U written to ' + cross_pols [ : - 15 ] + '.U.polcal.fil' ) obs . data = V obs . write_to_fil ( cross_pols [ : - 15 ] + '.V.polcal.fil' ) #assuming file is named *.cross_pols.fil print ( 'Calibrated Stokes V written to ' + cross_pols [ : - 15 ] + '.V.polcal.fil' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/funilrys/PyFunceble/blob/cdf69cbde120199171f7158e1c33635753e6e2f5/PyFunceble/http_code.py#L157-L204<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get ( self ) : if PyFunceble . HTTP_CODE [ "active" ] : # The http status code extraction is activated. # We get the http status code. http_code = self . _access ( ) # We initiate a variable which will save the list of allowed # http status code. list_of_valid_http_code = [ ] for codes in [ PyFunceble . HTTP_CODE [ "list" ] [ "up" ] , PyFunceble . HTTP_CODE [ "list" ] [ "potentially_down" ] , PyFunceble . HTTP_CODE [ "list" ] [ "potentially_up" ] , ] : # We loop throught the list of http status code. # We extend the list of valid with the currently read # codes. list_of_valid_http_code . extend ( codes ) if http_code not in list_of_valid_http_code or http_code is None : # * The extracted http code is not in the list of valid http code. # or # * The extracted http code is equal to `None`. # We return 3 star in order to mention that we were not eable to extract # the http status code. return "*" * 3 # * The extracted http code is in the list of valid http code. # or # * The extracted http code is not equal to `None`. # We return the extracted http status code. return http_code # The http status code extraction is activated. # We return None. return None

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/EpistasisLab/scikit-mdr/blob/768565deb10467d04a960d27e000ab38b7aa8a62/mdr/mdr.py#L210-L234<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def score ( self , features , class_labels , scoring_function = None , * * scoring_function_kwargs ) : if self . feature_map is None : raise ValueError ( 'The MDR model must be fit before score can be called.' ) new_feature = self . predict ( features ) if scoring_function is None : return accuracy_score ( class_labels , new_feature ) else : return scoring_function ( class_labels , new_feature , * * scoring_function_kwargs )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/pinot_hook.py#L51-L64<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_uri ( self ) : conn = self . get_connection ( getattr ( self , self . conn_name_attr ) ) host = conn . host if conn . port is not None : host += ':{port}' . format ( port = conn . port ) conn_type = 'http' if not conn . conn_type else conn . conn_type endpoint = conn . extra_dejson . get ( 'endpoint' , 'pql' ) return '{conn_type}://{host}/{endpoint}' . format ( conn_type = conn_type , host = host , endpoint = endpoint )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/reingart/gui2py/blob/aca0a05f6fcde55c94ad7cc058671a06608b01a4/gui/doc/ext/autosummary/generate.py#L274-L285<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def find_autosummary_in_files ( filenames ) : documented = [ ] for filename in filenames : f = open ( filename , 'r' ) lines = f . read ( ) . splitlines ( ) documented . extend ( find_autosummary_in_lines ( lines , filename = filename ) ) f . close ( ) return documented

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/RRZE-HPC/kerncraft/blob/c60baf8043e4da8d8d66da7575021c2f4c6c78af/kerncraft/kernel.py#L1458-L1512<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def compile_kernel ( self , openmp = False , assembly = False , verbose = False ) : compiler , compiler_args = self . _machine . get_compiler ( ) in_filename = self . get_kernel_code ( openmp = openmp , as_filename = True ) if assembly : compiler_args += [ '-S' ] suffix = '.s' else : suffix = '.o' out_filename , already_exists = self . _get_intermediate_file ( os . path . splitext ( os . path . basename ( in_filename ) ) [ 0 ] + suffix , binary = not assembly , fp = False ) if already_exists : if verbose : print ( 'Executing (compile_kernel): ' , 'using cached' , out_filename ) return out_filename compiler_args += [ '-std=c99' ] cmd = ( [ compiler ] + [ in_filename , '-c' , '-I' + reduce_path ( os . path . abspath ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) + '/headers/' ) , '-o' , out_filename ] + compiler_args ) if verbose : print ( 'Executing (compile_kernel): ' , ' ' . join ( cmd ) ) try : subprocess . check_output ( cmd ) except subprocess . CalledProcessError as e : print ( "Compilation failed:" , e , file = sys . stderr ) sys . exit ( 1 ) # FIXME TODO FIXME TODO FIXME TODO # Hacky workaround for icc issue (icc may issue vkmovb instructions with AVX512, which are # invalid and should be kmovb): if compiler == 'icc' and assembly : with open ( out_filename , 'r+' ) as f : assembly = f . read ( ) f . seek ( 0 ) f . write ( assembly . replace ( 'vkmovb' , 'kmovb' ) ) f . truncate ( ) # FIXME TODO FIXME TODO FIXME TODO # Let's return the out_file name return out_filename

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/lib/pretty.py#L212-L229<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def breakable ( self , sep = ' ' ) : width = len ( sep ) group = self . group_stack [ - 1 ] if group . want_break : self . flush ( ) self . output . write ( self . newline ) self . output . write ( ' ' * self . indentation ) self . output_width = self . indentation self . buffer_width = 0 else : self . buffer . append ( Breakable ( sep , width , self ) ) self . buffer_width += width self . _break_outer_groups ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/coleifer/irc/blob/f9d2bd6369aafe6cb0916c9406270ca8ecea2080/irc.py#L246-L270<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def enter_event_loop ( self ) : patterns = self . dispatch_patterns ( ) self . logger . debug ( 'entering receive loop' ) while 1 : try : data = self . _sock_file . readline ( ) except socket . error : data = None if not data : self . logger . info ( 'server closed connection' ) self . close ( ) return True data = data . rstrip ( ) for pattern , callback in patterns : match = pattern . match ( data ) if match : callback ( * * match . groupdict ( ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/hirmeos/entity-fishing-client-python/blob/cd5c6e10c6c4e653669e11d735d5773766986bda/nerd/nerd_client.py#L357-L375<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_concept ( self , conceptId , lang = 'en' ) : url = urljoin ( self . concept_service + '/' , conceptId ) res , status_code = self . get ( url , params = { 'lang' : lang } ) if status_code != 200 : logger . debug ( 'Fetch concept failed.' ) return self . decode ( res ) , status_code

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/yandex/yandex-tank/blob/d71d63b6ab5de8b8a5ea2b728b6ab9ac0b1ba71b/yandextank/plugins/Console/screen.py#L443-L450<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def add_info_widget ( self , widget ) : index = widget . get_index ( ) while index in self . info_widgets . keys ( ) : index += 1 self . info_widgets [ widget . get_index ( ) ] = widget

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/math/linalg.py#L448-L543<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def lu_solve ( lower_upper , perm , rhs , validate_args = False , name = None ) : with tf . compat . v1 . name_scope ( name , 'lu_solve' , [ lower_upper , perm , rhs ] ) : lower_upper = tf . convert_to_tensor ( value = lower_upper , dtype_hint = tf . float32 , name = 'lower_upper' ) perm = tf . convert_to_tensor ( value = perm , dtype_hint = tf . int32 , name = 'perm' ) rhs = tf . convert_to_tensor ( value = rhs , dtype_hint = lower_upper . dtype , name = 'rhs' ) assertions = _lu_solve_assertions ( lower_upper , perm , rhs , validate_args ) if assertions : with tf . control_dependencies ( assertions ) : lower_upper = tf . identity ( lower_upper ) perm = tf . identity ( perm ) rhs = tf . identity ( rhs ) if rhs . shape . ndims == 2 and perm . shape . ndims == 1 : # Both rhs and perm have scalar batch_shape. permuted_rhs = tf . gather ( rhs , perm , axis = - 2 ) else : # Either rhs or perm have non-scalar batch_shape or we can't determine # this information statically. rhs_shape = tf . shape ( input = rhs ) broadcast_batch_shape = tf . broadcast_dynamic_shape ( rhs_shape [ : - 2 ] , tf . shape ( input = perm ) [ : - 1 ] ) d , m = rhs_shape [ - 2 ] , rhs_shape [ - 1 ] rhs_broadcast_shape = tf . concat ( [ broadcast_batch_shape , [ d , m ] ] , axis = 0 ) # Tile out rhs. broadcast_rhs = tf . broadcast_to ( rhs , rhs_broadcast_shape ) broadcast_rhs = tf . reshape ( broadcast_rhs , [ - 1 , d , m ] ) # Tile out perm and add batch indices. broadcast_perm = tf . broadcast_to ( perm , rhs_broadcast_shape [ : - 1 ] ) broadcast_perm = tf . reshape ( broadcast_perm , [ - 1 , d ] ) broadcast_batch_size = tf . reduce_prod ( input_tensor = broadcast_batch_shape ) broadcast_batch_indices = tf . broadcast_to ( tf . range ( broadcast_batch_size ) [ : , tf . newaxis ] , [ broadcast_batch_size , d ] ) broadcast_perm = tf . stack ( [ broadcast_batch_indices , broadcast_perm ] , axis = - 1 ) permuted_rhs = tf . gather_nd ( broadcast_rhs , broadcast_perm ) permuted_rhs = tf . reshape ( permuted_rhs , rhs_broadcast_shape ) lower = tf . linalg . set_diag ( tf . linalg . band_part ( lower_upper , num_lower = - 1 , num_upper = 0 ) , tf . ones ( tf . shape ( input = lower_upper ) [ : - 1 ] , dtype = lower_upper . dtype ) ) return linear_operator_util . matrix_triangular_solve_with_broadcast ( lower_upper , # Only upper is accessed. linear_operator_util . matrix_triangular_solve_with_broadcast ( lower , permuted_rhs ) , lower = False )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_pubsub_hook.py#L60-L81<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def publish ( self , project , topic , messages ) : body = { 'messages' : messages } full_topic = _format_topic ( project , topic ) request = self . get_conn ( ) . projects ( ) . topics ( ) . publish ( topic = full_topic , body = body ) try : request . execute ( num_retries = self . num_retries ) except HttpError as e : raise PubSubException ( 'Error publishing to topic {}' . format ( full_topic ) , e )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mental32/spotify.py/blob/bb296cac7c3dd289908906b7069bd80f43950515/spotify/models/user.py#L233-L245<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>async def replace_tracks ( self , playlist , * tracks ) -> str : tracks = [ str ( track ) for track in tracks ] await self . http . replace_playlist_tracks ( self . id , str ( playlist ) , tracks = ',' . join ( tracks ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/singularityhub/sregistry-cli/blob/abc96140a1d15b5e96d83432e1e0e1f4f8f36331/sregistry/main/base/http.py#L81-L96<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def post ( self , url , headers = None , data = None , return_json = True , default_headers = True ) : bot . debug ( "POST %s" % url ) return self . _call ( url , headers = headers , func = requests . post , data = data , return_json = return_json , default_headers = default_headers )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/synw/gencharts/blob/fa35604a9445b399bb4f91bc91af488e8e8208fd/gencharts/__init__.py#L114-L124<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _dict_to_df ( self , dictobj , xfield , yfield ) : x = [ ] y = [ ] for datapoint in dictobj : x . append ( datapoint ) y . append ( dictobj [ datapoint ] ) df = pd . DataFrame ( { xfield [ 0 ] : x , yfield [ 0 ] : y } ) return df

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mikewaters/command-session/blob/cea0d81a56551530f52f1cf3780c0ac408e069ef/commandsession/commandsession.py#L212-L252<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def unpack_pargs ( positional_args , param_kwargs , gnu = False ) : def _transform ( argname ) : """Transform a python identifier into a              shell-appropriate argument name             """ if len ( argname ) == 1 : return '-{}' . format ( argname ) return '--{}' . format ( argname . replace ( '_' , '-' ) ) args = [ ] for item in param_kwargs . keys ( ) : for value in param_kwargs . getlist ( item ) : if gnu : args . append ( '{}={}' . format ( _transform ( item ) , value ) ) else : args . extend ( [ _transform ( item ) , value ] ) if positional_args : for item in positional_args : args . append ( _transform ( item ) ) return args

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chrisrink10/basilisp/blob/3d82670ee218ec64eb066289c82766d14d18cc92/src/basilisp/lang/set.py#L134-L136<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def s ( * members : T , meta = None ) -> Set [ T ] : return Set ( pset ( members ) , meta = meta )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/gurumate-2.8.6-py2.7.egg/gurumate/httpd.py#L8-L15<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def check_running ( process_name = "apache2" ) : if not gurumate . base . get_pid_list ( process_name ) : fail ( "Apache process '%s' doesn't seem to be working" % process_name ) return False #unreachable return True

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/greenbender/pynntp/blob/991a76331cdf5d8f9dbf5b18f6e29adc80749a2f/nntp/nntp.py#L548-L565<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def quit ( self ) : code , message = self . command ( "QUIT" ) if code != 205 : raise NNTPReplyError ( code , message ) self . socket . close ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/makearl/tornado-profile/blob/1b721480d7edc6229f991469e88b9f7a8bb914f3/tornado_profile.py#L212-L217<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def delete ( self ) : CProfileWrapper . profiler . disable ( ) self . running = False self . set_status ( 204 ) self . finish ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mozilla-iot/webthing-python/blob/65d467c89ed79d0bbc42b8b3c8f9e5a320edd237/webthing/thing.py#L233-L245<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_property ( self , property_name ) : prop = self . find_property ( property_name ) if prop : return prop . get_value ( ) return None

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/gtaylor/python-route53/blob/b9fc7e258a79551c9ed61e4a71668b7f06f9e774/route53/transport.py#L173-L187<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _send_get_request ( self , path , params , headers ) : r = requests . get ( self . endpoint + path , params = params , headers = headers ) r . raise_for_status ( ) return r . text

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/rwl/godot/blob/013687c9e8983d2aa2ceebb8a76c5c4f1e37c90f/godot/component/ellipse.py#L89-L123<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _draw_mainlayer ( self , gc , view_bounds = None , mode = "default" ) : x_origin = self . x_origin y_origin = self . y_origin gc . save_state ( ) try : #            self._draw_bounds(gc) gc . begin_path ( ) gc . translate_ctm ( x_origin , y_origin ) gc . scale_ctm ( self . e_width , self . e_height ) gc . arc ( 0.0 , 0.0 , 1.0 , 0 , 2.0 * pi ) gc . close_path ( ) # Draw stroke at same scale as graphics context #            ctm = gc.get_ctm() #            if hasattr(ctm, "__len__") and len(ctm) == 6: #                scale = sqrt( (ctm[0]+ctm[1]) * (ctm[0]+ctm[1]) / 2.0 + \ #                              (ctm[2]+ctm[3]) * (ctm[2]+ctm[3]) / 2.0 ) #            elif hasattr(gc, "get_ctm_scale"): #                scale = gc.get_ctm_scale() #            else: #                raise RuntimeError("Unable to get scale from GC.") gc . set_line_width ( self . pen . line_width ) gc . set_stroke_color ( self . pen . color_ ) if self . filled : gc . set_fill_color ( self . pen . fill_color_ ) gc . draw_path ( FILL_STROKE ) else : gc . stroke_path ( ) finally : gc . restore_state ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/similar.py#L50-L67<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def append_stream ( self , streamid , stream , encoding = None ) : if encoding is None : readlines = stream . readlines else : readlines = decoding_stream ( stream , encoding ) . readlines try : self . linesets . append ( LineSet ( streamid , readlines ( ) , self . ignore_comments , self . ignore_docstrings , self . ignore_imports , ) ) except UnicodeDecodeError : pass

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/librosa/librosa/blob/180e8e6eb8f958fa6b20b8cba389f7945d508247/librosa/filters.py#L391-L543<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def constant_q ( sr , fmin = None , n_bins = 84 , bins_per_octave = 12 , tuning = 0.0 , window = 'hann' , filter_scale = 1 , pad_fft = True , norm = 1 , dtype = np . complex64 , * * kwargs ) : if fmin is None : fmin = note_to_hz ( 'C1' ) # Pass-through parameters to get the filter lengths lengths = constant_q_lengths ( sr , fmin , n_bins = n_bins , bins_per_octave = bins_per_octave , tuning = tuning , window = window , filter_scale = filter_scale ) # Apply tuning correction correction = 2.0 ** ( float ( tuning ) / bins_per_octave ) fmin = correction * fmin # Q should be capitalized here, so we suppress the name warning # pylint: disable=invalid-name Q = float ( filter_scale ) / ( 2.0 ** ( 1. / bins_per_octave ) - 1 ) # Convert lengths back to frequencies freqs = Q * sr / lengths # Build the filters filters = [ ] for ilen , freq in zip ( lengths , freqs ) : # Build the filter: note, length will be ceil(ilen) sig = np . exp ( np . arange ( - ilen // 2 , ilen // 2 , dtype = float ) * 1j * 2 * np . pi * freq / sr ) # Apply the windowing function sig = sig * __float_window ( window ) ( len ( sig ) ) # Normalize sig = util . normalize ( sig , norm = norm ) filters . append ( sig ) # Pad and stack max_len = max ( lengths ) if pad_fft : max_len = int ( 2.0 ** ( np . ceil ( np . log2 ( max_len ) ) ) ) else : max_len = int ( np . ceil ( max_len ) ) filters = np . asarray ( [ util . pad_center ( filt , max_len , * * kwargs ) for filt in filters ] , dtype = dtype ) return filters , np . asarray ( lengths )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L241-L246<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def nrows ( self ) : if not self . _ex . _cache . nrows_valid ( ) : self . _ex . _cache . flush ( ) self . _frame ( fill_cache = True ) return self . _ex . _cache . nrows

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/marrabld/planarradpy/blob/5095d1cb98d4f67a7c3108c9282f2d59253e89a8/gui/gui_mainLayout.py#L181-L192<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def search_file_result ( self ) : if self . ui . tabWidget . currentIndex ( ) == TabWidget . NORMAL_MODE : self . result_file = self . file_dialog . getOpenFileName ( caption = str ( "Open Report File" ) , directory = "./outputs" ) if not self . result_file == '' : self . ui . show_all_curves . setDisabled ( False ) self . ui . show_grid . setDisabled ( False ) self . data_processing ( ) self . display_the_graphic ( self . num_line , self . wavelength , self . data_wanted , self . information ) self . authorized_display = True

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/intel-analytics/BigDL/blob/e9c19788285986ab789a2e2998f9a85d7524779f/pyspark/bigdl/optim/optimizer.py#L425-L432<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def add ( self , scheduler , max_iteration , bigdl_type = "float" ) : return callBigDlFunc ( bigdl_type , "addScheduler" , self . value , scheduler , max_iteration )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/adafruit/Adafruit_Python_PureIO/blob/6f4976d91c52d70b67b28bba75a429b5328a52c1/Adafruit_PureIO/smbus.py#L201-L216<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def read_i2c_block_data ( self , addr , cmd , length = 32 ) : assert self . _device is not None , 'Bus must be opened before operations are made against it!' # Build ctypes values to marshall between ioctl and Python. reg = c_uint8 ( cmd ) result = create_string_buffer ( length ) # Build ioctl request. request = make_i2c_rdwr_data ( [ ( addr , 0 , 1 , pointer ( reg ) ) , # Write cmd register. ( addr , I2C_M_RD , length , cast ( result , POINTER ( c_uint8 ) ) ) # Read data. ] ) # Make ioctl call and return result data. ioctl ( self . _device . fileno ( ) , I2C_RDWR , request ) return bytearray ( result . raw )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/kmmbvnr/django-any/blob/6f64ebd05476e2149e2e71deeefbb10f8edfc412/django_any/xunit.py#L10-L28<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def weighted_choice ( choices ) : total = sum ( [ weight for ( weight , _ ) in choices ] ) i = random . randint ( 0 , total - 1 ) for weight , choice in choices : i -= weight if i < 0 : if callable ( choice ) : return choice ( ) return choice raise Exception ( 'Bug' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/yandex/yandex-tank/blob/d71d63b6ab5de8b8a5ea2b728b6ab9ac0b1ba71b/yandextank/plugins/Telegraf/config.py#L227-L258<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_custom_exec_script ( self ) : cfg_path = "agent_customs_{}.cfg" . format ( self . host ) if os . path . isfile ( cfg_path ) : logger . info ( 'Found agent custom execs config file in working directory with the same name as created for host %s.\n' 'Creating new one via tempfile. This will affect predictable filenames for agent artefacts' , self . host ) handle , cfg_path = tempfile . mkstemp ( '.sh' , 'agent_customs_' ) os . close ( handle ) cmds = "" for idx , cmd in enumerate ( self . custom ) : cmds += "-{idx}) {cmd};;\n" . format ( idx = idx , cmd = cmd [ 'cmd' ] ) customs_script = """         #!/bin/sh         while :         do             case "$1" in             {cmds}             *) break;;             esac             shift         done         """ . format ( cmds = cmds ) with open ( cfg_path , 'w' ) as fds : fds . write ( customs_script ) return cfg_path

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/lxml/html/__init__.py#L624-L661<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def fragments_fromstring ( html , no_leading_text = False , base_url = None , parser = None , * * kw ) : if parser is None : parser = html_parser # FIXME: check what happens when you give html with a body, head, etc. if isinstance ( html , bytes ) : if not _looks_like_full_html_bytes ( html ) : # can't use %-formatting in early Py3 versions html = ( '<html><body>' . encode ( 'ascii' ) + html + '</body></html>' . encode ( 'ascii' ) ) else : if not _looks_like_full_html_unicode ( html ) : html = '<html><body>%s</body></html>' % html doc = document_fromstring ( html , parser = parser , base_url = base_url , * * kw ) assert _nons ( doc . tag ) == 'html' bodies = [ e for e in doc if _nons ( e . tag ) == 'body' ] assert len ( bodies ) == 1 , ( "too many bodies: %r in %r" % ( bodies , html ) ) body = bodies [ 0 ] elements = [ ] if no_leading_text and body . text and body . text . strip ( ) : raise etree . ParserError ( "There is leading text: %r" % body . text ) if body . text and body . text . strip ( ) : elements . append ( body . text ) elements . extend ( body ) # FIXME: removing the reference to the parent artificial document # would be nice return elements

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/opencast/pyCA/blob/c89b168d4780d157e1b3f7676628c1b131956a88/pyca/db.py#L115-L118<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def remaining_duration ( self , time ) : return max ( 0 , self . end - max ( self . start , time ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PythonSanSebastian/docstamp/blob/b43808f2e15351b0b2f0b7eade9c7ef319c9e646/docstamp/template.py#L26-L48<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_environment_for ( file_path ) : work_dir = os . path . dirname ( os . path . abspath ( file_path ) ) if not os . path . exists ( work_dir ) : raise IOError ( 'Could not find folder for dirname of file {}.' . format ( file_path ) ) try : jinja_env = Environment ( loader = FileSystemLoader ( work_dir ) ) except : raise else : return jinja_env

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/katerina7479/pypdflite/blob/ac2501f30d6619eae9dea5644717575ca9263d0a/pypdflite/pdflite.py#L90-L113<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def close ( self ) : self . document . _set_page_numbers ( ) # Places header, pages, page content first.  self . _put_header ( ) self . _put_pages ( ) self . _put_resources ( ) # Information object  self . _put_information ( ) # Catalog object  self . _put_catalog ( ) # Cross-reference object  #self._put_cross_reference()  # Trailer object  self . _put_trailer ( ) if hasattr ( self . destination , "write" ) : output = self . _output_to_io ( ) elif self . destination == 'string' : output = self . _output_to_string ( ) else : self . _output_to_file ( ) output = None return output

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/IEMLdev/ieml/blob/4c842ba7e6165e2f1b4a4e2e98759f9f33af5f25/ieml/grammar/paths/parser/parser.py#L57-L63<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def p_path_sum ( self , p ) : if len ( p ) == 2 : p [ 0 ] = [ p [ 1 ] ] else : p [ 0 ] = p [ 1 ] + [ p [ 3 ] ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chaoss/grimoirelab-kingarthur/blob/9d6a638bee68d5e5c511f045eeebf06340fd3252/arthur/utils.py#L58-L67<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def reader_release ( self ) : self . _readers_mutex . acquire ( ) self . _readers -= 1 if self . _readers == 0 : self . _access_mutex . release ( ) self . _readers_mutex . release ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/urinieto/msaf/blob/9dbb57d77a1310465a65cc40f1641d083ca74385/msaf/pymf/chnmf.py#L193-L218<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def factorize ( self , show_progress = False , compute_w = True , compute_h = True , compute_err = True , niter = 1 ) : AA . factorize ( self , niter = 1 , show_progress = show_progress , compute_w = compute_w , compute_h = compute_h , compute_err = compute_err )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/pyca/pyopenssl/blob/1fbe064c50fd030948141d7d630673761525b0d0/leakcheck/crypto.py#L79-L90<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def check_load_privatekey_callback_incorrect ( self ) : for i in xrange ( self . iterations * 10 ) : try : load_privatekey ( FILETYPE_PEM , self . ENCRYPTED_PEM , lambda * args : "hello, public" ) except Error : pass

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/zenodo/zenodo-accessrequests/blob/ce2cf3f1425d02ba4f3ad3202cfca43a1892558a/zenodo_accessrequests/ext.py#L34-L44<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def verify_token ( ) : try : from . models import SecretLink token = request . args [ 'token' ] # if the token is valid if token and SecretLink . validate_token ( token , { } ) : # then save in session the token session [ 'accessrequests-secret-token' ] = token except KeyError : pass

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SmokinCaterpillar/pypet/blob/97ad3e80d46dbdea02deeb98ea41f05a19565826/examples/example_17_wrapping_an_existing_project/original.py#L149-L192<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def main ( ) : rules_to_test = [ 10 , 30 , 90 , 110 , 184 ] # rules we want to explore: steps = 250 # cell iterations ncells = 400 # number of cells seed = 100042 # RNG seed initial_states = [ 'single' , 'random' ] # Initial states we want to explore # create a folder for the plots and the data folder = os . path . join ( os . getcwd ( ) , 'experiments' , 'ca_patterns_original' ) if not os . path . isdir ( folder ) : os . makedirs ( folder ) filename = os . path . join ( folder , 'all_patterns.p' ) print ( 'Computing all patterns' ) all_patterns = [ ] # list containing the simulation results for idx , rule_number in enumerate ( rules_to_test ) : # iterate over all rules for initial_name in initial_states : # iterate over the initial states # make the initial state initial_state = make_initial_state ( initial_name , ncells , seed = seed ) # simulate the automaton pattern = cellular_automaton_1D ( initial_state , rule_number , steps ) # keep the resulting pattern all_patterns . append ( ( rule_number , initial_name , pattern ) ) # Print a progressbar, because I am always impatient #  (ok that's already from pypet, but it's really handy!) progressbar ( idx , len ( rules_to_test ) , reprint = True ) # Store all patterns to disk with open ( filename , 'wb' ) as file : pickle . dump ( all_patterns , file = file ) # Finally print all patterns print ( 'Plotting all patterns' ) for idx , pattern_tuple in enumerate ( all_patterns ) : rule_number , initial_name , pattern = pattern_tuple # Plot the pattern filename = os . path . join ( folder , 'rule_%s_%s.png' % ( str ( rule_number ) , initial_name ) ) plot_pattern ( pattern , rule_number , filename ) progressbar ( idx , len ( all_patterns ) , reprint = True )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyProphet/pyprophet/blob/f546ad171750cd7685afbde6785fe71f82cadb35/pyprophet/main.py#L212-L222<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def reduce ( infile , outfile ) : if outfile is None : outfile = infile else : outfile = outfile reduce_osw ( infile , outfile )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/boundary/pulse-api-cli/blob/b01ca65b442eed19faac309c9d62bbc3cb2c098f/boundary/relay_list.py#L59-L72<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _filter ( self ) : if self . _metrics or self . _control or self . _plugins : relays = self . _relays [ 'result' ] [ 'relays' ] for relay in relays : if self . _metrics : del relays [ relay ] [ 'metrics' ] if self . _control : del relays [ relay ] [ 'control' ] if self . _plugins : if 'plugins' in relays [ relay ] : del relays [ relay ] [ 'plugins' ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/lxml/html/diff.py#L573-L578<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def split_trailing_whitespace ( word ) : stripped_length = len ( word . rstrip ( ) ) return word [ 0 : stripped_length ] , word [ stripped_length : ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ybrs/single-beat/blob/d036b62d2531710dfd806e9dc2a8d67c77616082/singlebeat/beat.py#L355-L370<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def cli_command_stop ( self , msg ) : info = '' if self . state == State . RUNNING and self . sprocess and self . sprocess . proc : self . state = State . PAUSED self . sprocess . set_exit_callback ( self . proc_exit_cb_state_set ) self . sprocess . proc . kill ( ) info = 'killed' # TODO: check if process is really dead etc. return info

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/librosa/librosa/blob/180e8e6eb8f958fa6b20b8cba389f7945d508247/librosa/segment.py#L54-L287<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def recurrence_matrix ( data , k = None , width = 1 , metric = 'euclidean' , sym = False , sparse = False , mode = 'connectivity' , bandwidth = None , self = False , axis = - 1 ) : data = np . atleast_2d ( data ) # Swap observations to the first dimension and flatten the rest data = np . swapaxes ( data , axis , 0 ) t = data . shape [ 0 ] data = data . reshape ( ( t , - 1 ) ) if width < 1 or width > t : raise ParameterError ( 'width={} must be at least 1 and at most data.shape[{}]={}' . format ( width , axis , t ) ) if mode not in [ 'connectivity' , 'distance' , 'affinity' ] : raise ParameterError ( ( "Invalid mode='{}'. Must be one of " "['connectivity', 'distance', " "'affinity']" ) . format ( mode ) ) if k is None : if t > 2 * width + 1 : k = 2 * np . ceil ( np . sqrt ( t - 2 * width + 1 ) ) else : k = 2 if bandwidth is not None : if bandwidth <= 0 : raise ParameterError ( 'Invalid bandwidth={}. ' 'Must be strictly positive.' . format ( bandwidth ) ) k = int ( k ) # Build the neighbor search object try : knn = sklearn . neighbors . NearestNeighbors ( n_neighbors = min ( t - 1 , k + 2 * width ) , metric = metric , algorithm = 'auto' ) except ValueError : knn = sklearn . neighbors . NearestNeighbors ( n_neighbors = min ( t - 1 , k + 2 * width ) , metric = metric , algorithm = 'brute' ) knn . fit ( data ) # Get the knn graph if mode == 'affinity' : kng_mode = 'distance' else : kng_mode = mode rec = knn . kneighbors_graph ( mode = kng_mode ) . tolil ( ) # Remove connections within width for diag in range ( - width + 1 , width ) : rec . setdiag ( 0 , diag ) # Retain only the top-k links per point for i in range ( t ) : # Get the links from point i links = rec [ i ] . nonzero ( ) [ 1 ] # Order them ascending idx = links [ np . argsort ( rec [ i , links ] . toarray ( ) ) ] [ 0 ] # Everything past the kth closest gets squashed rec [ i , idx [ k : ] ] = 0 if self : if mode == 'connectivity' : rec . setdiag ( 1 ) elif mode == 'affinity' : # we need to keep the self-loop in here, but not mess up the # bandwidth estimation # # using negative distances here preserves the structure without changing # the statistics of the data rec . setdiag ( - 1 ) # symmetrize if sym : # Note: this operation produces a CSR (compressed sparse row) matrix! # This is why we have to do it after filling the diagonal in self-mode rec = rec . minimum ( rec . T ) rec = rec . tocsr ( ) rec . eliminate_zeros ( ) if mode == 'connectivity' : rec = rec . astype ( np . bool ) elif mode == 'affinity' : if bandwidth is None : bandwidth = np . nanmedian ( rec . max ( axis = 1 ) . data ) # Set all the negatives back to 0 # Negatives are temporarily inserted above to preserve the sparsity structure # of the matrix without corrupting the bandwidth calculations rec . data [ rec . data < 0 ] = 0.0 rec . data [ : ] = np . exp ( rec . data / ( - 1 * bandwidth ) ) if not sparse : rec = rec . toarray ( ) return rec

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/reingart/gui2py/blob/aca0a05f6fcde55c94ad7cc058671a06608b01a4/gui/component.py#L741-L761<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _calc_dimension ( self , dim_val , dim_max , font_dim ) : if dim_val is None : return - 1 # let wx automatic pos/size  elif isinstance ( dim_val , int ) : return dim_val # use fixed pixel value (absolute)  elif isinstance ( dim_val , basestring ) : if dim_val . endswith ( "%" ) : # percentaje, relative to parent max size:  dim_val = int ( dim_val [ : - 1 ] ) dim_val = dim_val / 100.0 * dim_max elif dim_val . endswith ( "em" ) : # use current font size (suport fractions):  dim_val = float ( dim_val [ : - 2 ] ) dim_val = dim_val * font_dim elif dim_val . endswith ( "px" ) : # fixed pixels  dim_val = dim_val [ : - 2 ] elif dim_val == "" or dim_val == "auto" : dim_val = - 1 return int ( dim_val )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/iotile/typedargs/blob/0a5091a664b9b4d836e091e9ba583e944f438fd8/typedargs/utils.py#L36-L58<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _parse_validators ( valids ) : outvals = [ ] for val in valids : if isinstance ( val , str ) : args = [ ] elif len ( val ) > 1 : args = val [ 1 : ] val = val [ 0 ] else : raise ValidationError ( "You must pass either an n-tuple or a string to define a validator" , validator = val ) name = "validate_%s" % str ( val ) outvals . append ( ( name , args ) ) return outvals

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neurosynth/neurosynth/blob/948ce7edce15d7df693446e76834e0c23bfe8f11/neurosynth/base/imageutils.py#L98-L152<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_grid ( image , scale = 4 , apply_mask = True , save_file = None ) : if isinstance ( image , string_types ) : image = nb . load ( image ) # create a list of cluster centers centers = [ ] x_length , y_length , z_length = image . shape for x in range ( 0 , x_length , scale ) : for y in range ( 0 , y_length , scale ) : for z in range ( 0 , z_length , scale ) : centers . append ( ( x , y , z ) ) # create a box around each center with the diameter equal to the scaling # factor grid = np . zeros ( image . shape ) for ( i , ( x , y , z ) ) in enumerate ( centers ) : for mov_x in range ( ( - scale + 1 ) // 2 , ( scale + 1 ) // 2 ) : for mov_y in range ( ( - scale + 1 ) // 2 , ( scale + 1 ) // 2 ) : for mov_z in range ( ( - scale + 1 ) // 2 , ( scale + 1 ) // 2 ) : try : # Ignore voxels outside bounds of image grid [ x + mov_x , y + mov_y , z + mov_z ] = i + 1 except : pass if apply_mask : mask = image if isinstance ( mask , string_types ) : mask = nb . load ( mask ) if type ( mask ) . __module__ != np . __name__ : mask = mask . get_data ( ) grid [ ~ mask . astype ( bool ) ] = 0.0 grid = nb . Nifti1Image ( grid , image . get_affine ( ) , image . get_header ( ) ) if save_file is not None : nb . save ( grid , save_file ) return grid

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tnkteja/myhelp/blob/fb3a4809d448ad14d5b2e6ddf2e7e89ad52b71cb/virtualEnvironment/lib/python2.7/site-packages/coverage/control.py#L495-L510<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def combine ( self ) : aliases = None if self . config . paths : aliases = PathAliases ( self . file_locator ) for paths in self . config . paths . values ( ) : result = paths [ 0 ] for pattern in paths [ 1 : ] : aliases . add ( pattern , result ) self . data . combine_parallel_data ( aliases = aliases )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Azure/azure-sdk-for-python/blob/d7306fde32f60a293a7567678692bdad31e4b667/azure-servicemanagement-legacy/azure/servicemanagement/servicemanagementservice.py#L2579-L2604<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def update_disk ( self , disk_name , has_operating_system = None , label = None , media_link = None , name = None , os = None ) : _validate_not_none ( 'disk_name' , disk_name ) _validate_not_none ( 'label' , label ) return self . _perform_put ( self . _get_disk_path ( disk_name ) , _XmlSerializer . disk_to_xml ( label , None , None , None ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/visualization/text.py#L60-L69<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def bot ( self ) : ret = self . bot_format % self . bot_connect . center ( self . width , self . bot_pad ) if self . right_fill : ret = ret . ljust ( self . right_fill , self . bot_pad ) if self . left_fill : ret = ret . rjust ( self . left_fill , self . bot_pad ) ret = ret . center ( self . layer_width , self . bot_bck ) return ret

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/iotaledger/iota.lib.py/blob/97cdd1e241498446b46157b79b2a1ea2ec6d387a/iota/transaction/base.py#L501-L543<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_messages ( self , errors = 'drop' ) : # type: (Text) -> List[Text] decode_errors = 'strict' if errors == 'drop' else errors messages = [ ] for group in self . group_transactions ( ) : # Ignore inputs. if group [ 0 ] . value < 0 : continue message_trytes = TryteString ( b'' ) for txn in group : message_trytes += txn . signature_message_fragment if message_trytes : try : messages . append ( message_trytes . decode ( decode_errors ) ) except ( TrytesDecodeError , UnicodeDecodeError ) : if errors != 'drop' : raise return messages

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/parallel/apps/ipcontrollerapp.py#L282-L297<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def load_secondary_config ( self ) : if self . reuse_files : try : self . load_config_from_json ( ) except ( AssertionError , IOError ) as e : self . log . error ( "Could not load config from JSON: %s" % e ) else : # successfully loaded config from JSON, and reuse=True # no need to wite back the same file self . write_connection_files = False # switch Session.key default to secure default_secure ( self . config ) self . log . debug ( "Config changed" ) self . log . debug ( repr ( self . config ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mordred-descriptor/mordred/blob/2848b088fd7b6735590242b5e22573babc724f10/mordred/surface_area/_sasa.py#L95-L118<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def from_mol ( cls , mol , conformer = - 1 , solvent_radius = 1.4 , level = 4 ) : rs = atoms_to_numpy ( lambda a : vdw_radii [ a . GetAtomicNum ( ) ] + solvent_radius , mol ) conf = mol . GetConformer ( conformer ) ps = np . array ( [ list ( conf . GetAtomPosition ( i ) ) for i in range ( mol . GetNumAtoms ( ) ) ] ) return cls ( rs , ps , level )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SmokinCaterpillar/pypet/blob/97ad3e80d46dbdea02deeb98ea41f05a19565826/pypet/storageservice.py#L3037-L3112<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _all_set_attributes_to_recall_natives ( data , ptitem , prefix ) : # If `data` is a container, remember the container type if type ( data ) is tuple : HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . COLL_TYPE , HDF5StorageService . COLL_TUPLE ) elif type ( data ) is list : HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . COLL_TYPE , HDF5StorageService . COLL_LIST ) elif type ( data ) is np . ndarray : HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . COLL_TYPE , HDF5StorageService . COLL_NDARRAY ) elif type ( data ) is np . matrix : HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . COLL_TYPE , HDF5StorageService . COLL_MATRIX ) elif type ( data ) in pypetconstants . PARAMETER_SUPPORTED_DATA : HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . COLL_TYPE , HDF5StorageService . COLL_SCALAR ) strtype = type ( data ) . __name__ if not strtype in pypetconstants . PARAMETERTYPEDICT : raise TypeError ( 'I do not know how to handle `%s` its type is `%s`.' % ( str ( data ) , repr ( type ( data ) ) ) ) HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . SCALAR_TYPE , strtype ) elif type ( data ) is dict : if len ( data ) > 0 : HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . COLL_TYPE , HDF5StorageService . COLL_DICT ) else : HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . COLL_TYPE , HDF5StorageService . COLL_EMPTY_DICT ) else : raise TypeError ( 'I do not know how to handle `%s` its type is `%s`.' % ( str ( data ) , repr ( type ( data ) ) ) ) if type ( data ) in ( list , tuple ) : # If data is a list or tuple we need to remember the data type of the elements # in the list or tuple. # We do NOT need to remember the elements of `dict` explicitly, though. # `dict` is stored # as an `ObjectTable` and thus types are already conserved. if len ( data ) > 0 : strtype = type ( data [ 0 ] ) . __name__ if not strtype in pypetconstants . PARAMETERTYPEDICT : raise TypeError ( 'I do not know how to handle `%s` its type is ' '`%s`.' % ( str ( data ) , strtype ) ) HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . SCALAR_TYPE , strtype ) elif ( type ( data ) in ( np . ndarray , np . matrix ) and np . issubdtype ( data . dtype , str ) ) : HDF5StorageService . _all_set_attr ( ptitem , prefix + HDF5StorageService . SCALAR_TYPE , str . __name__ )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/umich-brcf-bioinf/Jacquard/blob/83dd61dd2b5e4110468493beec7bc121e6cb3cd1/jacquard/utils/vcf.py#L271-L277<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def format_tags ( self ) : tags = VcfRecord . _EMPTY_SET if self . sample_tag_values : first_sample = list ( self . sample_tag_values . keys ( ) ) [ 0 ] tags = set ( self . sample_tag_values [ first_sample ] . keys ( ) ) return tags

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/LLNL/scraper/blob/881a316e4c04dfa5a9cf491b7c7f9f997a7c56ea/scraper/github/__init__.py#L14-L31<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def gov_orgs ( ) : us_gov_github_orgs = set ( ) gov_orgs = requests . get ( 'https://government.github.com/organizations.json' ) . json ( ) us_gov_github_orgs . update ( gov_orgs [ 'governments' ] [ 'U.S. Federal' ] ) us_gov_github_orgs . update ( gov_orgs [ 'governments' ] [ 'U.S. Military and Intelligence' ] ) us_gov_github_orgs . update ( gov_orgs [ 'research' ] [ 'U.S. Research Labs' ] ) return list ( us_gov_github_orgs )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/sergei-maertens/django-systemjs/blob/efd4a3862a39d9771609a25a5556f36023cf6e5c/systemjs/jspm.py#L33-L56<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def find_systemjs_location ( ) : location = os . path . abspath ( os . path . dirname ( locate_package_json ( ) ) ) conf = parse_package_json ( ) if 'jspm' in conf : conf = conf [ 'jspm' ] try : conf = conf [ 'directories' ] except TypeError : raise ImproperlyConfigured ( "`package.json` doesn't appear to be a valid json object. " "Location: %s" % location ) except KeyError : raise ImproperlyConfigured ( "The `directories` configuarion was not found in package.json. " "Please check your jspm install and/or configuarion. `package.json` " "location: %s" % location ) # check for explicit location, else fall back to the default as jspm does jspm_packages = conf [ 'packages' ] if 'packages' in conf else 'jspm_packages' base = conf [ 'baseURL' ] if 'baseURL' in conf else '.' return os . path . join ( location , base , jspm_packages , 'system.js' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neherlab/treetime/blob/f6cdb58d19243a18ffdaa2b2ec71872fa00e65c0/treetime/treetime.py#L773-L795<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _find_best_root ( self , covariation = True , force_positive = True , slope = 0 , * * kwarks ) : for n in self . tree . find_clades ( ) : n . branch_length = n . mutation_length self . logger ( "TreeTime._find_best_root: searching for the best root position..." , 2 ) Treg = self . setup_TreeRegression ( covariation = covariation ) return Treg . optimal_reroot ( force_positive = force_positive , slope = slope ) [ 'node' ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jrxFive/python-nomad/blob/37df37e4de21e6f8ac41c6154e7f1f44f1800020/nomad/api/namespaces.py#L60-L73<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_namespaces ( self , prefix = None ) : params = { "prefix" : prefix } return self . request ( method = "get" , params = params ) . json ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/LionelAuroux/pyrser/blob/f153a97ef2b6bf915a1ed468c0252a9a59b754d5/pyrser/parsing/stream.py#L199-L202<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def save_context ( self ) -> bool : self . _contexts . append ( self . _cursor . position ) return True

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/trainable_distributions/trainable_distributions_lib.py#L200-L281<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def bernoulli ( x , layer_fn = tf . compat . v1 . layers . dense , name = None ) : with tf . compat . v1 . name_scope ( name , 'bernoulli' , [ x ] ) : x = tf . convert_to_tensor ( value = x , name = 'x' ) logits = tf . squeeze ( layer_fn ( x , 1 ) , axis = - 1 ) return tfd . Bernoulli ( logits = logits )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/UCBerkeleySETI/blimpy/blob/b8822d3e3e911944370d84371a91fa0c29e9772e/blimpy/filterbank.py#L218-L235<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _setup_time_axis ( self , t_start = None , t_stop = None ) : # now check to see how many integrations requested ii_start , ii_stop = 0 , self . n_ints_in_file if t_start : ii_start = t_start if t_stop : ii_stop = t_stop n_ints = ii_stop - ii_start ## Setup time axis t0 = self . header [ b'tstart' ] t_delt = self . header [ b'tsamp' ] self . timestamps = np . arange ( 0 , n_ints ) * t_delt / 24. / 60. / 60 + t0 return ii_start , ii_stop , n_ints

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/vaexio/vaex/blob/a45b672f8287afca2ada8e36b74b604b9b28dd85/packages/vaex-core/vaex/dataframe.py#L3726-L3739<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def set_active_range ( self , i1 , i2 ) : logger . debug ( "set active range to: %r" , ( i1 , i2 ) ) self . _active_fraction = ( i2 - i1 ) / float ( self . length_original ( ) ) # self._fraction_length = int(self._length * self._active_fraction) self . _index_start = i1 self . _index_end = i2 self . select ( None ) self . set_current_row ( None ) self . _length_unfiltered = i2 - i1 self . signal_active_fraction_changed . emit ( self , self . _active_fraction )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/vaexio/vaex/blob/a45b672f8287afca2ada8e36b74b604b9b28dd85/packages/vaex-core/vaex/functions.py#L363-L389<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def dt_day_name ( x ) : import pandas as pd return pd . Series ( _pandas_dt_fix ( x ) ) . dt . day_name ( ) . values . astype ( str )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/jinja2/filters.py#L193-L223<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def do_dictsort ( value , case_sensitive = False , by = 'key' ) : if by == 'key' : pos = 0 elif by == 'value' : pos = 1 else : raise FilterArgumentError ( 'You can only sort by either ' '"key" or "value"' ) def sort_func ( item ) : value = item [ pos ] if isinstance ( value , string_types ) and not case_sensitive : value = value . lower ( ) return value return sorted ( value . items ( ) , key = sort_func )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/getgauge/gauge-python/blob/90f3547dcfd2d16d51f116cdd4e53527eeab1a57/getgauge/parser_redbaron.py#L62-L80<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _step_decorator_args ( self , decorator ) : args = decorator . call . value step = None if len ( args ) == 1 : try : step = args [ 0 ] . value . to_python ( ) except ( ValueError , SyntaxError ) : pass if isinstance ( step , six . string_types + ( list , ) ) : return step logging . error ( "Decorator step accepts either a string or a list of \                 strings - %s" , self . file_path ) else : logging . error ( "Decorator step accepts only one argument - %s" , self . file_path )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/labstreaminglayer/liblsl-Python/blob/1ff6fe2794f8dba286b7491d1f7a4c915b8a0605/pylsl/pylsl.py#L1034-L1039<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def remove_child ( self , rhs ) : if type ( rhs ) is XMLElement : lib . lsl_remove_child ( self . e , rhs . e ) else : lib . lsl_remove_child_n ( self . e , rhs )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/core/displayhook.py#L95-L105<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def quiet ( self ) : # do not print output if input ends in ';' try : cell = self . shell . history_manager . input_hist_parsed [ self . prompt_count ] if cell . rstrip ( ) . endswith ( ';' ) : return True except IndexError : # some uses of ipshellembed may fail here pass return False

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/UCBerkeleySETI/blimpy/blob/b8822d3e3e911944370d84371a91fa0c29e9772e/blimpy/waterfall.py#L159-L165<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def read_data ( self , f_start = None , f_stop = None , t_start = None , t_stop = None ) : self . container . read_data ( f_start = f_start , f_stop = f_stop , t_start = t_start , t_stop = t_stop ) self . __load_data ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SectorLabs/django-postgres-extra/blob/eef2ed5504d225858d4e4f5d77a838082ca6053e/psqlextra/manager/manager.py#L173-L195<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def insert ( self , * * fields ) : if self . conflict_target or self . conflict_action : compiler = self . _build_insert_compiler ( [ fields ] ) rows = compiler . execute_sql ( return_id = True ) pk_field_name = self . model . _meta . pk . name return rows [ 0 ] [ pk_field_name ] # no special action required, use the standard Django create(..) return super ( ) . create ( * * fields ) . pk

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/server/blueprints/genes/views.py#L26-L39<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def gene ( hgnc_id = None , hgnc_symbol = None ) : if hgnc_symbol : query = store . hgnc_genes ( hgnc_symbol ) if query . count ( ) == 1 : hgnc_id = query . first ( ) [ 'hgnc_id' ] else : return redirect ( url_for ( '.genes' , query = hgnc_symbol ) ) try : genes = controllers . gene ( store , hgnc_id ) except ValueError as error : return abort ( 404 ) return genes

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/inveniosoftware/invenio-migrator/blob/6902c6968a39b747d15e32363f43b7dffe2622c2/invenio_migrator/legacy/records.py#L133-L142<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def dump_record_json ( marcxml ) : try : from invenio . modules . records . api import Record d = Record . create ( marcxml , 'marc' ) return d . dumps ( clean = True ) except ImportError : from invenio . bibfield import create_record d = create_record ( marcxml , master_format = 'marc' ) return d . dumps ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/dagcircuit/dagcircuit.py#L313-L357<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def apply_operation_back ( self , op , qargs = None , cargs = None , condition = None ) : qargs = qargs or [ ] cargs = cargs or [ ] all_cbits = self . _bits_in_condition ( condition ) all_cbits . extend ( cargs ) self . _check_condition ( op . name , condition ) self . _check_bits ( qargs , self . output_map ) self . _check_bits ( all_cbits , self . output_map ) self . _add_op_node ( op , qargs , cargs , condition ) # Add new in-edges from predecessors of the output nodes to the # operation node while deleting the old in-edges of the output nodes # and adding new edges from the operation node to each output node al = [ qargs , all_cbits ] for q in itertools . chain ( * al ) : ie = list ( self . _multi_graph . predecessors ( self . output_map [ q ] ) ) if len ( ie ) != 1 : raise DAGCircuitError ( "output node has multiple in-edges" ) self . _multi_graph . add_edge ( ie [ 0 ] , self . _id_to_node [ self . _max_node_id ] , name = "%s[%s]" % ( q [ 0 ] . name , q [ 1 ] ) , wire = q ) self . _multi_graph . remove_edge ( ie [ 0 ] , self . output_map [ q ] ) self . _multi_graph . add_edge ( self . _id_to_node [ self . _max_node_id ] , self . output_map [ q ] , name = "%s[%s]" % ( q [ 0 ] . name , q [ 1 ] ) , wire = q ) return self . _id_to_node [ self . _max_node_id ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ricobl/django-importer/blob/6967adfa7a286be7aaf59d3f33c6637270bd9df6/django_importer/importers/base.py#L48-L70<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse ( self ) : # Checks if the source is loaded if not self . loaded : self . load ( self . source ) for item in self . get_items ( ) : # Parse the fields from the source into a dict data = self . parse_item ( item ) # Get the instance from the DB, or a new one instance = self . get_instance ( data ) # Feed instance with data self . feed_instance ( data , instance ) # Try to save the instance or keep the error try : self . save_item ( item , data , instance ) except Exception as e : self . save_error ( data , sys . exc_info ( ) ) # Unload the source self . unload ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jazzband/django-ddp/blob/1e1954b06fe140346acea43582515991685e4e01/setup.py#L59-L72<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def finalize_options ( self ) : # Get all the information we need to install pure Python modules # from the umbrella 'install' command -- build (source) directory, # install (target) directory, and whether to compile .py files. self . set_undefined_options ( 'build' , ( 'build_lib' , 'build_lib' ) , ) self . set_undefined_options ( 'build_py' , ( 'package_dir' , 'package_dir' ) , ) setuptools . command . build_py . build_py . finalize_options ( self )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/agile-geoscience/striplog/blob/8033b673a151f96c29802b43763e863519a3124c/striplog/legend.py#L153-L176<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _repr_html_ ( self ) : rows , c = '' , '' s = '<tr><td><strong>{k}</strong></td><td style="{stl}">{v}</td></tr>' for k , v in self . __dict__ . items ( ) : if k == '_colour' : k = 'colour' c = utils . text_colour_for_hex ( v ) style = 'color:{}; background-color:{}' . format ( c , v ) else : style = 'color:black; background-color:white' if k == 'component' : try : v = v . _repr_html_ ( ) except AttributeError : v = v . __repr__ ( ) rows += s . format ( k = k , v = v , stl = style ) html = '<table>{}</table>' . format ( rows ) return html

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/capitalone/giraffez/blob/6b4d27eb1a1eaf188c6885c7364ef27e92b1b957/giraffez/types.py#L282-L344<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def serialize ( self ) : data = b"" for column in self : row = struct . pack ( "5H" , column . type , column . length , column . precision , column . scale , len ( column . name ) ) row += ensure_bytes ( column . name ) data += row return struct . pack ( "H" , len ( data ) ) + data

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/grid_search.py#L710-L734<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_hyperparams_dict ( self , id , display = True ) : idx = id if is_type ( id , int ) else self . model_ids . index ( id ) model = self [ idx ] model_params = dict ( ) # if cross-validation is turned on, parameters in one of the fold model actual contains the max_runtime_secs # parameter and not the main model that is returned. if model . _is_xvalidated : model = h2o . get_model ( model . _xval_keys [ 0 ] ) for param_name in self . hyper_names : model_params [ param_name ] = model . params [ param_name ] [ 'actual' ] [ 0 ] if isinstance ( model . params [ param_name ] [ 'actual' ] , list ) else model . params [ param_name ] [ 'actual' ] if display : print ( 'Hyperparameters: [' + ', ' . join ( list ( self . hyper_params . keys ( ) ) ) + ']' ) return model_params

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jp74/django-model-publisher/blob/075886b866c9b2232fd7267937c4d7571e251780/publisher/management/commands/publish_model.py#L17-L22<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def error ( self , message , code = 1 ) : print >> sys . stderr , message sys . exit ( code )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/classes.py#L742-L754<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def visit_classdef ( self , node ) : self . _check_bases_classes ( node ) # if not an exception or a metaclass if node . type == "class" and has_known_bases ( node ) : try : node . local_attr ( "__init__" ) except astroid . NotFoundError : self . add_message ( "no-init" , args = node , node = node ) self . _check_slots ( node ) self . _check_proper_bases ( node ) self . _check_consistent_mro ( node )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tnkteja/myhelp/blob/fb3a4809d448ad14d5b2e6ddf2e7e89ad52b71cb/virtualEnvironment/lib/python2.7/site-packages/coverage/cmdline.py#L372-L472<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def command_line ( self , argv ) : # Collect the command-line options. if not argv : self . help_fn ( topic = 'minimum_help' ) return OK # The command syntax we parse depends on the first argument.  Classic # syntax always starts with an option. self . classic = argv [ 0 ] . startswith ( '-' ) if self . classic : parser = ClassicOptionParser ( ) else : parser = CMDS . get ( argv [ 0 ] ) if not parser : self . help_fn ( "Unknown command: '%s'" % argv [ 0 ] ) return ERR argv = argv [ 1 : ] parser . help_fn = self . help_fn ok , options , args = parser . parse_args ( argv ) if not ok : return ERR # Handle help and version. if self . do_help ( options , args , parser ) : return OK # Check for conflicts and problems in the options. if not self . args_ok ( options , args ) : return ERR # Listify the list options. source = unshell_list ( options . source ) omit = unshell_list ( options . omit ) include = unshell_list ( options . include ) debug = unshell_list ( options . debug ) # Do something. self . coverage = self . covpkg . coverage ( data_suffix = options . parallel_mode , cover_pylib = options . pylib , timid = options . timid , branch = options . branch , config_file = options . rcfile , source = source , omit = omit , include = include , debug = debug , ) if 'debug' in options . actions : return self . do_debug ( args ) if 'erase' in options . actions or options . erase_first : self . coverage . erase ( ) else : self . coverage . load ( ) if 'execute' in options . actions : self . do_execute ( options , args ) if 'combine' in options . actions : self . coverage . combine ( ) self . coverage . save ( ) # Remaining actions are reporting, with some common options. report_args = dict ( morfs = args , ignore_errors = options . ignore_errors , omit = omit , include = include , ) if 'report' in options . actions : total = self . coverage . report ( show_missing = options . show_missing , * * report_args ) if 'annotate' in options . actions : self . coverage . annotate ( directory = options . directory , * * report_args ) if 'html' in options . actions : total = self . coverage . html_report ( directory = options . directory , title = options . title , * * report_args ) if 'xml' in options . actions : outfile = options . outfile total = self . coverage . xml_report ( outfile = outfile , * * report_args ) if options . fail_under is not None : if total >= options . fail_under : return OK else : return FAIL_UNDER else : return OK

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py#L57-L68<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _get_tensor_like_attributes ( ) : # Enable "Tensor semantics" for distributions. # See tensorflow/python/framework/ops.py `class Tensor` for details. attrs = dict ( ) # Setup overloadable operators and white-listed members / properties. attrs . update ( ( attr , _wrap_method ( tf . Tensor , attr ) ) for attr in tf . Tensor . OVERLOADABLE_OPERATORS . union ( { '__iter__' } ) ) # Copy some members straight-through. attrs . update ( ( attr , getattr ( tf . Tensor , attr ) ) for attr in { '__nonzero__' , '__bool__' , '__array_priority__' } ) return attrs

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Numergy/yoda/blob/109f0e9441130488b0155f05883ef6531cf46ee9/yoda/logger.py#L65-L71<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def set_file_handler ( self , logfile ) : handler = logging . FileHandler ( logfile ) handler . setLevel ( logging . NOTSET ) handler . setFormatter ( Formatter ( FORMAT ) ) self . addHandler ( handler )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/edoburu/django-tag-parser/blob/c24256cfdd0248434f2e3df3444ed9f945d4181f/tag_parser/parser.py#L36-L87<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse_token_kwargs ( parser , token , allowed_kwargs = None , compile_args = True , compile_kwargs = True ) : if isinstance ( token , Token ) : bits = token . split_contents ( ) else : bits = token expect_kwarg = False args = [ ] kwargs = { } prev_bit = None tag_name = bits [ 0 ] for bit in bits [ 1 : : ] : kwarg_match = kwarg_re . match ( bit ) if kwarg_match : # Keyword argument expect_kwarg = True ( name , expr ) = bit . split ( '=' , 2 ) kwargs [ name ] = parser . compile_filter ( expr ) if compile_kwargs else expr else : # Still at positioned arguments. if expect_kwarg : raise TemplateSyntaxError ( "{0} tag may not have a non-keyword argument ({1}) after a keyword argument ({2})." . format ( bits [ 0 ] , bit , prev_bit ) ) args . append ( parser . compile_filter ( bit ) if compile_args else bit ) prev_bit = bit # Validate the allowed arguments, to make things easier for template developers if allowed_kwargs is not None and kwargs : if not allowed_kwargs : raise TemplateSyntaxError ( "The option %s=... cannot be used in '%s'.\nNo keyword arguments are allowed." ) for name in kwargs : if name not in allowed_kwargs : raise TemplateSyntaxError ( "The option %s=... cannot be used in '%s'.\nPossible options are: %s." % ( name , bits [ 0 ] , ", " . join ( allowed_kwargs ) ) ) return tag_name , args , kwargs

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/katerina7479/pypdflite/blob/ac2501f30d6619eae9dea5644717575ca9263d0a/pypdflite/pdflite.py#L256-L292<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _put_trailer ( self ) : startxref = len ( self . session . buffer ) self . _put_cross_reference ( ) md5 = hashlib . md5 ( ) md5 . update ( datetime . now ( ) . strftime ( '%Y%m%d%H%M%S' ) ) try : md5 . update ( self . filepath ) except TypeError : pass if self . title : md5 . update ( self . title ) if self . subject : md5 . update ( self . subject ) if self . author : md5 . update ( self . author ) if self . keywords : md5 . update ( self . keywords ) if self . creator : md5 . update ( self . creator ) objnum = len ( self . session . objects ) self . session . _out ( 'trailer' ) self . session . _out ( '<<' ) self . session . _out ( '/Size %s' % objnum ) self . session . _out ( '/Root %s 0 R' % ( objnum - 1 ) ) self . session . _out ( '/Info %s 0 R' % ( objnum - 2 ) ) self . session . _out ( '/ID [ <%s> <%s>]' % ( md5 . hexdigest ( ) , md5 . hexdigest ( ) ) ) self . session . _out ( '>>' ) self . session . _out ( 'startxref' ) self . session . _out ( startxref ) self . session . _out ( '%%EOF' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/VingtCinq/python-resize-image/blob/a4e645792ef30c5fcc558df6da6de18b1ecb95ea/resizeimage/resizeimage.py#L118-L138<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def resize_width ( image , size , resample = Image . LANCZOS ) : try : width = size [ 0 ] except : width = size img_format = image . format img = image . copy ( ) img_size = img . size # If the origial image has already the good width, return it # fix issue #16 if img_size [ 0 ] == width : return image new_height = int ( math . ceil ( ( width / img_size [ 0 ] ) * img_size [ 1 ] ) ) img . thumbnail ( ( width , new_height ) , resample ) img . format = img_format return img

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SmokinCaterpillar/pypet/blob/97ad3e80d46dbdea02deeb98ea41f05a19565826/examples/example_21_scoop_multiprocessing.py#L16-L19<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def multiply ( traj ) : z = traj . x * traj . y traj . f_add_result ( 'z' , z = z , comment = 'I am the product of two reals!' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/pyreverse/main.py#L193-L217<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def run ( self , args ) : if not args : print ( self . help ( ) ) return 1 # insert current working directory to the python path to recognize # dependencies to local modules even if cwd is not in the PYTHONPATH sys . path . insert ( 0 , os . getcwd ( ) ) try : project = project_from_files ( args , project_name = self . config . project , black_list = self . config . black_list , ) linker = Linker ( project , tag = True ) handler = DiadefsHandler ( self . config ) diadefs = handler . get_diadefs ( project , linker ) finally : sys . path . pop ( 0 ) if self . config . output_format == "vcg" : writer . VCGWriter ( self . config ) . write ( diadefs ) else : writer . DotWriter ( self . config ) . write ( diadefs ) return 0

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chrisrink10/basilisp/blob/3d82670ee218ec64eb066289c82766d14d18cc92/src/basilisp/lang/runtime.py#L537-L553<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def __get_or_create ( ns_cache : NamespaceMap , name : sym . Symbol , module : types . ModuleType = None , core_ns_name = CORE_NS , ) -> lmap . Map : ns = ns_cache . entry ( name , None ) if ns is not None : return ns_cache new_ns = Namespace ( name , module = module ) if name . name != core_ns_name : core_ns = ns_cache . entry ( sym . symbol ( core_ns_name ) , None ) assert core_ns is not None , "Core namespace not loaded yet!" new_ns . refer_all ( core_ns ) return ns_cache . assoc ( name , new_ns )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/vaexio/vaex/blob/a45b672f8287afca2ada8e36b74b604b9b28dd85/packages/vaex-core/vaex/functions.py#L1185-L1217<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def str_rindex ( x , sub , start = 0 , end = None ) : return str_rfind ( x , sub , start , end )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/elliterate/capybara.py/blob/0c6ae449cc37e4445ec3cd6af95674533beedc6c/capybara/node/matchers.py#L784-L798<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def has_unchecked_field ( self , locator , * * kwargs ) : kwargs [ "checked" ] = False return self . has_selector ( "field" , locator , * * kwargs )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/inveniosoftware/invenio-migrator/blob/6902c6968a39b747d15e32363f43b7dffe2622c2/invenio_migrator/tasks/records.py#L36-L57<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def import_record ( data , source_type = None , latest_only = False ) : source_type = source_type or 'marcxml' assert source_type in [ 'marcxml' , 'json' ] recorddump = current_migrator . records_dump_cls ( data , source_type = source_type , pid_fetchers = current_migrator . records_pid_fetchers , ) try : current_migrator . records_dumploader_cls . create ( recorddump ) db . session . commit ( ) except Exception : db . session . rollback ( ) raise

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/dopefishh/pympi/blob/79c747cde45b5ba203ed93154d8c123ac9c3ef56/pympi/Praat.py#L297-L319<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def to_eaf ( self , skipempty = True , pointlength = 0.1 ) : from pympi . Elan import Eaf eaf_out = Eaf ( ) if pointlength <= 0 : raise ValueError ( 'Pointlength should be strictly positive' ) for tier in self . get_tiers ( ) : eaf_out . add_tier ( tier . name ) for ann in tier . get_intervals ( True ) : if tier . tier_type == 'TextTier' : ann = ( ann [ 0 ] , ann [ 0 ] + pointlength , ann [ 1 ] ) if ann [ 2 ] . strip ( ) or not skipempty : eaf_out . add_annotation ( tier . name , int ( round ( ann [ 0 ] * 1000 ) ) , int ( round ( ann [ 1 ] * 1000 ) ) , ann [ 2 ] ) return eaf_out

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/openvenues/pypostal/blob/1c0fd96b5e2463b7015cd3625ac276db520c69fe/postal/expand.py#L9-L54<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def expand_address ( address , languages = None , * * kw ) : address = safe_decode ( address , 'utf-8' ) return _expand . expand_address ( address , languages = languages , * * kw )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/umich-brcf-bioinf/Jacquard/blob/83dd61dd2b5e4110468493beec7bc121e6cb3cd1/jacquard/variant_caller_transforms/mutect.py#L224-L244<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def claim ( self , file_readers ) : unclaimed_readers = [ ] vcf_readers = [ ] for file_reader in file_readers : if self . _is_mutect_vcf ( file_reader ) : vcf_reader = vcf . VcfReader ( file_reader ) vcf_readers . append ( _MutectVcfReader ( vcf_reader ) ) else : unclaimed_readers . append ( file_reader ) return ( unclaimed_readers , vcf_readers )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/agile-geoscience/striplog/blob/8033b673a151f96c29802b43763e863519a3124c/striplog/striplog.py#L331-L382<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def __intervals_from_tops ( self , tops , values , basis , components , field = None , ignore_nan = True ) : # Scale tops to actual depths. length = float ( basis . size ) start , stop = basis [ 0 ] , basis [ - 1 ] tops = [ start + ( p / ( length - 1 ) ) * ( stop - start ) for p in tops ] bases = tops [ 1 : ] + [ stop ] list_of_Intervals = [ ] for i , t in enumerate ( tops ) : v , c , d = values [ i ] , [ ] , { } if ignore_nan and np . isnan ( v ) : continue if ( field is not None ) : d = { field : v } if components is not None : try : c = [ deepcopy ( components [ int ( v ) ] ) ] except IndexError : c = [ ] if c and ( c [ 0 ] is None ) : c = [ ] interval = Interval ( t , bases [ i ] , data = d , components = c ) list_of_Intervals . append ( interval ) return list_of_Intervals

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/tools/monitor/job_monitor.py#L22-L64<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _text_checker ( job , interval , _interval_set = False , quiet = False , output = sys . stdout ) : status = job . status ( ) msg = status . value prev_msg = msg msg_len = len ( msg ) if not quiet : print ( '\r%s: %s' % ( 'Job Status' , msg ) , end = '' , file = output ) while status . name not in [ 'DONE' , 'CANCELLED' , 'ERROR' ] : time . sleep ( interval ) status = job . status ( ) msg = status . value if status . name == 'QUEUED' : msg += ' (%s)' % job . queue_position ( ) if not _interval_set : interval = max ( job . queue_position ( ) , 2 ) else : if not _interval_set : interval = 2 # Adjust length of message so there are no artifacts if len ( msg ) < msg_len : msg += ' ' * ( msg_len - len ( msg ) ) elif len ( msg ) > msg_len : msg_len = len ( msg ) if msg != prev_msg and not quiet : print ( '\r%s: %s' % ( 'Job Status' , msg ) , end = '' , file = output ) prev_msg = msg if not quiet : print ( '' , file = output )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ingolemo/python-lenses/blob/a3a6ed0a31f6674451e542e7380a8aa16e6f8edf/lenses/optics/base.py#L152-L172<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def view ( self , state ) : # type: (S) -> B if not self . _is_kind ( Fold ) : raise TypeError ( 'Must be an instance of Fold to .view()' ) guard = object ( ) result = self . preview ( state ) . maybe ( guard ) if result is guard : raise ValueError ( 'No focus to view' ) return cast ( B , result )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/raw_metrics.py#L90-L114<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_type ( tokens , start_index ) : i = start_index tok_type = tokens [ i ] [ 0 ] start = tokens [ i ] [ 2 ] pos = start line_type = None while i < len ( tokens ) and tokens [ i ] [ 2 ] [ 0 ] == start [ 0 ] : tok_type = tokens [ i ] [ 0 ] pos = tokens [ i ] [ 3 ] if line_type is None : if tok_type == tokenize . STRING : line_type = "docstring_lines" elif tok_type == tokenize . COMMENT : line_type = "comment_lines" elif tok_type in JUNK : pass else : line_type = "code_lines" i += 1 if line_type is None : line_type = "empty_lines" elif i < len ( tokens ) and tokens [ i ] [ 0 ] == tokenize . NEWLINE : i += 1 return i , pos [ 0 ] - start [ 0 ] + 1 , line_type

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/precond/django-customary/blob/2cf2295d84d3d1bb6c034d4df25e15d814c1eb75/customary/api/__init__.py#L20-L60<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def api_request ( methods = None , require_token = True ) : def decorator ( view_func ) : @ wraps ( view_func , assigned = available_attrs ( view_func ) ) def _wrapped_view ( request , * args , * * kwargs ) : ApiToken = apps . get_model ( 'api' , 'ApiToken' ) m = methods if methods is not None else DEFAULT_API_METHODS if request . method not in m : response = ApiResponse ( False , 'Method not supported' , status = 405 ) response [ 'Allow' ] = ', ' . join ( methods ) return response try : data = json . loads ( request . body . decode ( 'utf-8' ) ) if request . body else { } if require_token : token_string = request . GET [ 'token' ] if request . method == 'GET' else data [ 'token' ] try : token = ApiToken . objects . get ( token = token_string ) token . save ( ) # Update the last_seen field data [ 'token' ] = token except ApiToken . DoesNotExist : logger . exception ( 'Valid token required, "{0}" supplied' . format ( token_string ) ) return ApiResponse ( False , 'Valid token required' , status = 403 ) return ApiResponse ( data = view_func ( request , data = data , * args , * * kwargs ) ) except Exception as e : if e . __class__ . __name__ == 'DoesNotExist' : logger . exception ( 'Not found while handling ajax request' ) return ApiResponse ( False , 'Exception: {0}' . format ( e ) , status = 404 ) else : logger . exception ( 'Error handling ajax request' ) return ApiResponse ( False , 'Exception: {0}' . format ( e ) , status = 500 ) return _wrapped_view return decorator

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/adapter/mongo/hgnc.py#L437-L453<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def id_transcripts_by_gene ( self , build = '37' ) : hgnc_id_transcripts = { } LOG . info ( "Fetching all id transcripts" ) for gene_obj in self . hgnc_collection . find ( { 'build' : build } ) : hgnc_id = gene_obj [ 'hgnc_id' ] id_transcripts = self . get_id_transcripts ( hgnc_id = hgnc_id , build = build ) hgnc_id_transcripts [ hgnc_id ] = id_transcripts return hgnc_id_transcripts

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PolicyStat/docx2html/blob/2dc4afd1e3a3f2f0b357d0bff903eb58bcc94429/docx2html/core.py#L494-L503<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def style_is_false ( style ) : if style is None : return False w_namespace = get_namespace ( style , 'w' ) return style . get ( '%sval' % w_namespace ) != 'false'

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/hdima/erlport/blob/246b7722d62b87b48be66d9a871509a537728962/priv/python3/erlport/erlproto.py#L84-L95<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def read ( self ) : packet = self . packet with self . __read_lock : buffer = self . __buffer while len ( buffer ) < packet : buffer += self . _read_data ( ) length = self . __unpack ( buffer [ : packet ] ) [ 0 ] + packet while len ( buffer ) < length : buffer += self . _read_data ( ) term , self . __buffer = decode ( buffer [ packet : ] ) return term

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/bitlabstudio/django-dashboard-app/blob/ed98f2bca91a4ced36d0dd1aa1baee78e989cf64/dashboard_app/widget_pool.py#L56-L67<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_widgets_that_need_update ( self ) : result = [ ] for widget_name , widget in self . get_widgets ( ) . items ( ) : if widget . should_update ( ) : result . append ( widget ) return result

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/un33k/django-toolware/blob/973f3e003dc38b812897dab88455bee37dcaf931/toolware/utils/generic.py#L141-L145<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_url_args ( url ) : url_data = urllib . parse . urlparse ( url ) arg_dict = urllib . parse . parse_qs ( url_data . query ) return arg_dict

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neherlab/treetime/blob/f6cdb58d19243a18ffdaa2b2ec71872fa00e65c0/treetime/treeanc.py#L809-L819<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _calc_dist2root ( self ) : self . tree . root . dist2root = 0.0 for clade in self . tree . get_nonterminals ( order = 'preorder' ) : # parents first for c in clade . clades : if not hasattr ( c , 'mutation_length' ) : c . mutation_length = c . branch_length c . dist2root = c . up . dist2root + c . mutation_length

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2183-L2211<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def cor ( self , y = None , na_rm = False , use = None ) : assert_is_type ( y , H2OFrame , None ) assert_is_type ( na_rm , bool ) assert_is_type ( use , None , "everything" , "all.obs" , "complete.obs" ) if y is None : y = self if use is None : use = "complete.obs" if na_rm else "everything" if self . nrow == 1 or ( self . ncol == 1 and y . ncol == 1 ) : return ExprNode ( "cor" , self , y , use ) . _eager_scalar ( ) return H2OFrame . _expr ( expr = ExprNode ( "cor" , self , y , use ) ) . _frame ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/distributions/kullback_leibler.py#L34-L47<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _registered_kl ( type_a , type_b ) : hierarchy_a = tf_inspect . getmro ( type_a ) hierarchy_b = tf_inspect . getmro ( type_b ) dist_to_children = None kl_fn = None for mro_to_a , parent_a in enumerate ( hierarchy_a ) : for mro_to_b , parent_b in enumerate ( hierarchy_b ) : candidate_dist = mro_to_a + mro_to_b candidate_kl_fn = _DIVERGENCES . get ( ( parent_a , parent_b ) , None ) if not kl_fn or ( candidate_kl_fn and candidate_dist < dist_to_children ) : dist_to_children = candidate_dist kl_fn = candidate_kl_fn return kl_fn

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/assemblerflow/flowcraft/blob/fc3f4bddded1efc76006600016dc71a06dd908c0/flowcraft/generator/inspect.py#L1467-L1486<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _dag_file_to_dict ( self ) : try : dag_file = open ( os . path . join ( self . workdir , ".treeDag.json" ) ) dag_json = json . load ( dag_file ) except ( FileNotFoundError , json . decoder . JSONDecodeError ) : logger . warning ( colored_print ( "WARNING: dotfile named .treeDag.json not found or corrupted" , "red_bold" ) ) dag_json = { } return dag_json

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/pip/vcs/bazaar.py#L39-L52<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def export ( self , location ) : temp_dir = tempfile . mkdtemp ( '-export' , 'pip-' ) self . unpack ( temp_dir ) if os . path . exists ( location ) : # Remove the location to make sure Bazaar can export it correctly rmtree ( location ) try : self . run_command ( [ 'export' , location ] , cwd = temp_dir , show_stdout = False ) finally : rmtree ( temp_dir )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/quantum_info/operators/channel/transformations.py#L115-L124<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _to_operator ( rep , data , input_dim , output_dim ) : if rep == 'Operator' : return data if rep == 'Stinespring' : return _stinespring_to_operator ( data , input_dim , output_dim ) # Convert via Kraus representation if rep != 'Kraus' : data = _to_kraus ( rep , data , input_dim , output_dim ) return _kraus_to_operator ( data , input_dim , output_dim )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Nic30/hwt/blob/8cbb399e326da3b22c233b98188a9d08dec057e6/hwt/simulator/hdlSimulator.py#L400-L432<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _applyValues ( self ) -> Generator [ None , None , None ] : va = self . _valuesToApply self . _applyValPlaned = False # log if there are items to log lav = self . config . logApplyingValues if va and lav : lav ( self , va ) self . _valuesToApply = [ ] # apply values to signals, values can overwrite each other # but each signal should be driven by only one process and # it should resolve value collision addSp = self . _seqProcsToRun . append for s , vUpdater , isEventDependent , comesFrom in va : if isEventDependent : # now=0 and this was process initialization or async reg addSp ( comesFrom ) else : # regular combinational process s . simUpdateVal ( self , vUpdater ) self . _runCombProcesses ( ) # processes triggered from simUpdateVal can add new values if self . _valuesToApply and not self . _applyValPlaned : self . _scheduleApplyValues ( ) return yield

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Nic30/hwt/blob/8cbb399e326da3b22c233b98188a9d08dec057e6/hwt/synthesizer/interface.py#L260-L265<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _updateParamsFrom ( self , otherObj , updater = _default_param_updater , exclude = None , prefix = "" ) : PropDeclrCollector . _updateParamsFrom ( self , otherObj , updater , exclude , prefix )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/HydraChain/hydrachain/blob/6c0919b0575dc8aa481f3a8c703e1a7f0575ecc3/hydrachain/consensus/base.py#L497-L511<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def validate_votes ( self , validators_H , validators_prevH ) : assert self . sender def check ( lockset , validators ) : if not lockset . num_eligible_votes == len ( validators ) : raise InvalidProposalError ( 'lockset num_eligible_votes mismatch' ) for v in lockset : if v . sender not in validators : raise InvalidProposalError ( 'invalid signer' ) if self . round_lockset : check ( self . round_lockset , validators_H ) check ( self . signing_lockset , validators_prevH ) return True

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Azure/azure-sdk-for-python/blob/d7306fde32f60a293a7567678692bdad31e4b667/azure-servicemanagement-legacy/azure/servicemanagement/_common_error.py#L29-L34<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _general_error_handler ( http_error ) : message = str ( http_error ) if http_error . respbody is not None : message += '\n' + http_error . respbody . decode ( 'utf-8-sig' ) raise AzureHttpError ( message , http_error . status )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/account.py#L279-L296<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def token_validate_with_login ( self , * * kwargs ) : path = self . _get_path ( 'token_validate_with_login' ) response = self . _GET ( path , kwargs ) self . _set_attrs_to_values ( response ) return response

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/kgiusti/pyngus/blob/5392392046989f1bb84ba938c30e4d48311075f1/pyngus/link.py#L878-L884<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _ep_need_close ( self ) : LOG . debug ( "Session %s close requested - closing..." , self . _name ) links = self . _links . copy ( ) # may modify _links for link in links : link . _session_closed ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/boundary/pulse-api-cli/blob/b01ca65b442eed19faac309c9d62bbc3cb2c098f/boundary/webhook_handler.py#L182-L193<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def do_POST ( self ) : self . send_response ( urllib2 . httplib . OK ) self . end_headers ( ) content_length = int ( self . headers [ 'Content-Length' ] ) body = self . rfile . read ( content_length ) print ( "Client: {0}" . format ( str ( self . client_address ) ) ) print ( "headers: {0}" . format ( self . headers ) ) print ( "path: {0}" . format ( self . path ) ) print ( "body: {0}" . format ( body ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mdgoldberg/sportsref/blob/09f11ac856a23c96d666d1d510bb35d6f050b5c3/sportsref/nfl/pbp.py#L56-L358<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse_play_details ( details ) : # if input isn't a string, return None if not isinstance ( details , basestring ) : return None rushOptRE = r'(?P<rushDir>{})' . format ( r'|' . join ( RUSH_OPTS . keys ( ) ) ) passOptRE = r'(?P<passLoc>{})' . format ( r'|' . join ( PASS_OPTS . keys ( ) ) ) playerRE = r"\S{6,8}\d{2}" # initialize return dictionary - struct struct = { } # handle challenges # TODO: record the play both before & after an overturned challenge challengeRE = re . compile ( r'.+\. (?P<challenger>.+?) challenged.*? the play was ' '(?P<callUpheld>upheld|overturned)\.' , re . IGNORECASE ) match = challengeRE . search ( details ) if match : struct [ 'isChallenge' ] = True struct . update ( match . groupdict ( ) ) # if overturned, only record updated play if 'overturned' in details : overturnedIdx = details . index ( 'overturned.' ) newStart = overturnedIdx + len ( 'overturned.' ) details = details [ newStart : ] . strip ( ) else : struct [ 'isChallenge' ] = False # TODO: expand on laterals struct [ 'isLateral' ] = details . find ( 'lateral' ) != - 1 # create rushing regex rusherRE = r"(?P<rusher>{0})" . format ( playerRE ) rushOptRE = r"(?: {})?" . format ( rushOptRE ) rushYardsRE = r"(?:(?:(?P<rushYds>\-?\d+) yards?)|(?:no gain))" # cases: tackle, fumble, td, penalty tackleRE = ( r"(?: \(tackle by (?P<tackler1>{0})" r"(?: and (?P<tackler2>{0}))?\))?" . format ( playerRE ) ) # currently, plays with multiple fumbles record the original fumbler # and the final fumble recoverer fumbleRE = ( r"(?:" r"\.? ?(?P<fumbler>{0}) fumbles" r"(?: \(forced by (?P<fumbForcer>{0})\))?" r"(?:.*, recovered by (?P<fumbRecoverer>{0}) at )?" r"(?:, ball out of bounds at )?" r"(?:(?P<fumbRecFieldSide>[a-z]+)?\-?(?P<fumbRecYdLine>\-?\d+))?" r"(?: and returned for (?P<fumbRetYds>\-?\d*) yards)?" r")?" . format ( playerRE ) ) tdSafetyRE = r"(?:(?P<isTD>, touchdown)|(?P<isSafety>, safety))?" # TODO: offsetting penalties penaltyRE = ( r"(?:.*?" r"\. Penalty on (?P<penOn>{0}|): " r"(?P<penalty>[^\(,]+)" r"(?: \((?P<penDeclined>Declined)\)|" r", (?P<penYds>\d*) yards?)" r"(?: \(no play\))?" r")?" . format ( playerRE ) ) rushREstr = ( r"{}{}(?: for {}{}{}{}{})?" ) . format ( rusherRE , rushOptRE , rushYardsRE , tackleRE , fumbleRE , tdSafetyRE , penaltyRE ) rushRE = re . compile ( rushREstr , re . IGNORECASE ) # create passing regex # TODO: capture "defended by X" for defensive stats passerRE = r"(?P<passer>{0})" . format ( playerRE ) sackRE = ( r"(?:sacked (?:by (?P<sacker1>{0})(?: and (?P<sacker2>{0}))? )?" r"for (?P<sackYds>\-?\d+) yards?)" . format ( playerRE ) ) # create throw RE completeRE = r"pass (?P<isComplete>(?:in)?complete)" passOptRE = r"(?: {})?" . format ( passOptRE ) targetedRE = r"(?: (?:to |intended for )?(?P<target>{0}))?" . format ( playerRE ) passYardsRE = r"(?: for (?:(?P<passYds>\-?\d+) yards?|no gain))" intRE = ( r'(?: is intercepted by (?P<interceptor>{0}) at ' . format ( playerRE ) + r'(?:(?P<intFieldSide>[a-z]*)?\-?(?P<intYdLine>\-?\d*))?' + r'(?: and returned for (?P<intRetYds>\-?\d+) yards?\.?)?)?' ) throwRE = r'(?:{}{}{}(?:(?:{}|{}){})?)' . format ( completeRE , passOptRE , targetedRE , passYardsRE , intRE , tackleRE ) passREstr = ( r"{} (?:{}|{})(?:{}{}{})?" ) . format ( passerRE , sackRE , throwRE , fumbleRE , tdSafetyRE , penaltyRE ) passRE = re . compile ( passREstr , re . IGNORECASE ) # create kickoff regex koKickerRE = r'(?P<koKicker>{0})' . format ( playerRE ) koYardsRE = ( r' kicks (?:off|(?P<isOnside>onside))' r' (?:(?P<koYds>\d+) yards?|no gain)' ) nextREs = [ ] nextREs . append ( ( r', (?:returned|recovered) by (?P<koReturner>{0})(?: for ' r'(?:(?P<koRetYds>\-?\d+) yards?|no gain))?' ) . format ( playerRE ) ) nextREs . append ( ( r'(?P<isMuffedCatch>, muffed catch by )(?P<muffedBy>{0}),' r'(?: recovered by (?P<muffRecoverer>{0}))?' ) . format ( playerRE ) + r'(?: and returned for (?:(?P<muffRetYds>\-?\d+) yards|no gain))?' ) nextREs . append ( r', recovered by (?P<onsideRecoverer>{0})' . format ( playerRE ) ) nextREs . append ( r'(?P<oob>, out of bounds)' ) nextREs . append ( r'(?P<isTouchback>, touchback)' ) # TODO: test the following line to fix a small subset of cases # (ex: muff -> oob) nextRE = '' . join ( r'(?:{})?' . format ( nre ) for nre in nextREs ) kickoffREstr = r'{}{}{}{}{}{}{}' . format ( koKickerRE , koYardsRE , nextRE , tackleRE , fumbleRE , tdSafetyRE , penaltyRE ) kickoffRE = re . compile ( kickoffREstr , re . IGNORECASE ) # create timeout regex timeoutREstr = r'Timeout #(?P<timeoutNum>\d) by (?P<timeoutTeam>.+)' timeoutRE = re . compile ( timeoutREstr , re . IGNORECASE ) # create FG regex fgKickerRE = r'(?P<fgKicker>{0})' . format ( playerRE ) fgBaseRE = ( r' (?P<fgDist>\d+) yard field goal' r' (?P<fgGood>good|no good)' ) fgBlockRE = ( r'(?:, (?P<isBlocked>blocked) by ' r'(?P<fgBlocker>{0}))?' . format ( playerRE ) + r'(?:, recovered by (?P<fgBlockRecoverer>{0}))?' . format ( playerRE ) + r'(?: and returned for (?:(?P<fgBlockRetYds>\-?\d+) yards?|no gain))?' ) fgREstr = r'{}{}{}{}{}' . format ( fgKickerRE , fgBaseRE , fgBlockRE , tdSafetyRE , penaltyRE ) fgRE = re . compile ( fgREstr , re . IGNORECASE ) # create punt regex punterRE = r'.*?(?P<punter>{0})' . format ( playerRE ) puntBlockRE = ( ( r' punts, (?P<isBlocked>blocked) by (?P<puntBlocker>{0})' r'(?:, recovered by (?P<puntBlockRecoverer>{0})' ) . format ( playerRE ) + r'(?: and returned (?:(?P<puntBlockRetYds>\-?\d+) yards|no gain))?)?' ) puntYdsRE = r' punts (?P<puntYds>\d+) yards?' nextREs = [ ] nextREs . append ( r', (?P<isFairCatch>fair catch) by (?P<fairCatcher>{0})' . format ( playerRE ) ) nextREs . append ( r', (?P<oob>out of bounds)' ) nextREs . append ( ( r'(?P<isMuffedCatch>, muffed catch by )(?P<muffedBy>{0}),' r' recovered by (?P<muffRecoverer>{0})' ) . format ( playerRE ) + r' and returned for ' + r'(?:(?P<muffRetYds>\d+) yards|no gain)' ) nextREs . append ( r', returned by (?P<puntReturner>{0}) for ' . format ( playerRE ) + r'(?:(?P<puntRetYds>\-?\d+) yards?|no gain)' ) nextRE = r'(?:{})?' . format ( '|' . join ( nextREs ) ) puntREstr = r'{}(?:{}|{}){}{}{}{}{}' . format ( punterRE , puntBlockRE , puntYdsRE , nextRE , tackleRE , fumbleRE , tdSafetyRE , penaltyRE ) puntRE = re . compile ( puntREstr , re . IGNORECASE ) # create kneel regex kneelREstr = ( r'(?P<kneelQB>{0}) kneels for ' . format ( playerRE ) + r'(?:(?P<kneelYds>\-?\d+) yards?|no gain)' ) kneelRE = re . compile ( kneelREstr , re . IGNORECASE ) # create spike regex spikeREstr = r'(?P<spikeQB>{0}) spiked the ball' . format ( playerRE ) spikeRE = re . compile ( spikeREstr , re . IGNORECASE ) # create XP regex extraPointREstr = ( r'(?:(?P<xpKicker>{0}) kicks)? ?extra point ' r'(?P<xpGood>good|no good)' ) . format ( playerRE ) extraPointRE = re . compile ( extraPointREstr , re . IGNORECASE ) # create 2pt conversion regex twoPointREstr = ( r'Two Point Attempt: (?P<twoPoint>.*?),?\s+conversion\s+' r'(?P<twoPointSuccess>succeeds|fails)' ) twoPointRE = re . compile ( twoPointREstr , re . IGNORECASE ) # create penalty regex psPenaltyREstr = ( r'^Penalty on (?P<penOn>{0}|' . format ( playerRE ) + r'\w{3}): ' + r'(?P<penalty>[^\(,]+)(?: \((?P<penDeclined>Declined)\)|' + r', (?P<penYds>\d*) yards?|' + r'.*?(?: \(no play\)))' ) psPenaltyRE = re . compile ( psPenaltyREstr , re . IGNORECASE ) # try parsing as a kickoff match = kickoffRE . search ( details ) if match : # parse as a kickoff struct [ 'isKickoff' ] = True struct . update ( match . groupdict ( ) ) return struct # try parsing as a timeout match = timeoutRE . search ( details ) if match : # parse as timeout struct [ 'isTimeout' ] = True struct . update ( match . groupdict ( ) ) return struct # try parsing as a field goal match = fgRE . search ( details ) if match : # parse as a field goal struct [ 'isFieldGoal' ] = True struct . update ( match . groupdict ( ) ) return struct # try parsing as a punt match = puntRE . search ( details ) if match : # parse as a punt struct [ 'isPunt' ] = True struct . update ( match . groupdict ( ) ) return struct # try parsing as a kneel match = kneelRE . search ( details ) if match : # parse as a kneel struct [ 'isKneel' ] = True struct . update ( match . groupdict ( ) ) return struct # try parsing as a spike match = spikeRE . search ( details ) if match : # parse as a spike struct [ 'isSpike' ] = True struct . update ( match . groupdict ( ) ) return struct # try parsing as an XP match = extraPointRE . search ( details ) if match : # parse as an XP struct [ 'isXP' ] = True struct . update ( match . groupdict ( ) ) return struct # try parsing as a 2-point conversion match = twoPointRE . search ( details ) if match : # parse as a 2-point conversion struct [ 'isTwoPoint' ] = True struct [ 'twoPointSuccess' ] = match . group ( 'twoPointSuccess' ) realPlay = sportsref . nfl . pbp . parse_play_details ( match . group ( 'twoPoint' ) ) if realPlay : struct . update ( realPlay ) return struct # try parsing as a pass match = passRE . search ( details ) if match : # parse as a pass struct [ 'isPass' ] = True struct . update ( match . groupdict ( ) ) return struct # try parsing as a pre-snap penalty match = psPenaltyRE . search ( details ) if match : # parse as a pre-snap penalty struct [ 'isPresnapPenalty' ] = True struct . update ( match . groupdict ( ) ) return struct # try parsing as a run match = rushRE . search ( details ) if match : # parse as a run struct [ 'isRun' ] = True struct . update ( match . groupdict ( ) ) return struct return None

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ToucanToco/toucan-data-sdk/blob/c3ca874e1b64f4bdcc2edda750a72d45d1561d8a/toucan_data_sdk/utils/postprocess/converter.py#L21-L39<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def convert_datetime_to_str ( df , * , column : str , format : str , new_column : str = None ) : new_column = new_column or column df [ new_column ] = df [ column ] . dt . strftime ( format ) return df

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/vaexio/vaex/blob/a45b672f8287afca2ada8e36b74b604b9b28dd85/packages/vaex-core/vaex/dataframe.py#L5080-L5103<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def export ( self , path , column_names = None , byteorder = "=" , shuffle = False , selection = False , progress = None , virtual = False , sort = None , ascending = True ) : if path . endswith ( '.arrow' ) : self . export_arrow ( path , column_names , byteorder , shuffle , selection , progress = progress , virtual = virtual , sort = sort , ascending = ascending ) elif path . endswith ( '.hdf5' ) : self . export_hdf5 ( path , column_names , byteorder , shuffle , selection , progress = progress , virtual = virtual , sort = sort , ascending = ascending ) elif path . endswith ( '.fits' ) : self . export_fits ( path , column_names , shuffle , selection , progress = progress , virtual = virtual , sort = sort , ascending = ascending ) if path . endswith ( '.parquet' ) : self . export_parquet ( path , column_names , shuffle , selection , progress = progress , virtual = virtual , sort = sort , ascending = ascending )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/power-system-simulation-toolbox/psst/blob/8c116fb7afd183881ecc605e017dffc87cdc49e6/psst/scenarios/reduction.py#L111-L237<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def fast_forward_selection ( scenarios , number_of_reduced_scenarios , probability = None ) : print ( "Running fast forward selection algorithm" ) number_of_scenarios = scenarios . shape [ 1 ] logger . debug ( "Input number of scenarios = %d" , number_of_scenarios ) # if probability is not defined assign equal probability to all scenarios if probability is None : probability = np . array ( [ 1 / number_of_scenarios for i in range ( 0 , number_of_scenarios ) ] ) # initialize z, c and J z = np . array ( [ np . inf for i in range ( 0 , number_of_scenarios ) ] ) c = np . zeros ( ( number_of_scenarios , number_of_scenarios ) ) J = range ( 0 , number_of_scenarios ) # no reduction necessary if number_of_reduced_scenarios >= number_of_scenarios : return ( scenarios , probability , J ) for scenario_k in range ( 0 , number_of_scenarios ) : for scenario_u in range ( 0 , number_of_scenarios ) : c [ scenario_k , scenario_u ] = distance ( scenarios [ : , scenario_k ] , scenarios [ : , scenario_u ] ) for scenario_u in range ( 0 , number_of_scenarios ) : summation = 0 for scenario_k in range ( 0 , number_of_scenarios ) : if scenario_k != scenario_u : summation = summation + probability [ scenario_k ] * c [ scenario_k , scenario_u ] z [ scenario_u ] = summation U = [ np . argmin ( z ) ] for u in U : J . remove ( u ) for _ in range ( 0 , number_of_scenarios - number_of_reduced_scenarios - 1 ) : print ( "Running {}" . format ( _ ) ) for scenario_u in J : for scenario_k in J : lowest_value = np . inf for scenario_number in U : lowest_value = min ( c [ scenario_k , scenario_u ] , c [ scenario_k , scenario_number ] ) c [ scenario_k , scenario_u ] = lowest_value for scenario_u in J : summation = 0 for scenario_k in J : if scenario_k not in U : summation = summation + probability [ scenario_k ] * c [ scenario_k , scenario_u ] z [ scenario_u ] = summation u_i = np . argmin ( [ item if i in J else np . inf for i , item in enumerate ( z ) ] ) J . remove ( u_i ) U . append ( u_i ) reduced_scenario_set = U reduced_probability = [ ] reduced_probability = copy . deepcopy ( probability ) for deleted_scenario_number in J : lowest_value = np . inf # find closest scenario_number for scenario_j in reduced_scenario_set : if c [ deleted_scenario_number , scenario_j ] < lowest_value : closest_scenario_number = scenario_j lowest_value = c [ deleted_scenario_number , scenario_j ] reduced_probability [ closest_scenario_number ] = reduced_probability [ closest_scenario_number ] + reduced_probability [ deleted_scenario_number ] reduced_scenarios = copy . deepcopy ( scenarios [ : , reduced_scenario_set ] ) reduced_probability = reduced_probability [ reduced_scenario_set ] return reduced_scenarios , reduced_probability , reduced_scenario_set

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/pulse/pulse_lib/continuous.py#L37-L47<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def square ( times : np . ndarray , amp : complex , period : float , phase : float = 0 ) -> np . ndarray : x = times / period + phase / np . pi return amp * ( 2 * ( 2 * np . floor ( x ) - np . floor ( 2 * x ) ) + 1 ) . astype ( np . complex_ )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Microsoft/botbuilder-python/blob/274663dd91c811bae6ac4488915ba5880771b0a7/libraries/botframework-connector/azure_bdist_wheel.py#L368-L448<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def egg2dist ( self , egginfo_path , distinfo_path ) : def adios ( p ) : """Appropriately delete directory, file or link.""" if os . path . exists ( p ) and not os . path . islink ( p ) and os . path . isdir ( p ) : shutil . rmtree ( p ) elif os . path . exists ( p ) : os . unlink ( p ) adios ( distinfo_path ) if not os . path . exists ( egginfo_path ) : # There is no egg-info. This is probably because the egg-info # file/directory is not named matching the distribution name used # to name the archive file. Check for this case and report # accordingly. import glob pat = os . path . join ( os . path . dirname ( egginfo_path ) , '*.egg-info' ) possible = glob . glob ( pat ) err = "Egg metadata expected at %s but not found" % ( egginfo_path , ) if possible : alt = os . path . basename ( possible [ 0 ] ) err += " (%s found - possible misnamed archive file?)" % ( alt , ) raise ValueError ( err ) if os . path . isfile ( egginfo_path ) : # .egg-info is a single file pkginfo_path = egginfo_path pkg_info = self . _pkginfo_to_metadata ( egginfo_path , egginfo_path ) os . mkdir ( distinfo_path ) else : # .egg-info is a directory pkginfo_path = os . path . join ( egginfo_path , 'PKG-INFO' ) pkg_info = self . _pkginfo_to_metadata ( egginfo_path , pkginfo_path ) # ignore common egg metadata that is useless to wheel shutil . copytree ( egginfo_path , distinfo_path , ignore = lambda x , y : set ( ( 'PKG-INFO' , 'requires.txt' , 'SOURCES.txt' , 'not-zip-safe' , ) ) ) # delete dependency_links if it is only whitespace dependency_links_path = os . path . join ( distinfo_path , 'dependency_links.txt' ) with open ( dependency_links_path , 'r' ) as dependency_links_file : dependency_links = dependency_links_file . read ( ) . strip ( ) if not dependency_links : adios ( dependency_links_path ) write_pkg_info ( os . path . join ( distinfo_path , 'METADATA' ) , pkg_info ) # XXX deprecated. Still useful for current distribute/setuptools. metadata_path = os . path . join ( distinfo_path , 'METADATA' ) self . add_requirements ( metadata_path ) # XXX intentionally a different path than the PEP. metadata_json_path = os . path . join ( distinfo_path , 'metadata.json' ) pymeta = pkginfo_to_dict ( metadata_path , distribution = self . distribution ) if 'description' in pymeta : description_filename = 'DESCRIPTION.rst' description_text = pymeta . pop ( 'description' ) description_path = os . path . join ( distinfo_path , description_filename ) with open ( description_path , "wb" ) as description_file : description_file . write ( description_text . encode ( 'utf-8' ) ) pymeta [ 'extensions' ] [ 'python.details' ] [ 'document_names' ] [ 'description' ] = description_filename # XXX heuristically copy any LICENSE/LICENSE.txt? license = self . license_file ( ) if license : license_filename = 'LICENSE.txt' shutil . copy ( license , os . path . join ( self . distinfo_dir , license_filename ) ) pymeta [ 'extensions' ] [ 'python.details' ] [ 'document_names' ] [ 'license' ] = license_filename with open ( metadata_json_path , "w" ) as metadata_json : json . dump ( pymeta , metadata_json , sort_keys = True ) adios ( egginfo_path )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/core/debugger.py#L495-L526<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def checkline ( self , filename , lineno ) : ####################################################################### # XXX Hack!  Use python-2.5 compatible code for this call, because with # all of our changes, we've drifted from the pdb api in 2.6.  For now, # changing: # #line = linecache.getline(filename, lineno, self.curframe.f_globals) # to: # line = linecache . getline ( filename , lineno ) # # does the trick.  But in reality, we need to fix this by reconciling # our updates with the new Pdb APIs in Python 2.6. # # End hack.  The rest of this method is copied verbatim from 2.6 pdb.py ####################################################################### if not line : print >> self . stdout , 'End of file' return 0 line = line . strip ( ) # Don't allow setting breakpoint at a blank line if ( not line or ( line [ 0 ] == '#' ) or ( line [ : 3 ] == '"""' ) or line [ : 3 ] == "'''" ) : print >> self . stdout , '*** Blank or comment' return 0 return lineno

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/iotile/typedargs/blob/0a5091a664b9b4d836e091e9ba583e944f438fd8/typedargs/annotate.py#L40-L93<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_help ( func ) : help_text = "" if isinstance ( func , dict ) : name = context_name ( func ) help_text = "\n" + name + "\n\n" doc = inspect . getdoc ( func ) if doc is not None : doc = inspect . cleandoc ( doc ) help_text += doc + '\n' return help_text sig = func . metadata . signature ( ) doc = inspect . getdoc ( func ) if doc is not None : doc = inspect . cleandoc ( doc ) help_text += "\n" + sig + "\n\n" if doc is not None : help_text += doc + '\n' if inspect . isclass ( func ) : func = func . __init__ # If we derived the parameter annotations from a docstring, # don't insert a custom arguments section since it already # exists. if func . metadata . load_from_doc : return help_text help_text += "\nArguments:\n" for key , info in func . metadata . annotated_params . items ( ) : type_name = info . type_name desc = "" if info . desc is not None : desc = info . desc help_text += "  - %s (%s): %s\n" % ( key , type_name , desc ) return help_text

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/rwl/godot/blob/013687c9e8983d2aa2ceebb8a76c5c4f1e37c90f/godot/ui/graph_view_model.py#L405-L418<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def add_cluster ( self , info ) : if not info . initialized : return graph = self . _request_graph ( info . ui . control ) if graph is not None : cluster = Cluster ( ) #root=graph, parent=graph) retval = cluster . edit_traits ( parent = info . ui . control , kind = "livemodal" ) if retval . result : graph . clusters . append ( cluster )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tnkteja/myhelp/blob/fb3a4809d448ad14d5b2e6ddf2e7e89ad52b71cb/virtualEnvironment/lib/python2.7/site-packages/coverage/control.py#L750-L775<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def process_startup ( ) : cps = os . environ . get ( "COVERAGE_PROCESS_START" ) if cps : cov = coverage ( config_file = cps , auto_data = True ) cov . start ( ) cov . _warn_no_data = False cov . _warn_unimported_source = False

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/draios/python-sdc-client/blob/47f83415842048778939b90944f64386a3bcb205/sdcclient/_scanning.py#L455-L472<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def update_policy ( self , policyid , policy_description ) : url = self . url + '/api/scanning/v1/policies/' + policyid data = json . dumps ( policy_description ) res = requests . put ( url , headers = self . hdrs , data = data , verify = self . ssl_verify ) if not self . _checkResponse ( res ) : return [ False , self . lasterr ] return [ True , res . json ( ) ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/IdentityPython/fedoidcmsg/blob/d30107be02521fa6cdfe285da3b6b0cdd153c8cc/src/fedoidcmsg/bundle.py#L92-L105<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_signed_bundle ( self , sign_alg = 'RS256' , iss_list = None ) : data = self . dict ( iss_list ) _jwt = JWT ( self . sign_keys , iss = self . iss , sign_alg = sign_alg ) return _jwt . pack ( { 'bundle' : data } )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/pyca/pyopenssl/blob/1fbe064c50fd030948141d7d630673761525b0d0/src/OpenSSL/SSL.py#L2108-L2121<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def server_random ( self ) : session = _lib . SSL_get_session ( self . _ssl ) if session == _ffi . NULL : return None length = _lib . SSL_get_server_random ( self . _ssl , _ffi . NULL , 0 ) assert length > 0 outp = _no_zero_allocator ( "unsigned char[]" , length ) _lib . SSL_get_server_random ( self . _ssl , outp , length ) return _ffi . buffer ( outp , length ) [ : ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/funilrys/PyFunceble/blob/cdf69cbde120199171f7158e1c33635753e6e2f5/PyFunceble/helpers.py#L581-L603<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def to_yaml ( self , destination , flow_style = False ) : with open ( destination , "w" ) as file : # We open the file we are going to write. # Note: We always overwrite the destination. # We save the current dictionnary into a json format. dump_yaml ( self . main_dictionnary , file , encoding = "utf-8" , allow_unicode = True , indent = 4 , default_flow_style = flow_style , )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/pip/_vendor/cachecontrol/adapter.py#L30-L48<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def send ( self , request , * * kw ) : if request . method == 'GET' : cached_response = self . controller . cached_request ( request ) if cached_response : return self . build_response ( request , cached_response , from_cache = True ) # check for etags and add headers if appropriate request . headers . update ( self . controller . conditional_headers ( request ) ) resp = super ( CacheControlAdapter , self ) . send ( request , * * kw ) return resp

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/susam/ice/blob/532e685c504ea96f9e42833594585159ac1d2068/ice.py#L766-L782<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def response ( self ) : if isinstance ( self . body , bytes ) : out = self . body elif isinstance ( self . body , str ) : out = self . body . encode ( self . charset ) else : out = b'' self . add_header ( 'Content-Type' , self . content_type ) self . add_header ( 'Content-Length' , str ( len ( out ) ) ) self . start ( self . status_line , self . _headers ) return [ out ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chrisnorman7/wxgoodies/blob/0064e4d5784714b90357ebb0bc721395e103349b/wxgoodies/keys.py#L170-L187<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def remove_hotkey ( control , key ) : l = _hotkeys . get ( control , [ ] ) for a in l : key_str , id = a if key_str == key : control . Unbind ( wx . EVT_HOTKEY , id = id ) control . UnregisterHotKey ( id ) l . remove ( a ) if l : _hotkeys [ control ] = l else : del _hotkeys [ control ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ibm-watson-iot/iot-python/blob/195f05adce3fba4ec997017e41e02ebd85c0c4cc/tmp/src/things/things.py#L690-L702<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def deletePhysicalInterface ( self , physicalInterfaceId ) : req = ApiClient . onePhysicalInterfaceUrl % ( self . host , "/draft" , physicalInterfaceId ) resp = requests . delete ( req , auth = self . credentials , verify = self . verify ) if resp . status_code == 204 : self . logger . debug ( "physical interface deleted" ) else : raise ibmiotf . APIException ( resp . status_code , "HTTP error deleting a physical interface" , resp ) return resp

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/solvebio/solvebio-python/blob/b29614643043afd19c1d8074e8f25c6700d51a73/solvebio/resource/task.py#L22-L26<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def child_object ( self ) : from . import types child_klass = types . get ( self . task_type . split ( '.' ) [ 1 ] ) return child_klass . retrieve ( self . task_id , client = self . _client )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/proofit404/service-factory/blob/a09d4e097e5599244564a2a7f0611e58efb4156a/service_factory/validation.py#L34-L40<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def validate_params ( request ) : if 'params' in request : correct_params = isinstance ( request [ 'params' ] , ( list , dict ) ) error = 'Incorrect parameter values' assert correct_params , error

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/quantopian/pgcontents/blob/ed36268b7917332d16868208e1e565742a8753e1/pgcontents/pgmanager.py#L166-L177<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_file_id ( self , path ) : with self . engine . begin ( ) as db : try : file_id = get_file_id ( db , self . user_id , path ) except NoSuchFile : self . no_such_entity ( path ) return file_id

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/lxml/html/__init__.py#L1100-L1113<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _value__get ( self ) : content = self . text or '' if self . tag . startswith ( "{%s}" % XHTML_NAMESPACE ) : serialisation_method = 'xml' else : serialisation_method = 'html' for el in self : # it's rare that we actually get here, so let's not use ''.join() content += etree . tostring ( el , method = serialisation_method , encoding = 'unicode' ) return content

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/urinieto/msaf/blob/9dbb57d77a1310465a65cc40f1641d083ca74385/msaf/algorithms/fmc2d/utils_2dfmc.py#L53-L63<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def json_to_bounds ( segments_json ) : f = open ( segments_json ) segments = json . load ( f ) [ "segments" ] bounds = [ ] for segment in segments : bounds . append ( segment [ "start" ] ) bounds . append ( bounds [ - 1 ] + segments [ - 1 ] [ "duration" ] ) # Add last boundary f . close ( ) return np . asarray ( bounds )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/treycucco/pyebnf/blob/3634ddabbe5d73508bcc20f4a591f86a46634e1d/pyebnf/primitive.py#L64-L68<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def is_empty ( self ) : return all ( isinstance ( c , ParseNode ) and c . is_empty for c in self . children )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jupyter-widgets/jupyterlab-sidecar/blob/8889d09f1a0933e2cbee06d4874f720b075b29e8/setupbase.py#L138-L193<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_cmdclass ( prerelease_cmd = None , package_data_spec = None , data_files_spec = None ) : wrapped = [ prerelease_cmd ] if prerelease_cmd else [ ] if package_data_spec or data_files_spec : wrapped . append ( 'handle_files' ) wrapper = functools . partial ( _wrap_command , wrapped ) handle_files = _get_file_handler ( package_data_spec , data_files_spec ) if 'bdist_egg' in sys . argv : egg = wrapper ( bdist_egg , strict = True ) else : egg = bdist_egg_disabled cmdclass = dict ( build_py = wrapper ( build_py , strict = is_repo ) , bdist_egg = egg , sdist = wrapper ( sdist , strict = True ) , handle_files = handle_files , ) if bdist_wheel : cmdclass [ 'bdist_wheel' ] = wrapper ( bdist_wheel , strict = True ) cmdclass [ 'develop' ] = wrapper ( develop , strict = True ) return cmdclass

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chaoss/grimoirelab-kingarthur/blob/9d6a638bee68d5e5c511f045eeebf06340fd3252/arthur/server.py#L120-L135<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def remove ( self ) : payload = cherrypy . request . json logger . debug ( "Reading tasks to remove..." ) task_ids = { } for task_data in payload [ 'tasks' ] : task_id = task_data [ 'task_id' ] removed = super ( ) . remove_task ( task_id ) task_ids [ task_id ] = removed result = { 'tasks' : task_ids } return result

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/gholt/swiftly/blob/5bcc1c65323b1caf1f85adbefd9fc4988c072149/swiftly/cli/delete.py#L140-L217<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def cli_delete ( context , path , body = None , recursive = False , yes_empty_account = False , yes_delete_account = False , until_empty = False ) : path = path . lstrip ( '/' ) if path else '' if not path : if yes_empty_account : cli_empty_account ( context , yes_empty_account = yes_empty_account , until_empty = until_empty ) if yes_delete_account : with context . client_manager . with_client ( ) as client : status , reason , headers , contents = client . delete_account ( headers = context . headers , query = context . query , cdn = context . cdn , body = body , yes_i_mean_delete_the_account = yes_delete_account ) if status // 100 != 2 : if status == 404 and context . ignore_404 : return raise ReturnCode ( 'deleting account: %s %s' % ( status , reason ) ) elif '/' not in path . rstrip ( '/' ) : path = path . rstrip ( '/' ) if recursive : cli_empty_container ( context , path , until_empty = until_empty ) with context . client_manager . with_client ( ) as client : status , reason , headers , contents = client . delete_container ( path , headers = context . headers , query = context . query , cdn = context . cdn , body = body ) if status // 100 != 2 : if status == 404 and context . ignore_404 : return raise ReturnCode ( 'deleting container %r: %s %s' % ( path , status , reason ) ) else : with context . client_manager . with_client ( ) as client : status , reason , headers , contents = client . delete_object ( * path . split ( '/' , 1 ) , headers = context . headers , query = context . query , cdn = context . cdn , body = body ) if status // 100 != 2 : if status == 404 and context . ignore_404 : return raise ReturnCode ( 'deleting object %r: %s %s' % ( path , status , reason ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/zomux/deepy/blob/090fbad22a08a809b12951cd0d4984f5bd432698/deepy/layers/layer.py#L111-L121<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def belongs_to ( self , block ) : if self . _linked_block : raise SystemError ( "The layer {} has already blonged to {}" . format ( self . name , self . _linked_block . name ) ) self . _linked_block = block block . register_layer ( self ) return self

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/nose/plugins/capture.py#L47-L52<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def configure ( self , options , conf ) : self . conf = conf if not options . capture : self . enabled = False

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/cli_action_loggers.py#L72-L86<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def on_post_execution ( * * kwargs ) : logging . debug ( "Calling callbacks: %s" , __post_exec_callbacks ) for cb in __post_exec_callbacks : try : cb ( * * kwargs ) except Exception : logging . exception ( 'Failed on post-execution callback using %s' , cb )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/CiscoDevNet/webexteamssdk/blob/6fc2cc3557e080ba4b2a380664cb2a0532ae45cd/examples/bot-example-flask.py#L98-L158<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def webex_teams_webhook_events ( ) : if request . method == 'GET' : return ( """<!DOCTYPE html>                    <html lang="en">                        <head>                            <meta charset="UTF-8">                            <title>Webex Teams Bot served via Flask</title>                        </head>                    <body>                    <p>                    <strong>Your Flask web server is up and running!</strong>                    </p>                    <p>                    Here is a nice Cat Fact for you:                    </p>                    <blockquote>{}</blockquote>                    </body>                    </html>                 """ . format ( get_catfact ( ) ) ) elif request . method == 'POST' : """Respond to inbound webhook JSON HTTP POST from Webex Teams.""" # Get the POST data sent from Webex Teams json_data = request . json print ( "\n" ) print ( "WEBHOOK POST RECEIVED:" ) print ( json_data ) print ( "\n" ) # Create a Webhook object from the JSON data webhook_obj = Webhook ( json_data ) # Get the room details room = api . rooms . get ( webhook_obj . data . roomId ) # Get the message details message = api . messages . get ( webhook_obj . data . id ) # Get the sender's details person = api . people . get ( message . personId ) print ( "NEW MESSAGE IN ROOM '{}'" . format ( room . title ) ) print ( "FROM '{}'" . format ( person . displayName ) ) print ( "MESSAGE '{}'\n" . format ( message . text ) ) # This is a VERY IMPORTANT loop prevention control step. # If you respond to all messages...  You will respond to the messages # that the bot posts and thereby create a loop condition. me = api . people . me ( ) if message . personId == me . id : # Message was sent by me (bot); do not respond. return 'OK' else : # Message was sent by someone else; parse message and respond. if "/CAT" in message . text : print ( "FOUND '/CAT'" ) # Get a cat fact cat_fact = get_catfact ( ) print ( "SENDING CAT FACT '{}'" . format ( cat_fact ) ) # Post the fact to the room where the request was received api . messages . create ( room . id , text = cat_fact ) return 'OK'

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/gholt/swiftly/blob/5bcc1c65323b1caf1f85adbefd9fc4988c072149/swiftly/cli/put.py#L394-L412<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _get_manifest_body ( context , prefix , path2info , put_headers ) : if context . static_segments : body = json . dumps ( [ { 'path' : '/' + p , 'size_bytes' : s , 'etag' : e } for p , ( s , e ) in sorted ( six . iteritems ( path2info ) ) ] ) put_headers [ 'content-length' ] = str ( len ( body ) ) context . query [ 'multipart-manifest' ] = 'put' else : body = '' put_headers [ 'content-length' ] = '0' put_headers [ 'x-object-manifest' ] = prefix return body

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jaraco/jaraco.util/blob/f21071c64f165a5cf844db15e39356e1a47f4b02/jaraco/util/exceptions.py#L6-L20<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def throws_exception ( callable , * exceptions ) : with context . ExceptionTrap ( ) : with context . ExceptionTrap ( * exceptions ) as exc : callable ( ) return bool ( exc )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/quantum_info/operators/channel/choi.py#L113-L116<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _bipartite_shape ( self ) : return ( self . _input_dim , self . _output_dim , self . _input_dim , self . _output_dim )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/models/dagrun.py#L95-L111<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def refresh_from_db ( self , session = None ) : DR = DagRun exec_date = func . cast ( self . execution_date , DateTime ) dr = session . query ( DR ) . filter ( DR . dag_id == self . dag_id , func . cast ( DR . execution_date , DateTime ) == exec_date , DR . run_id == self . run_id ) . one ( ) self . id = dr . id self . state = dr . state

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/design_analysis.py#L513-L518<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def visit_while ( self , node ) : branches = 1 if node . orelse : branches += 1 self . _inc_branch ( node , branches )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Chilipp/sphinx-nbexamples/blob/08e0319ff3c70f8a931dfa8890caf48add4d0470/sphinx_nbexamples/__init__.py#L381-L458<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_rst ( self , nb , in_dir , odir ) : raw_rst , resources = nbconvert . export_by_name ( 'rst' , nb ) # remove ipython magics rst_content = '' i0 = 0 m = None # HACK: we insert the bokeh style sheets here as well, since for some # themes (e.g. the sphinx_rtd_theme) it is not sufficient to include # the style sheets only via app.add_stylesheet bokeh_str = '' if 'bokeh' in raw_rst and self . insert_bokeh : bokeh_str += self . BOKEH_TEMPLATE . format ( version = self . insert_bokeh ) if 'bokeh' in raw_rst and self . insert_bokeh_widgets : bokeh_str += self . BOKEH_WIDGETS_TEMPLATE . format ( version = self . insert_bokeh_widgets ) for m in code_blocks . finditer ( raw_rst ) : lines = m . group ( ) . splitlines ( True ) header , content = lines [ 0 ] , '' . join ( lines [ 1 : ] ) no_magics = magic_patt . sub ( '\g<1>' , content ) # if the code cell only contained magic commands, we skip it if no_magics . strip ( ) : rst_content += ( raw_rst [ i0 : m . start ( ) ] + bokeh_str + header + no_magics ) bokeh_str = '' i0 = m . end ( ) else : rst_content += raw_rst [ i0 : m . start ( ) ] i0 = m . end ( ) if m is not None : rst_content += bokeh_str + raw_rst [ m . end ( ) : ] else : rst_content = raw_rst rst_content = '.. _%s:\n\n' % self . reference + rst_content url = self . url if url is not None : rst_content += self . CODE_DOWNLOAD_NBVIEWER . format ( pyfile = os . path . basename ( self . py_file ) , nbfile = os . path . basename ( self . outfile ) , url = url ) else : rst_content += self . CODE_DOWNLOAD . format ( pyfile = os . path . basename ( self . py_file ) , nbfile = os . path . basename ( self . outfile ) ) supplementary_files = self . supplementary_files other_supplementary_files = self . other_supplementary_files if supplementary_files or other_supplementary_files : for f in ( supplementary_files or [ ] ) + ( other_supplementary_files or [ ] ) : if not os . path . exists ( os . path . join ( odir , f ) ) : copyfile ( os . path . join ( in_dir , f ) , os . path . join ( odir , f ) ) if supplementary_files : rst_content += self . data_download ( supplementary_files ) rst_file = self . get_out_file ( ) outputs = sorted ( resources [ 'outputs' ] , key = rst_content . find ) base = os . path . join ( 'images' , os . path . splitext ( os . path . basename ( self . infile ) ) [ 0 ] + '_%i.png' ) out_map = { os . path . basename ( original ) : base % i for i , original in enumerate ( outputs ) } for original , final in six . iteritems ( out_map ) : rst_content = rst_content . replace ( original , final ) with open ( rst_file , 'w' ) as f : f . write ( rst_content . rstrip ( ) + '\n' ) pictures = [ ] for original in outputs : fname = os . path . join ( odir , out_map [ os . path . basename ( original ) ] ) pictures . append ( fname ) if six . PY3 : f = open ( fname , 'w+b' ) else : f = open ( fname , 'w' ) f . write ( resources [ 'outputs' ] [ original ] ) f . close ( ) self . pictures = pictures

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mrtazz/notifo.py/blob/26079db3b40c26661155af20a9f16a0eca06dbde/notifo/notifo.py#L25-L31<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def subscribe_user ( self , user ) : url = self . root_url + "subscribe_user" values = { } values [ "username" ] = user return self . _query ( url , values )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L2675-L2700<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def pivot ( self , index , column , value ) : assert_is_type ( index , str ) assert_is_type ( column , str ) assert_is_type ( value , str ) col_names = self . names if index not in col_names : raise H2OValueError ( "Index not in H2OFrame" ) if column not in col_names : raise H2OValueError ( "Column not in H2OFrame" ) if value not in col_names : raise H2OValueError ( "Value column not in H2OFrame" ) if self . type ( column ) not in [ "enum" , "time" , "int" ] : raise H2OValueError ( "'column' argument is not type enum, time or int" ) if self . type ( index ) not in [ "enum" , "time" , "int" ] : raise H2OValueError ( "'index' argument is not type enum, time or int" ) return H2OFrame . _expr ( expr = ExprNode ( "pivot" , self , index , column , value ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neurosynth/neurosynth/blob/948ce7edce15d7df693446e76834e0c23bfe8f11/neurosynth/analysis/decode.py#L123-L152<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def load_features ( self , features , image_type = None , from_array = False , threshold = 0.001 ) : if from_array : if isinstance ( features , list ) : features = features [ 0 ] self . _load_features_from_array ( features ) elif path . exists ( features [ 0 ] ) : self . _load_features_from_images ( features ) else : self . _load_features_from_dataset ( features , image_type = image_type , threshold = threshold )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SectorLabs/django-postgres-extra/blob/eef2ed5504d225858d4e4f5d77a838082ca6053e/psqlextra/backend/hstore_required.py#L151-L161<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _drop_hstore_required ( self , table_name , field , key ) : name = self . _required_constraint_name ( table_name , field , key ) sql = self . sql_hstore_required_drop . format ( table = self . quote_name ( table_name ) , name = self . quote_name ( name ) ) self . execute ( sql )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SectorLabs/django-postgres-extra/blob/eef2ed5504d225858d4e4f5d77a838082ca6053e/psqlextra/indexes/conditional_unique_index.py#L41-L45<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def deconstruct ( self ) : path = '%s.%s' % ( self . __class__ . __module__ , self . __class__ . __name__ ) path = path . replace ( 'django.db.models.indexes' , 'django.db.models' ) return path , ( ) , { 'fields' : self . fields , 'name' : self . name , 'condition' : self . condition }

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/piface/pifacecommon/blob/006bca14c18d43ba2d9eafaa84ef83b512c51cf6/pifacecommon/interrupts.py#L255-L306<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def watch_port_events ( port , chip , pin_function_maps , event_queue , return_after_kbdint = False ) : # set up epoll gpio25 = open ( GPIO_INTERRUPT_DEVICE_VALUE , 'r' ) # change to use 'with'? epoll = select . epoll ( ) epoll . register ( gpio25 , select . EPOLLIN | select . EPOLLET ) while True : # wait here until input try : events = epoll . poll ( ) except KeyboardInterrupt as e : if return_after_kbdint : return else : raise e except IOError as e : # ignore "Interrupted system call" error. # I don't really like this solution. Ignoring problems is bad! if e . errno != errno . EINTR : raise # find out where the interrupt came from and put it on the event queue if port == pifacecommon . mcp23s17 . GPIOA : interrupt_flag = chip . intfa . value else : interrupt_flag = chip . intfb . value if interrupt_flag == 0 : continue # The interrupt has not been flagged on this board else : if port == pifacecommon . mcp23s17 . GPIOA : interrupt_capture = chip . intcapa . value else : interrupt_capture = chip . intcapb . value event_queue . add_event ( InterruptEvent ( interrupt_flag , interrupt_capture , chip , time . time ( ) ) ) epoll . close ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/UCBerkeleySETI/blimpy/blob/b8822d3e3e911944370d84371a91fa0c29e9772e/blimpy/guppi.py#L105-L164<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def read_header ( self ) : start_idx = self . file_obj . tell ( ) key , val = '' , '' header_dict = { } keep_reading = True first_line = self . file_obj try : while keep_reading : if start_idx + 80 > self . filesize : keep_reading = False raise EndOfFileError ( "End Of Data File" ) line = self . file_obj . read ( 80 ) if PYTHON3 : line = line . decode ( "utf-8" ) # print line if line . startswith ( 'END' ) : keep_reading = False break else : key , val = line . split ( '=' ) key , val = key . strip ( ) , val . strip ( ) if "'" in val : # Items in quotes are strings val = str ( val . strip ( "'" ) . strip ( ) ) elif "." in val : # Items with periods are floats (if not a string) val = float ( val ) else : # Otherwise it's an integer val = int ( val ) header_dict [ key ] = val except ValueError : print ( "CURRENT LINE: " , line ) print ( "BLOCK START IDX: " , start_idx ) print ( "FILE SIZE: " , self . filesize ) print ( "NEXT 512 BYTES: \n" ) print ( self . file_obj . read ( 512 ) ) raise data_idx = self . file_obj . tell ( ) # Seek past padding if DIRECTIO is being used if "DIRECTIO" in header_dict . keys ( ) : if int ( header_dict [ "DIRECTIO" ] ) == 1 : if data_idx % 512 : data_idx += ( 512 - data_idx % 512 ) self . file_obj . seek ( start_idx ) return header_dict , data_idx

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/pyca/pyopenssl/blob/1fbe064c50fd030948141d7d630673761525b0d0/src/OpenSSL/_util.py#L34-L54<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def exception_from_error_queue ( exception_type ) : errors = [ ] while True : error = lib . ERR_get_error ( ) if error == 0 : break errors . append ( ( text ( lib . ERR_lib_error_string ( error ) ) , text ( lib . ERR_func_error_string ( error ) ) , text ( lib . ERR_reason_error_string ( error ) ) ) ) raise exception_type ( errors )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/agabrown/PyGaia/blob/ae972b0622a15f713ffae471f925eac25ccdae47/pygaia/errors/astrometric.py#L286-L312<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def positionError ( G , vmini , beta , extension = 0.0 ) : parallaxError = parallaxErrorSkyAvg ( G , vmini , extension = extension ) return errorScalingFactor ( 'alphaStar' , beta ) * parallaxError , errorScalingFactor ( 'delta' , beta ) * parallaxError

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/a-tal/nagaram/blob/2edcb0ef8cb569ebd1c398be826472b4831d6110/nagaram/anagrams.py#L7-L23<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _letter_map ( word ) : lmap = { } for letter in word : try : lmap [ letter ] += 1 except KeyError : lmap [ letter ] = 1 return lmap

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mdgoldberg/sportsref/blob/09f11ac856a23c96d666d1d510bb35d6f050b5c3/sportsref/nba/seasons.py#L44-L50<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_main_doc ( self ) : url = ( sportsref . nba . BASE_URL + '/leagues/NBA_{}.html' . format ( self . yr ) ) return pq ( sportsref . utils . get_html ( url ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/sts/internal/util.py#L32-L49<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def broadcast_batch_shape ( distributions ) : # Static case batch_shape = distributions [ 0 ] . batch_shape for distribution in distributions : batch_shape = tf . broadcast_static_shape ( batch_shape , distribution . batch_shape ) if batch_shape . is_fully_defined ( ) : return batch_shape . as_list ( ) # Fallback on dynamic. batch_shape = distributions [ 0 ] . batch_shape_tensor ( ) for distribution in distributions : batch_shape = tf . broadcast_dynamic_shape ( batch_shape , distribution . batch_shape_tensor ( ) ) return tf . convert_to_tensor ( value = batch_shape )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L858-L866<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_frame ( frame_id , * * kwargs ) : assert_is_type ( frame_id , str ) return H2OFrame . get_frame ( frame_id , * * kwargs )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/reingart/gui2py/blob/aca0a05f6fcde55c94ad7cc058671a06608b01a4/gui/controls/canvas.py#L225-L238<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def draw_arc ( self , x1y1 , x2y2 , xcyc ) : self . _buf_image . DrawArcPoint ( x1y1 , x2y2 , xcyc ) if self . auto_refresh : dc = wx . ClientDC ( self . wx_obj ) dc . BlitPointSize ( ( 0 , 0 ) , ( self . _size [ 0 ] , self . _size [ 1 ] ) , self . _buf_image , ( 0 , 0 ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tmontaigu/pylas/blob/8335a1a7d7677f0e4bc391bb6fa3c75b42ed5b06/pylas/extradims.py#L111-L130<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_id_for_extra_dim_type ( type_str ) : try : return _type_to_extra_dim_id_style_1 [ type_str ] except KeyError : try : return _type_to_extra_dim_id_style_2 [ type_str ] except KeyError : raise errors . UnknownExtraType ( type_str )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Azure/azure-sdk-for-python/blob/d7306fde32f60a293a7567678692bdad31e4b667/azure-servicebus/azure/servicebus/control_client/_common_serialization.py#L156-L166<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse_response ( response , return_type ) : root = ETree . fromstring ( response . body ) xml_name = getattr ( return_type , '_xml_name' , return_type . __name__ ) if root . tag == xml_name : return _ETreeXmlToObject . _parse_response_body_from_xml_node ( root , return_type ) return None

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/avelino/bottle-auth/blob/db07e526864aeac05ee68444b47e5db29540ce18/bottle_auth/core/escape.py#L188-L200<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def to_basestring ( value ) : if isinstance ( value , _BASESTRING_TYPES ) : return value assert isinstance ( value , bytes ) return value . decode ( "utf-8" )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/synw/gencharts/blob/fa35604a9445b399bb4f91bc91af488e8e8208fd/gencharts/__init__.py#L134-L153<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _write_file ( self , slug , folderpath , html ) : # check directories if not os . path . isdir ( folderpath ) : try : os . makedirs ( folderpath ) except Exception as e : tr . err ( e ) # construct file path filepath = folderpath + "/" + slug + ".html" #~ write the file try : filex = open ( filepath , "w" ) filex . write ( html ) filex . close ( ) except Exception as e : tr . err ( e )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/susam/ice/blob/532e685c504ea96f9e42833594585159ac1d2068/ice.py#L108-L117<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def run ( self , host = '127.0.0.1' , port = 8080 ) : from wsgiref import simple_server self . _server = simple_server . make_server ( host , port , self ) self . _server . serve_forever ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/config/application.py#L443-L460<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def load_config_file ( self , filename , path = None ) : loader = PyFileConfigLoader ( filename , path = path ) try : config = loader . load_config ( ) except ConfigFileNotFound : # problem finding the file, raise raise except Exception : # try to get the full filename, but it will be empty in the # unlikely event that the error raised before filefind finished filename = loader . full_filename or filename # problem while running the file self . log . error ( "Exception while loading config file %s" , filename , exc_info = True ) else : self . log . debug ( "Loaded config file: %s" , loader . full_filename ) self . update_config ( config )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/layers/util.py#L119-L193<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def default_mean_field_normal_fn ( is_singular = False , loc_initializer = tf . compat . v1 . initializers . random_normal ( stddev = 0.1 ) , untransformed_scale_initializer = tf . compat . v1 . initializers . random_normal ( mean = - 3. , stddev = 0.1 ) , loc_regularizer = None , untransformed_scale_regularizer = None , loc_constraint = None , untransformed_scale_constraint = None ) : loc_scale_fn = default_loc_scale_fn ( is_singular = is_singular , loc_initializer = loc_initializer , untransformed_scale_initializer = untransformed_scale_initializer , loc_regularizer = loc_regularizer , untransformed_scale_regularizer = untransformed_scale_regularizer , loc_constraint = loc_constraint , untransformed_scale_constraint = untransformed_scale_constraint ) def _fn ( dtype , shape , name , trainable , add_variable_fn ) : """Creates multivariate `Deterministic` or `Normal` distribution.      Args:       dtype: Type of parameter's event.       shape: Python `list`-like representing the parameter's event shape.       name: Python `str` name prepended to any created (or existing)         `tf.Variable`s.       trainable: Python `bool` indicating all created `tf.Variable`s should be         added to the graph collection `GraphKeys.TRAINABLE_VARIABLES`.       add_variable_fn: `tf.get_variable`-like `callable` used to create (or         access existing) `tf.Variable`s.      Returns:       Multivariate `Deterministic` or `Normal` distribution.     """ loc , scale = loc_scale_fn ( dtype , shape , name , trainable , add_variable_fn ) if scale is None : dist = tfd . Deterministic ( loc = loc ) else : dist = tfd . Normal ( loc = loc , scale = scale ) batch_ndims = tf . size ( input = dist . batch_shape_tensor ( ) ) return tfd . Independent ( dist , reinterpreted_batch_ndims = batch_ndims ) return _fn

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/log/s3_task_handler.py#L146-L170<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def s3_write ( self , log , remote_log_location , append = True ) : if append and self . s3_log_exists ( remote_log_location ) : old_log = self . s3_read ( remote_log_location ) log = '\n' . join ( [ old_log , log ] ) if old_log else log try : self . hook . load_string ( log , key = remote_log_location , replace = True , encrypt = configuration . conf . getboolean ( 'core' , 'ENCRYPT_S3_LOGS' ) , ) except Exception : self . log . exception ( 'Could not write logs to %s' , remote_log_location )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/not-na/peng3d/blob/1151be665b26cc8a479f6307086ba919e4d32d85/peng3d/gui/__init__.py#L68-L84<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def changeSubMenu ( self , submenu ) : if submenu not in self . submenus : raise ValueError ( "Submenu %s does not exist!" % submenu ) elif submenu == self . activeSubMenu : return # Ignore double submenu activation to prevent bugs in submenu initializer old = self . activeSubMenu self . activeSubMenu = submenu if old is not None : self . submenus [ old ] . on_exit ( submenu ) self . submenus [ old ] . doAction ( "exit" ) self . submenu . on_enter ( old ) self . submenu . doAction ( "enter" )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/funilrys/PyFunceble/blob/cdf69cbde120199171f7158e1c33635753e6e2f5/PyFunceble/__init__.py#L312-L337<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def is_subdomain ( domain ) : # pragma: no cover if domain and isinstance ( domain , str ) : # * The given domain is not empty nor None. # and # * The given domain is a string. # We silently load the configuration. load_config ( True ) return Check ( domain ) . is_subdomain ( ) # We return None, there is nothing to check. return None

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/imap_hook.py#L49-L66<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def has_mail_attachment ( self , name , mail_folder = 'INBOX' , check_regex = False ) : mail_attachments = self . _retrieve_mails_attachments_by_name ( name , mail_folder , check_regex , latest_only = True ) return len ( mail_attachments ) > 0

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chrisrink10/basilisp/blob/3d82670ee218ec64eb066289c82766d14d18cc92/src/basilisp/lang/compiler/generator.py#L2356-L2364<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _collection_literal_to_py_ast ( ctx : GeneratorContext , form : Iterable [ LispForm ] ) -> Iterable [ GeneratedPyAST ] : yield from map ( partial ( _const_val_to_py_ast , ctx ) , form )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/config/configurable.py#L263-L273<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _walk_mro ( cls ) : for subclass in cls . mro ( ) : if issubclass ( cls , subclass ) and issubclass ( subclass , SingletonConfigurable ) and subclass != SingletonConfigurable : yield subclass

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/mcmc/sample_halton_sequence.py#L252-L266<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _randomize ( coeffs , radixes , seed = None ) : given_dtype = coeffs . dtype coeffs = tf . cast ( coeffs , dtype = tf . int32 ) num_coeffs = tf . shape ( input = coeffs ) [ - 1 ] radixes = tf . reshape ( tf . cast ( radixes , dtype = tf . int32 ) , shape = [ - 1 ] ) stream = distributions . SeedStream ( seed , salt = 'MCMCSampleHaltonSequence2' ) perms = _get_permutations ( num_coeffs , radixes , seed = stream ( ) ) perms = tf . reshape ( perms , shape = [ - 1 ] ) radix_sum = tf . reduce_sum ( input_tensor = radixes ) radix_offsets = tf . reshape ( tf . cumsum ( radixes , exclusive = True ) , shape = [ - 1 , 1 ] ) offsets = radix_offsets + tf . range ( num_coeffs ) * radix_sum permuted_coeffs = tf . gather ( perms , coeffs + offsets ) return tf . cast ( permuted_coeffs , dtype = given_dtype )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/skioo/django-datatrans-gateway/blob/1c4de5b589403e4ec3aadc4ff2fc1eb17b34bcc7/datatrans/gateway/payment_parameters.py#L40-L66<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def build_register_credit_card_parameters ( client_ref : str ) -> PaymentParameters : amount = 0 currency = 'CHF' # Datatrans requires this value to be filled, so we use this arbitrary currency. merchant_id = web_merchant_id refno = client_ref sign = sign_web ( merchant_id , amount , currency , refno ) parameters = PaymentParameters ( merchant_id = merchant_id , amount = amount , currency = currency , refno = refno , sign = sign , use_alias = True , ) logger . info ( 'building-payment-parameters' , parameters = parameters ) return parameters

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/librosa/librosa/blob/180e8e6eb8f958fa6b20b8cba389f7945d508247/librosa/filters.py#L794-L856<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_window ( window , Nx , fftbins = True ) : if six . callable ( window ) : return window ( Nx ) elif ( isinstance ( window , ( six . string_types , tuple ) ) or np . isscalar ( window ) ) : # TODO: if we add custom window functions in librosa, call them here return scipy . signal . get_window ( window , Nx , fftbins = fftbins ) elif isinstance ( window , ( np . ndarray , list ) ) : if len ( window ) == Nx : return np . asarray ( window ) raise ParameterError ( 'Window size mismatch: ' '{:d} != {:d}' . format ( len ( window ) , Nx ) ) else : raise ParameterError ( 'Invalid window specification: {}' . format ( window ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/gnosis/gnosis-py/blob/2a9a5d75a375fc9813ac04df133e6910c82f9d49/gnosis/safe/safe_creation_tx.py#L290-L300<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _sign_web3_transaction ( tx : Dict [ str , any ] , v : int , r : int , s : int ) -> ( bytes , HexBytes ) : unsigned_transaction = serializable_unsigned_transaction_from_dict ( tx ) rlp_encoded_transaction = encode_transaction ( unsigned_transaction , vrs = ( v , r , s ) ) # To get the address signing, just do ecrecover_to_pub(unsigned_transaction.hash(), v, r, s) return rlp_encoded_transaction , unsigned_transaction . hash ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tnkteja/myhelp/blob/fb3a4809d448ad14d5b2e6ddf2e7e89ad52b71cb/virtualEnvironment/lib/python2.7/site-packages/coverage/xmlreport.py#L25-L93<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def report ( self , morfs , outfile = None ) : # Initial setup. outfile = outfile or sys . stdout # Create the DOM that will store the data. impl = xml . dom . minidom . getDOMImplementation ( ) docType = impl . createDocumentType ( "coverage" , None , "http://cobertura.sourceforge.net/xml/coverage-03.dtd" ) self . xml_out = impl . createDocument ( None , "coverage" , docType ) # Write header stuff. xcoverage = self . xml_out . documentElement xcoverage . setAttribute ( "version" , __version__ ) xcoverage . setAttribute ( "timestamp" , str ( int ( time . time ( ) * 1000 ) ) ) xcoverage . appendChild ( self . xml_out . createComment ( " Generated by coverage.py: %s " % __url__ ) ) xpackages = self . xml_out . createElement ( "packages" ) xcoverage . appendChild ( xpackages ) # Call xml_file for each file in the data. self . packages = { } self . report_files ( self . xml_file , morfs ) lnum_tot , lhits_tot = 0 , 0 bnum_tot , bhits_tot = 0 , 0 # Populate the XML DOM with the package info. for pkg_name in sorted ( self . packages . keys ( ) ) : pkg_data = self . packages [ pkg_name ] class_elts , lhits , lnum , bhits , bnum = pkg_data xpackage = self . xml_out . createElement ( "package" ) xpackages . appendChild ( xpackage ) xclasses = self . xml_out . createElement ( "classes" ) xpackage . appendChild ( xclasses ) for class_name in sorted ( class_elts . keys ( ) ) : xclasses . appendChild ( class_elts [ class_name ] ) xpackage . setAttribute ( "name" , pkg_name . replace ( os . sep , '.' ) ) xpackage . setAttribute ( "line-rate" , rate ( lhits , lnum ) ) xpackage . setAttribute ( "branch-rate" , rate ( bhits , bnum ) ) xpackage . setAttribute ( "complexity" , "0" ) lnum_tot += lnum lhits_tot += lhits bnum_tot += bnum bhits_tot += bhits xcoverage . setAttribute ( "line-rate" , rate ( lhits_tot , lnum_tot ) ) xcoverage . setAttribute ( "branch-rate" , rate ( bhits_tot , bnum_tot ) ) # Use the DOM to write the output file. outfile . write ( self . xml_out . toprettyxml ( ) ) # Return the total percentage. denom = lnum_tot + bnum_tot if denom == 0 : pct = 0.0 else : pct = 100.0 * ( lhits_tot + bhits_tot ) / denom return pct

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/lsst-sqre/ltd-conveyor/blob/c492937c4c1e050ccc4a0b9dcc38f9980d57e305/ltdconveyor/s3/upload.py#L356-L407<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def list_dirnames_in_directory ( self , dirname ) : prefix = self . _create_prefix ( dirname ) dirnames = [ ] for obj in self . _bucket . objects . filter ( Prefix = prefix ) : # get directory name of every object under this path prefix dirname = os . path . dirname ( obj . key ) # dirname is empty if the object happens to be the directory # redirect object object for the prefix directory (directory # redirect objects are named after directories and have metadata # that tells Fastly to redirect the browser to the index.html # contained in the directory). if dirname == '' : dirname = obj . key + '/' # Strip out the path prefix from the directory name rel_dirname = os . path . relpath ( dirname , start = prefix ) # If there's only one part then this directory is at the root # relative to the prefix. We want this. dir_parts = rel_dirname . split ( '/' ) if len ( dir_parts ) == 1 : dirnames . append ( dir_parts [ 0 ] ) # Above algorithm finds root directories for all *files* in sub # subdirectories; trim down to the unique set. dirnames = list ( set ( dirnames ) ) # Remove posix-like relative directory names that can appear # in the bucket listing. for filtered_dir in ( '.' , '..' ) : if filtered_dir in dirnames : dirnames . remove ( filtered_dir ) return dirnames

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/edx/web-fragments/blob/42d760d700d70465e4e573b7b41442d8802ccd3c/web_fragments/fragment.py#L124-L138<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def add_resource_url ( self , url , mimetype , placement = None ) : if not placement : placement = self . _default_placement ( mimetype ) self . _resources . append ( FragmentResource ( 'url' , url , mimetype , placement ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/pydron/anycall/blob/43add96660258a14b24aa8e8413dffb1741b72d7/anycall/bytequeue.py#L32-L63<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def dequeue ( self , n ) : if self . _len < n : raise ValueError ( "Not enough bytes in the queue" ) self . _len -= n def part_generator ( n ) : """             Returns the requested bytes in parts             """ remaining = n while remaining : part = self . _parts . popleft ( ) if len ( part ) <= remaining : yield part remaining -= len ( part ) else : yield part [ : remaining ] self . _parts . appendleft ( part [ remaining : ] ) remaining = 0 return "" . join ( part_generator ( n ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mseclab/PyJFuzz/blob/f777067076f62c9ab74ffea6e90fd54402b7a1b4/pyjfuzz/core/pjf_server.py#L104-L114<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def run ( self ) : route ( "/" ) ( self . serve ) if self . config . html : route ( "/<filepath:path>" ) ( self . custom_html ) if self . config . fuzz_web : self . request_checker . start ( ) self . httpd . start ( ) self . httpsd . start ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/qasm/node/prefix.py#L36-L40<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def real ( self , nested_scope = None ) : operation = self . children [ 0 ] . operation ( ) expr = self . children [ 1 ] . real ( nested_scope ) return operation ( expr )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/lepture/flask-oauthlib/blob/9e6f152a5bb360e7496210da21561c3e6d41b0e1/flask_oauthlib/provider/oauth2.py#L479-L515<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def confirm_authorization_request ( self ) : server = self . server scope = request . values . get ( 'scope' ) or '' scopes = scope . split ( ) credentials = dict ( client_id = request . values . get ( 'client_id' ) , redirect_uri = request . values . get ( 'redirect_uri' , None ) , response_type = request . values . get ( 'response_type' , None ) , state = request . values . get ( 'state' , None ) ) log . debug ( 'Fetched credentials from request %r.' , credentials ) redirect_uri = credentials . get ( 'redirect_uri' ) log . debug ( 'Found redirect_uri %s.' , redirect_uri ) uri , http_method , body , headers = extract_params ( ) try : ret = server . create_authorization_response ( uri , http_method , body , headers , scopes , credentials ) log . debug ( 'Authorization successful.' ) return create_response ( * ret ) except oauth2 . FatalClientError as e : log . debug ( 'Fatal client error %r' , e , exc_info = True ) return self . _on_exception ( e , e . in_uri ( self . error_uri ) ) except oauth2 . OAuth2Error as e : log . debug ( 'OAuth2Error: %r' , e , exc_info = True ) # on auth error, we should preserve state if it's present according to RFC 6749 state = request . values . get ( 'state' ) if state and not e . state : e . state = state # set e.state so e.in_uri() can add the state query parameter to redirect uri return self . _on_exception ( e , e . in_uri ( redirect_uri or self . error_uri ) ) except Exception as e : log . exception ( e ) return self . _on_exception ( e , add_params_to_uri ( self . error_uri , { 'error' : str ( e ) } ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/distribute-0.6.31-py2.7.egg/pkg_resources.py#L520-L547<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def add ( self , dist , entry = None , insert = True , replace = False ) : if insert : dist . insert_on ( self . entries , entry ) if entry is None : entry = dist . location keys = self . entry_keys . setdefault ( entry , [ ] ) keys2 = self . entry_keys . setdefault ( dist . location , [ ] ) if not replace and dist . key in self . by_key : return # ignore hidden distros self . by_key [ dist . key ] = dist if dist . key not in keys : keys . append ( dist . key ) if dist . key not in keys2 : keys2 . append ( dist . key ) self . _added_new ( dist )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/marrabld/planarradpy/blob/5095d1cb98d4f67a7c3108c9282f2d59253e89a8/gui/gui_mainLayout.py#L630-L636<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def display_error_message ( self ) : self . ui . error_label . setScaledContents ( True ) # Warning image shown. self . ui . error_text_label . show ( ) # Warning message shown. self . ui . error_text_label . setStyleSheet ( 'color: red' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/rocky/python3-trepan/blob/14e91bc0acce090d67be145b1ac040cab92ac5f3/trepan/lib/stack.py#L282-L293<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def print_stack_trace ( proc_obj , count = None , color = 'plain' , opts = { } ) : if count is None : n = len ( proc_obj . stack ) else : n = min ( len ( proc_obj . stack ) , count ) try : for i in range ( n ) : print_stack_entry ( proc_obj , i , color = color , opts = opts ) except KeyboardInterrupt : pass return

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/LudovicRousseau/PyKCS11/blob/76ccd8741af2ea193aaf1ca29dfedfa412c134fe/PyKCS11/__init__.py#L1022-L1057<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def sign ( self , key , data , mecha = MechanismRSAPKCS1 ) : m = mecha . to_native ( ) signature = ckbytelist ( ) data1 = ckbytelist ( data ) rv = self . lib . C_SignInit ( self . session , m , key ) if rv != CKR_OK : raise PyKCS11Error ( rv ) # first call get signature size rv = self . lib . C_Sign ( self . session , data1 , signature ) if rv != CKR_OK : raise PyKCS11Error ( rv ) # second call get actual signature data rv = self . lib . C_Sign ( self . session , data1 , signature ) if rv != CKR_OK : raise PyKCS11Error ( rv ) return signature

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chrisrink10/basilisp/blob/3d82670ee218ec64eb066289c82766d14d18cc92/src/basilisp/importer.py#L35-L43<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _basilisp_bytecode ( mtime : int , source_size : int , code : List [ types . CodeType ] ) -> bytes : data = bytearray ( MAGIC_NUMBER ) data . extend ( _w_long ( mtime ) ) data . extend ( _w_long ( source_size ) ) data . extend ( marshal . dumps ( code ) ) # type: ignore return data

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jazzband/django-ddp/blob/1e1954b06fe140346acea43582515991685e4e01/dddp/__init__.py#L69-L81<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def as_dict ( self , * * kwargs ) : error , reason , details , err_kwargs = self . args result = { key : val for key , val in { 'error' : error , 'reason' : reason , 'details' : details , } . items ( ) if val is not None } result . update ( err_kwargs ) result . update ( kwargs ) return result

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/funilrys/PyFunceble/blob/cdf69cbde120199171f7158e1c33635753e6e2f5/PyFunceble/database.py#L758-L787<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def is_in_database ( self ) : if ( self . _authorization ( ) and PyFunceble . INTERN [ "file_to_test" ] in PyFunceble . INTERN [ "whois_db" ] and PyFunceble . INTERN [ "to_test" ] in PyFunceble . INTERN [ "whois_db" ] [ PyFunceble . INTERN [ "file_to_test" ] ] ) : # * We are authorized to work. # and # * The given file path exist in the database. # and # * The element we are testing is in the database related to the # given file path. # We return True, the element we are testing is into the database. return True # * We are not authorized to work. # or # * The given file path does not exist in the database. # or # * The element we are testing is not in the database related to the # given file path. # We return False,the element we are testing is not into the database. return False

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Toblerity/rtree/blob/5d33357c8e88f1a8344415dc15a7d2440211b281/rtree/index.py#L1348-L1351<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def destroy ( self , context , returnError ) : returnError . contents . value = self . IllegalStateError raise NotImplementedError ( "You must override this method." )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jp74/django-model-publisher/blob/075886b866c9b2232fd7267937c4d7571e251780/publisher/management/commands/publish_model.py#L44-L56<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_model ( self , model_name ) : klass = None try : module_name , class_name = model_name . rsplit ( '.' , 1 ) mod = __import__ ( module_name , fromlist = [ class_name ] ) klass = getattr ( mod , class_name ) except ImportError , e : self . error ( 'Cannot find app %s %s' % ( model_name , e ) ) return klass

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/design_analysis.py#L339-L378<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def leave_classdef ( self , node ) : my_methods = sum ( 1 for method in node . mymethods ( ) if not method . name . startswith ( "_" ) ) # Does the class contain less than n public methods ? # This checks only the methods defined in the current class, # since the user might not have control over the classes # from the ancestors. It avoids some false positives # for classes such as unittest.TestCase, which provides # a lot of assert methods. It doesn't make sense to warn # when the user subclasses TestCase to add his own tests. if my_methods > self . config . max_public_methods : self . add_message ( "too-many-public-methods" , node = node , args = ( my_methods , self . config . max_public_methods ) , ) # Stop here for exception, metaclass, interface classes and other # classes for which we don't need to count the methods. if ( node . type != "class" or _is_enum_class ( node ) or _is_dataclass ( node ) or _is_typing_namedtuple ( node ) ) : return # Does the class contain more than n public methods ? # This checks all the methods defined by ancestors and # by the current class. all_methods = _count_methods_in_class ( node ) if all_methods < self . config . min_public_methods : self . add_message ( "too-few-public-methods" , node = node , args = ( all_methods , self . config . min_public_methods ) , )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/coleifer/irc/blob/f9d2bd6369aafe6cb0916c9406270ca8ecea2080/irc.py#L284-L291<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def register_callbacks ( self ) : self . conn . register_callbacks ( ( ( re . compile ( pattern ) , callback ) for pattern , callback in self . command_patterns ( ) ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ccubed/Shosetsu/blob/eba01c058100ec8806129b11a2859f3126a1b101/Shosetsu/VNDB.py#L17-L62<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>async def search_vndb ( self , stype , term ) : fstype = "" if stype not in [ 'v' , 'r' , 'p' , 's' , 'c' , 'g' , 'i' , 'u' ] : raise VNDBBadStype ( stype ) else : if stype in [ 'v' , 'p' , 's' , 'c' , 'u' ] : fstype = '/{}/all' . format ( stype ) elif stype in [ 'g' , 'i' ] : fstype = '/{}/list' . format ( stype ) elif stype == 'r' : fstype = '/r' async with self . session . get ( self . base_url + "{}" . format ( fstype ) , params = { "q" : term } , headers = self . headers ) as response : if response . status == 404 : raise aiohttp . HttpBadRequest ( "VN Not Found" ) elif 'q=' not in response . url : raise VNDBOneResult ( term , response . url . rsplit ( '/' , 1 ) [ 1 ] ) text = await response . text ( ) if 'No Results' in text : raise VNDBNoResults ( term ) soup = BeautifulSoup ( text , 'lxml' ) resp = await self . parse_search ( stype , soup ) if resp == [ ] : raise VNDBNoResults ( term ) return resp

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/_vendor/slugify/slugify.py#L74-L175<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def slugify ( text , entities = True , decimal = True , hexadecimal = True , max_length = 0 , word_boundary = False , separator = DEFAULT_SEPARATOR , save_order = False , stopwords = ( ) , regex_pattern = None , lowercase = True , replacements = ( ) ) : # user-specific replacements if replacements : for old , new in replacements : text = text . replace ( old , new ) # ensure text is unicode if not isinstance ( text , _unicode_type ) : text = _unicode ( text , 'utf-8' , 'ignore' ) # replace quotes with dashes - pre-process text = QUOTE_PATTERN . sub ( DEFAULT_SEPARATOR , text ) # decode unicode text = unidecode . unidecode ( text ) # ensure text is still in unicode if not isinstance ( text , _unicode_type ) : text = _unicode ( text , 'utf-8' , 'ignore' ) # character entity reference if entities : text = CHAR_ENTITY_PATTERN . sub ( lambda m : unichr ( name2codepoint [ m . group ( 1 ) ] ) , text ) # decimal character reference if decimal : try : text = DECIMAL_PATTERN . sub ( lambda m : unichr ( int ( m . group ( 1 ) ) ) , text ) except Exception : pass # hexadecimal character reference if hexadecimal : try : text = HEX_PATTERN . sub ( lambda m : unichr ( int ( m . group ( 1 ) , 16 ) ) , text ) except Exception : pass # translate text = unicodedata . normalize ( 'NFKD' , text ) # make the text lowercase (optional) if lowercase : text = text . lower ( ) # remove generated quotes -- post-process text = QUOTE_PATTERN . sub ( '' , text ) # cleanup numbers text = NUMBERS_PATTERN . sub ( '' , text ) # replace all other unwanted characters if lowercase : pattern = regex_pattern or ALLOWED_CHARS_PATTERN else : pattern = regex_pattern or ALLOWED_CHARS_PATTERN_WITH_UPPERCASE text = re . sub ( pattern , DEFAULT_SEPARATOR , text ) # remove redundant text = DUPLICATE_DASH_PATTERN . sub ( DEFAULT_SEPARATOR , text ) . strip ( DEFAULT_SEPARATOR ) # remove stopwords if stopwords : if lowercase : stopwords_lower = [ s . lower ( ) for s in stopwords ] words = [ w for w in text . split ( DEFAULT_SEPARATOR ) if w not in stopwords_lower ] else : words = [ w for w in text . split ( DEFAULT_SEPARATOR ) if w not in stopwords ] text = DEFAULT_SEPARATOR . join ( words ) # finalize user-specific replacements if replacements : for old , new in replacements : text = text . replace ( old , new ) # smart truncate if requested if max_length > 0 : text = smart_truncate ( text , max_length , word_boundary , DEFAULT_SEPARATOR , save_order ) if separator != DEFAULT_SEPARATOR : text = text . replace ( DEFAULT_SEPARATOR , separator ) return text

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/not-na/peng3d/blob/1151be665b26cc8a479f6307086ba919e4d32d85/peng3d/model.py#L1039-L1086<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def setAnimation ( self , obj , animation , transition = None , force = False ) : self . ensureModelData ( obj ) data = obj . _modeldata # Validity check if animation not in self . modeldata [ "animations" ] : raise ValueError ( "There is no animation of name '%s' for model '%s'" % ( animation , self . modelname ) ) if data . get ( "_anidata" , { } ) . get ( "anitype" , None ) == animation and not force : return # animation is already running # Cache the obj to improve readability anim = self . modeldata [ "animations" ] [ animation ] # Set to default if not set if transition is None : transition = anim . default_jt # Notify the animation to allow it to initialize itself anim . startAnimation ( data , transition ) # initialize animation data if "_anidata" not in data : data [ "_anidata" ] = { } adata = data [ "_anidata" ] adata [ "anitype" ] = animation if "_schedfunc" in adata : # unschedule the old animation, if any # prevents clashing and crashes pyglet . clock . unschedule ( adata [ "_schedfunc" ] ) # Schedule the animation function def schedfunc ( * args ) : # This function is defined locally to create a closure # The closure stores the local variables, e.g. anim and data even after the parent function has finished # Note that this may also prevent the garbage collection of any objects defined in the parent scope anim . tickEntity ( data ) # register the function to pyglet pyglet . clock . schedule_interval ( schedfunc , 1. / ( anim . kps if anim . atype == "keyframes" else 60 ) ) # save it for later for de-initialization adata [ "_schedfunc" ] = schedfunc

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/treycucco/pyebnf/blob/3634ddabbe5d73508bcc20f4a591f86a46634e1d/pyebnf/compiler.py#L175-L196<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _get_rule_definition ( self , rule ) : fmt = """def {rule_fxn_name}(self, text):              {indent}\"\"\"{rule_source}\"\"\"              {indent}self._attempting(text)              {indent}return {rule_definition}(text){transform}           """ fmt = self . _clean_fmt ( fmt ) source = self . _indent ( self . _ast_to_code ( rule . expression ) , skip_first_line = True ) # All the primitives will accept a string x in place of terminal(x). This is terminal shorthand. # However, if a rule is only a wrapper around a single terminal, we have to actually make a # terminal call. This handles that situation. if self . use_terminal_shorthand and len ( source ) == 1 and source [ 0 ] . startswith ( ( "'" , '"' ) ) : source = [ "terminal({})" . format ( source [ 0 ] ) ] rule_source = fmt . format ( rule_fxn_name = self . _get_rule_fxn_name ( rule . name ) , indent = self . indent , rule_source = self . _get_rule_source ( rule ) , rule_definition = "\n" . join ( source ) , transform = self . _get_rule_transform ( rule ) ) return self . _indent ( rule_source , 1 )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/typechecks.py#L497-L560<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _retrieve_assert_arguments ( ) : try : raise RuntimeError ( "Catch me!" ) except RuntimeError : # Walk up the stacktrace until we are outside of this file tb = sys . exc_info ( ) [ 2 ] assert tb . tb_frame . f_code . co_name == "_retrieve_assert_arguments" this_filename = tb . tb_frame . f_code . co_filename fr = tb . tb_frame while fr is not None and fr . f_code . co_filename == this_filename : fr = fr . f_back # Read the source file and tokenize it, extracting the expressions. try : with io . open ( fr . f_code . co_filename , "r" , encoding = "utf-8" ) as f : # Skip initial lines that are irrelevant for i in range ( fr . f_lineno - 1 ) : next ( f ) # Create tokenizer g = tokenize . generate_tokens ( f . readline ) step = 0 args_tokens = [ ] level = 0 for ttt in g : if step == 0 : if ttt [ 0 ] != tokenize . NAME : continue if not ttt [ 1 ] . startswith ( "assert_" ) : continue step = 1 elif step == 1 : assert ttt [ 0 ] == tokenize . OP and ttt [ 1 ] == "(" args_tokens . append ( [ ] ) step = 2 elif step == 2 : if level == 0 and ttt [ 0 ] == tokenize . OP and ttt [ 1 ] == "," : args_tokens . append ( [ ] ) elif level == 0 and ttt [ 0 ] == tokenize . OP and ttt [ 1 ] == ")" : break else : if ttt [ 0 ] == tokenize . OP and ttt [ 1 ] in "([{" : level += 1 if ttt [ 0 ] == tokenize . OP and ttt [ 1 ] in ")]}" : level -= 1 assert level >= 0 , "Parse error: parentheses level became negative" args_tokens [ - 1 ] . append ( ttt ) args = [ tokenize . untokenize ( at ) . strip ( ) . replace ( "\n" , " " ) for at in args_tokens ] return args except IOError : return "arg" ,

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/maxcountryman/flask-uploads/blob/dc24fa0c53d605876e5b4502cadffdf1a4345b1d/flask_uploads.py#L433-L452<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def resolve_conflict ( self , target_folder , basename ) : name , ext = os . path . splitext ( basename ) count = 0 while True : count = count + 1 newname = '%s_%d%s' % ( name , count , ext ) if not os . path . exists ( os . path . join ( target_folder , newname ) ) : return newname

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/openergy/oplus/blob/f095868d1990c1d126e906ada6acbab26348b3d3/oplus/epm/relations_manager.py#L65-L99<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def register_link ( self , link ) : keys = tuple ( ( ref , link . initial_hook_value ) for ref in link . hook_references ) # look for a record hook for k in keys : if k in self . _record_hooks : # set link target link . set_target ( target_record = self . _record_hooks [ k ] . target_record ) break else : # look for a table hook for k in keys : if k in self . _table_hooks : # set link target link . set_target ( target_table = self . _table_hooks [ k ] ) break else : field_descriptor = link . source_record . get_field_descriptor ( link . source_index ) raise FieldValidationError ( f"No object found with any of given references : {keys}. " f"{field_descriptor.get_error_location_message(link.initial_hook_value)}" ) # store by source if link . source_record not in self . _links_by_source : self . _links_by_source [ link . source_record ] = set ( ) self . _links_by_source [ link . source_record ] . add ( link ) # store by target if link . target not in self . _links_by_target : self . _links_by_target [ link . target ] = set ( ) self . _links_by_target [ link . target ] . add ( link )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/oceanprotocol/oceandb-elasticsearch-driver/blob/11901e8396252b9dbb70fd48debcfa82f1dd1ff2/oceandb_elasticsearch_driver/plugin.py#L136-L170<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def query ( self , search_model : QueryModel ) : query_parsed = query_parser ( search_model . query ) self . logger . debug ( f'elasticsearch::query::{query_parsed[0]}' ) if search_model . sort is not None : self . _mapping_to_sort ( search_model . sort . keys ( ) ) sort = self . _sort_object ( search_model . sort ) else : sort = [ { "_id" : "asc" } ] if search_model . query == { } : query = { 'match_all' : { } } else : query = query_parsed [ 0 ] body = { 'query' : query , 'sort' : sort , 'from' : ( search_model . page - 1 ) * search_model . offset , 'size' : search_model . offset , } page = self . driver . _es . search ( index = self . driver . _index , doc_type = '_doc' , body = body , q = query_parsed [ 1 ] ) object_list = [ ] for x in page [ 'hits' ] [ 'hits' ] : object_list . append ( x [ '_source' ] ) return object_list

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/VingtCinq/python-resize-image/blob/a4e645792ef30c5fcc558df6da6de18b1ecb95ea/resizeimage/helpers.py#L14-L20<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def url_to_image ( url ) : r = requests . get ( url ) image = StringIO ( r . content ) return image

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/psutil/_pslinux.py#L183-L195<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_system_cpu_times ( ) : f = open ( '/proc/stat' , 'r' ) try : values = f . readline ( ) . split ( ) finally : f . close ( ) values = values [ 1 : 8 ] values = tuple ( [ float ( x ) / _CLOCK_TICKS for x in values ] ) return nt_sys_cputimes ( * values [ : 7 ] )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/singularityhub/sregistry-cli/blob/abc96140a1d15b5e96d83432e1e0e1f4f8f36331/sregistry/main/workers/aws.py#L97-L145<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def stream ( url , headers , stream_to = None , retry = True ) : bot . debug ( "GET %s" % url ) if DISABLE_SSL_CHECK is True : bot . warning ( 'Verify of certificates disabled! ::TESTING USE ONLY::' ) # Ensure headers are present, update if not response = requests . get ( url , headers = headers , verify = not DISABLE_SSL_CHECK , stream = True ) # If we get permissions error, one more try with updated token if response . status_code in [ 401 , 403 ] : headers = update_token ( headers ) return stream ( url , headers , stream_to , retry = False ) # Successful Response elif response . status_code == 200 : # Keep user updated with Progress Bar content_size = None if 'Content-Length' in response . headers : progress = 0 content_size = int ( response . headers [ 'Content-Length' ] ) bot . show_progress ( progress , content_size , length = 35 ) chunk_size = 1 << 20 with open ( stream_to , 'wb' ) as filey : for chunk in response . iter_content ( chunk_size = chunk_size ) : filey . write ( chunk ) if content_size is not None : progress += chunk_size bot . show_progress ( iteration = progress , total = content_size , length = 35 , carriage_return = False ) # Newline to finish download sys . stdout . write ( '\n' ) return stream_to bot . error ( "Problem with stream, response %s" % ( response . status_code ) ) sys . exit ( 1 )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/katerina7479/pypdflite/blob/ac2501f30d6619eae9dea5644717575ca9263d0a/pypdflite/pdfobjects/pdfcolor.py#L59-L73<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _is_equal ( self , test_color ) : if test_color is None : ans = False elif test_color . color_type != self . color_type : ans = False elif self . name is not None and self . name == test_color . name : ans = True elif ( self . red == test_color . red and self . blue == test_color . blue and self . green == test_color . green ) : ans = True else : ans = False return ans

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/scheibler/khard/blob/0f69430c2680f1ff5f073a977a3c5b753b96cc17/khard/carddav_object.py#L1507-L1553<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _get_types_for_vcard_object ( self , object , default_type ) : type_list = [ ] # try to find label group for custom value type if object . group : for label in self . vcard . getChildren ( ) : if label . name == "X-ABLABEL" and label . group == object . group : custom_type = label . value . strip ( ) if custom_type : type_list . append ( custom_type ) # then load type from params dict standard_types = object . params . get ( "TYPE" ) if standard_types is not None : if not isinstance ( standard_types , list ) : standard_types = [ standard_types ] for type in standard_types : type = type . strip ( ) if type and type . lower ( ) != "pref" : if not type . lower ( ) . startswith ( "x-" ) : type_list . append ( type ) elif type [ 2 : ] . lower ( ) not in [ x . lower ( ) for x in type_list ] : # add x-custom type in case it's not already added by # custom label for loop above but strip x- before type_list . append ( type [ 2 : ] ) # try to get pref parameter from vcard version 4.0 try : type_list . append ( "pref=%d" % int ( object . params . get ( "PREF" ) [ 0 ] ) ) except ( IndexError , TypeError , ValueError ) : # else try to determine, if type params contain pref attribute try : for x in object . params . get ( "TYPE" ) : if x . lower ( ) == "pref" and "pref" not in type_list : type_list . append ( "pref" ) except TypeError : pass # return type_list or default type if type_list : return type_list return [ default_type ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/vaexio/vaex/blob/a45b672f8287afca2ada8e36b74b604b9b28dd85/packages/vaex-core/vaex/ext/jprops.py#L260-L273<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _universal_newlines ( fp ) : # if file was opened with universal newline support we don't need to convert if 'U' in getattr ( fp , 'mode' , '' ) : for line in fp : yield line else : for line in fp : line = line . replace ( b'\r\n' , b'\n' ) . replace ( b'\r' , b'\n' ) for piece in line . split ( b'\n' ) : yield piece

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cartoonist/pystream-protobuf/blob/40e70b932436887b748905e5e0a82839e4c559f0/stream/stream.py#L165-L183<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _get_objs ( self ) : while True : count = self . _read_varint ( ) if count == 0 : break # Read a group containing `count` number of objects. for _ in range ( count ) : size = self . _read_varint ( ) if size == 0 : raise EOFError ( 'unexpected EOF.' ) # Read an object from the object group. yield self . _fd . read ( size ) if self . _group_delim : yield self . _delimiter ( ) if self . _delimiter is not None else None

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/3DLIRIOUS/MeshLabXML/blob/177cce21e92baca500f56a932d66bd9a33257af8/meshlabxml/transform.py#L569-L594<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def radial_flare ( script , flare_radius = None , start_radius = None , end_radius = None , end_height = None ) : # TODO: set radius limit, make it so flare continues to expand linearly after radius limit # if(r<=radius_limit, flare, factor*z+constant # TODO: add option to specify radius at height instead of radius effective_radius = '(flare_radius) + (start_radius) - (r)' r_func = 'if(z>0, (flare_radius) + (start_radius) - (effective_radius)*cos(z/(flare_radius)), (r))' z_func = 'if(z>0, (effective_radius)*sin(z/(flare_radius)), z)' r_func = r_func . replace ( 'effective_radius' , str ( effective_radius ) ) . replace ( 'start_radius' , str ( start_radius ) ) . replace ( 'flare_radius' , str ( flare_radius ) ) z_func = z_func . replace ( 'effective_radius' , str ( effective_radius ) ) . replace ( 'start_radius' , str ( start_radius ) ) . replace ( 'flare_radius' , str ( flare_radius ) ) function_cyl_co ( script = script , r_func = r_func , z_func = z_func ) return None

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/qt/console/console_widget.py#L1843-L1888<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _show_prompt ( self , prompt = None , html = False , newline = True ) : # Save the current end position to support _append*(before_prompt=True). cursor = self . _get_end_cursor ( ) self . _append_before_prompt_pos = cursor . position ( ) # Insert a preliminary newline, if necessary. if newline and cursor . position ( ) > 0 : cursor . movePosition ( QtGui . QTextCursor . Left , QtGui . QTextCursor . KeepAnchor ) if cursor . selection ( ) . toPlainText ( ) != '\n' : self . _append_plain_text ( '\n' ) # Write the prompt. self . _append_plain_text ( self . _prompt_sep ) if prompt is None : if self . _prompt_html is None : self . _append_plain_text ( self . _prompt ) else : self . _append_html ( self . _prompt_html ) else : if html : self . _prompt = self . _append_html_fetching_plain_text ( prompt ) self . _prompt_html = prompt else : self . _append_plain_text ( prompt ) self . _prompt = prompt self . _prompt_html = None self . _prompt_pos = self . _get_end_cursor ( ) . position ( ) self . _prompt_started ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L3219-L3241<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def cut ( self , breaks , labels = None , include_lowest = False , right = True , dig_lab = 3 ) : assert_is_type ( breaks , [ numeric ] ) if self . ncols != 1 : raise H2OValueError ( "Single-column frame is expected" ) if self . types [ self . names [ 0 ] ] not in { "int" , "real" } : raise H2OValueError ( "A numeric column is expected" ) fr = H2OFrame . _expr ( expr = ExprNode ( "cut" , self , breaks , labels , include_lowest , right , dig_lab ) , cache = self . _ex . _cache ) fr . _ex . _cache . types = { k : "enum" for k in self . names } return fr

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/py2/ec2_cmd.py#L232-L245<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def wait_for_ssh ( ips , port = 22 , skipAlive = True , requiredsuccess = 3 ) : log ( 'Waiting for SSH on following hosts: {0}' . format ( ips ) ) for ip in ips : if not skipAlive or not ssh_live ( ip , port ) : log ( 'Waiting for SSH on instance {0}...' . format ( ip ) ) count = 0 while count < requiredsuccess : if ssh_live ( ip , port ) : count += 1 else : count = 0 time . sleep ( 1 ) h2o_cmd . dot ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ibm-watson-iot/iot-python/blob/195f05adce3fba4ec997017e41e02ebd85c0c4cc/src/wiotp/sdk/api/lec/__init__.py#L51-L65<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get ( self , deviceUid , eventId ) : if not isinstance ( deviceUid , DeviceUid ) and isinstance ( deviceUid , dict ) : deviceUid = DeviceUid ( * * deviceUid ) url = "api/v0002/device/types/%s/devices/%s/events/%s" % ( deviceUid . typeId , deviceUid . deviceId , eventId ) r = self . _apiClient . get ( url ) if r . status_code == 200 : return LastEvent ( * * r . json ( ) ) else : raise ApiException ( r )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/draios/python-sdc-client/blob/47f83415842048778939b90944f64386a3bcb205/sdcclient/_common.py#L926-L952<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def save_memberships ( self , team , memberships ) : res = self . list_memberships ( team ) if res [ 0 ] is False : return res full_memberships = res [ 1 ] full_memberships . update ( memberships ) res = self . edit_team ( team , full_memberships ) if res [ 0 ] is False : return res else : return [ True , None ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/bolt-project/bolt/blob/9cd7104aa085498da3097b72696184b9d3651c51/bolt/spark/chunk.py#L415-L432<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def map_generic ( self , func ) : def process_record ( val ) : newval = empty ( 1 , dtype = "object" ) newval [ 0 ] = func ( val ) return newval rdd = self . _rdd . mapValues ( process_record ) nchunks = self . getnumber ( self . plan , self . vshape ) newshape = tuple ( [ int ( s ) for s in r_ [ self . kshape , nchunks ] ] ) newsplit = len ( self . shape ) return BoltArraySpark ( rdd , shape = newshape , split = newsplit , ordered = self . _ordered , dtype = "object" )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/parse/hpo.py#L42-L64<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse_hpo_disease ( hpo_line ) : hpo_line = hpo_line . rstrip ( ) . split ( '\t' ) hpo_info = { } disease = hpo_line [ 0 ] . split ( ':' ) hpo_info [ 'source' ] = disease [ 0 ] hpo_info [ 'disease_nr' ] = int ( disease [ 1 ] ) hpo_info [ 'hgnc_symbol' ] = None hpo_info [ 'hpo_term' ] = None if len ( hpo_line ) >= 3 : hpo_info [ 'hgnc_symbol' ] = hpo_line [ 2 ] if len ( hpo_line ) >= 4 : hpo_info [ 'hpo_term' ] = hpo_line [ 3 ] return hpo_info

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/horazont/aiosasl/blob/af58bf30f688757e58af6e87892d35a8ce798482/aiosasl/__init__.py#L316-L340<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def from_reply ( cls , state ) : if state in ( SASLState . FAILURE , SASLState . SUCCESS , SASLState . CHALLENGE ) : return state if state in ( "failure" , "success" , "challenge" ) : return SASLState ( state ) else : raise RuntimeError ( "invalid SASL state" , state )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/idlesign/django-sitetree/blob/61de4608e6e415247c75fe8691027d7c4ed0d1e7/sitetree/admin.py#L320-L354<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_urls ( self ) : urls = super ( TreeAdmin , self ) . get_urls ( ) prefix_change = 'change/' if DJANGO_POST_19 else '' sitetree_urls = [ url ( r'^change/$' , redirects_handler , name = get_tree_item_url_name ( 'changelist' ) ) , url ( r'^((?P<tree_id>\d+)/)?%sitem_add/$' % prefix_change , self . admin_site . admin_view ( self . tree_admin . item_add ) , name = get_tree_item_url_name ( 'add' ) ) , url ( r'^(?P<tree_id>\d+)/%sitem_(?P<item_id>\d+)/$' % prefix_change , self . admin_site . admin_view ( self . tree_admin . item_edit ) , name = get_tree_item_url_name ( 'change' ) ) , url ( r'^%sitem_(?P<item_id>\d+)/$' % prefix_change , self . admin_site . admin_view ( self . tree_admin . item_edit ) , name = get_tree_item_url_name ( 'change' ) ) , url ( r'^((?P<tree_id>\d+)/)?%sitem_(?P<item_id>\d+)/delete/$' % prefix_change , self . admin_site . admin_view ( self . tree_admin . item_delete ) , name = get_tree_item_url_name ( 'delete' ) ) , url ( r'^((?P<tree_id>\d+)/)?%sitem_(?P<item_id>\d+)/history/$' % prefix_change , self . admin_site . admin_view ( self . tree_admin . item_history ) , name = get_tree_item_url_name ( 'history' ) ) , url ( r'^(?P<tree_id>\d+)/%sitem_(?P<item_id>\d+)/move_(?P<direction>(up|down))/$' % prefix_change , self . admin_site . admin_view ( self . tree_admin . item_move ) , name = get_tree_item_url_name ( 'move' ) ) , ] if not DJANGO_POST_19 : sitetree_urls = patterns_func ( '' , * sitetree_urls ) if SMUGGLER_INSTALLED : sitetree_urls += ( url ( r'^dump_all/$' , self . admin_site . admin_view ( self . dump_view ) , name = 'sitetree_dump' ) , ) return sitetree_urls + urls

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/uw-it-aca/uw-restclients-canvas/blob/9845faf33d49a8f06908efc22640c001116d6ea2/uw_canvas/terms.py#L7-L23<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_all_terms ( self ) : if not self . _canvas_account_id : raise MissingAccountID ( ) params = { "workflow_state" : 'all' , 'per_page' : 500 } url = ACCOUNTS_API . format ( self . _canvas_account_id ) + "/terms" data_key = 'enrollment_terms' terms = [ ] response = self . _get_paged_resource ( url , params , data_key ) for data in response [ data_key ] : terms . append ( CanvasTerm ( data = data ) ) return terms

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mohabusama/pyguacamole/blob/344dccc6cb3a9a045afeaf337677e5d0001aa83a/guacamole/instruction.py#L133-L148<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def encode_arg ( arg ) : arg_utf8 = utf8 ( arg ) return ELEM_SEP . join ( [ str ( len ( str ( arg_utf8 ) ) ) , str ( arg_utf8 ) ] )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/lmjohns3/theanets/blob/79db9f878ef2071f2f576a1cf5d43a752a55894a/examples/lstm-chime.py#L71-L84<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def batches ( dataset ) : seq_lengths = dataset . variables [ 'seqLengths' ] . data seq_begins = np . concatenate ( ( [ 0 ] , np . cumsum ( seq_lengths ) [ : - 1 ] ) ) def sample ( ) : chosen = np . random . choice ( list ( range ( len ( seq_lengths ) ) ) , BATCH_SIZE , replace = False ) return batch_at ( dataset . variables [ 'inputs' ] . data , dataset . variables [ 'targetClasses' ] . data , seq_begins [ chosen ] , seq_lengths [ chosen ] ) return sample

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2non/pook/blob/e64094e41e4d89d98d2d29af7608ef27dc50cf19/pook/mock.py#L247-L267<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def headers_present ( self , headers ) : headers = { name : re . compile ( '(.*)' ) for name in headers } self . add_matcher ( matcher ( 'HeadersMatcher' , headers ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/capitalone/giraffez/blob/6b4d27eb1a1eaf188c6885c7364ef27e92b1b957/giraffez/config.py#L327-L349<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def unset_value ( self , key ) : if key . endswith ( "." ) : key = key [ : - 1 ] path = key . split ( "." ) curr = self . settings for p in path [ : - 1 ] : if p not in curr : raise ConfigurationError ( "Cannot unset '{}', nested key '{}' does not exist." . format ( key , p ) ) curr = curr [ p ] if not isinstance ( curr , dict ) : raise ConfigurationError ( "Cannot unset nested key '{}' in configuration value '{}'." . format ( path [ - 1 ] , key ) ) if path [ - 1 ] not in curr : raise ConfigurationError ( "Cannot unset '{}', nested key '{}' does not exist." . format ( key , path [ - 1 ] ) ) del curr [ path [ - 1 ] ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/merrychap/shellen/blob/3514b7ed3a1b7b1660c3f846a52f58ef02f0954c/shellen/asms/asm.py#L24-L42<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def avail_archs ( self ) : return { ARM32 : ( KS_ARCH_ARM , KS_MODE_ARM ) , ARM64 : ( KS_ARCH_ARM64 , KS_MODE_LITTLE_ENDIAN ) , ARM_TB : ( KS_ARCH_ARM , KS_MODE_THUMB ) , HEXAGON : ( KS_ARCH_HEXAGON , KS_MODE_BIG_ENDIAN ) , MIPS32 : ( KS_ARCH_MIPS , KS_MODE_MIPS32 ) , MIPS64 : ( KS_ARCH_MIPS , KS_MODE_MIPS64 ) , PPC32 : ( KS_ARCH_PPC , KS_MODE_PPC32 ) , PPC64 : ( KS_ARCH_PPC , KS_MODE_PPC64 ) , SPARC32 : ( KS_ARCH_SPARC , KS_MODE_SPARC32 ) , SPARC64 : ( KS_ARCH_SPARC , KS_MODE_SPARC64 ) , SYSTEMZ : ( KS_ARCH_SYSTEMZ , KS_MODE_BIG_ENDIAN ) , X86_16 : ( KS_ARCH_X86 , KS_MODE_16 ) , X86_32 : ( KS_ARCH_X86 , KS_MODE_32 ) , X86_64 : ( KS_ARCH_X86 , KS_MODE_64 ) , }

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/nvdv/vprof/blob/4c3ff78f8920ab10cb9c00b14143452aa09ff6bb/vprof/memory_profiler.py#L65-L75<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _format_obj_count ( objects ) : result = [ ] regex = re . compile ( r'<(?P<type>\w+) \'(?P<name>\S+)\'>' ) for obj_type , obj_count in objects . items ( ) : if obj_count != 0 : match = re . findall ( regex , repr ( obj_type ) ) if match : obj_type , obj_name = match [ 0 ] result . append ( ( "%s %s" % ( obj_type , obj_name ) , obj_count ) ) return sorted ( result , key = operator . itemgetter ( 1 ) , reverse = True )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ekzhu/datasketch/blob/b3e4129987890a2beb04f2c0b6dc618ae35f2e14/datasketch/experimental/aio/lsh.py#L275-L287<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>async def query ( self , minhash ) : if len ( minhash ) != self . h : raise ValueError ( "Expecting minhash with length %d, " "got %d" % ( self . h , len ( minhash ) ) ) fs = ( hashtable . get ( self . _H ( minhash . hashvalues [ start : end ] ) ) for ( start , end ) , hashtable in zip ( self . hashranges , self . hashtables ) ) candidates = frozenset ( chain . from_iterable ( await asyncio . gather ( * fs ) ) ) return list ( candidates )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/singularityhub/sregistry-cli/blob/abc96140a1d15b5e96d83432e1e0e1f4f8f36331/sregistry/main/workers/aws.py#L149-L177<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def update_token ( headers ) : try : from awscli . clidriver import create_clidriver except : bot . exit ( 'Please install pip install sregistry[aws]' ) driver = create_clidriver ( ) aws = driver . session . create_client ( 'ecr' ) tokens = aws . get_authorization_token ( ) token = tokens [ 'authorizationData' ] [ 0 ] [ 'authorizationToken' ] try : token = { "Authorization" : "Basic %s" % token } headers . update ( token ) except Exception : bot . error ( "Error getting token." ) sys . exit ( 1 ) return headers

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/html/notebook/handlers.py#L522-L528<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _really_start_hb ( self ) : if self . _beating and not self . hb_stream . closed ( ) : self . _hb_periodic_callback . start ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/config.py#L787-L794<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def add_help_section ( self , title , description , level = 0 ) : group = optparse . OptionGroup ( self . cmdline_parser , title = title . capitalize ( ) , description = description ) group . level = level self . _maxlevel = max ( self . _maxlevel , level ) self . cmdline_parser . add_option_group ( group )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chrisrink10/basilisp/blob/3d82670ee218ec64eb066289c82766d14d18cc92/src/basilisp/lang/keyword.py#L69-L77<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def __get_or_create ( kw_cache : "PMap[int, Keyword]" , h : int , name : str , ns : Optional [ str ] ) -> PMap : if h in kw_cache : return kw_cache kw = Keyword ( name , ns = ns ) return kw_cache . set ( h , kw )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/MisterY/price-database/blob/b4fd366b7763891c690fe3000b8840e656da023e/pricedb/app.py#L323-L345<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def __get_securities ( self , currency : str , agent : str , symbol : str , namespace : str ) -> List [ dal . Security ] : repo = self . get_security_repository ( ) query = repo . query if currency is not None : query = query . filter ( dal . Security . currency == currency ) if agent is not None : query = query . filter ( dal . Security . updater == agent ) if symbol is not None : query = query . filter ( dal . Security . symbol == symbol ) if namespace is not None : query = query . filter ( dal . Security . namespace == namespace ) # Sorting query = query . order_by ( dal . Security . namespace , dal . Security . symbol ) securities = query . all ( ) return securities

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/respondcreate/django-versatileimagefield/blob/d41e279c39cccffafbe876c67596184704ae8877/versatileimagefield/mixins.py#L108-L133<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def build_filters_and_sizers ( self , ppoi_value , create_on_demand ) : name = self . name if not name and self . field . placeholder_image_name : name = self . field . placeholder_image_name self . filters = FilterLibrary ( name , self . storage , versatileimagefield_registry , ppoi_value , create_on_demand ) for ( attr_name , sizedimage_cls ) in iteritems ( versatileimagefield_registry . _sizedimage_registry ) : setattr ( self , attr_name , sizedimage_cls ( path_to_image = name , storage = self . storage , create_on_demand = create_on_demand , ppoi = ppoi_value ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/scheibler/khard/blob/0f69430c2680f1ff5f073a977a3c5b753b96cc17/khard/address_book.py#L164-L200<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_short_uid_dict ( self , query = None ) : if self . _short_uids is None : if not self . _loaded : self . load ( query ) if not self . contacts : self . _short_uids = { } elif len ( self . contacts ) == 1 : self . _short_uids = { uid [ 0 : 1 ] : contact for uid , contact in self . contacts . items ( ) } else : self . _short_uids = { } sorted_uids = sorted ( self . contacts ) # Prepare for the loop; the first and last items are handled # seperatly. item0 , item1 = sorted_uids [ : 2 ] same1 = self . _compare_uids ( item0 , item1 ) self . _short_uids [ item0 [ : same1 + 1 ] ] = self . contacts [ item0 ] for item_new in sorted_uids [ 2 : ] : # shift the items and the common prefix lenght one further item0 , item1 = item1 , item_new same0 , same1 = same1 , self . _compare_uids ( item0 , item1 ) # compute the final prefix length for item1 same = max ( same0 , same1 ) self . _short_uids [ item0 [ : same + 1 ] ] = self . contacts [ item0 ] # Save the last item. self . _short_uids [ item1 [ : same1 + 1 ] ] = self . contacts [ item1 ] return self . _short_uids

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ToucanToco/toucan-data-sdk/blob/c3ca874e1b64f4bdcc2edda750a72d45d1561d8a/toucan_data_sdk/utils/generic/compute_evolution.py#L101-L160<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def compute_evolution_by_criteria ( df , id_cols : List [ str ] , value_col : str , compare_to : str , method : str = 'abs' , format : str = 'column' , offseted_suffix : str = '_offseted' , evolution_col_name : str = 'evolution_computed' , raise_duplicate_error : bool = True ) : return __compute_evolution ( * * locals ( ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Azure/azure-sdk-for-python/blob/d7306fde32f60a293a7567678692bdad31e4b667/azure-servicebus/azure/servicebus/common/mixins.py#L174-L222<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_subscription ( self , topic_name , subscription_name , lock_duration = 30 , requires_session = None , default_message_time_to_live = None , dead_lettering_on_message_expiration = None , dead_lettering_on_filter_evaluation_exceptions = None , enable_batched_operations = None , max_delivery_count = None ) : sub_properties = Subscription ( lock_duration = "PT{}S" . format ( int ( lock_duration ) ) , requires_session = requires_session , default_message_time_to_live = default_message_time_to_live , dead_lettering_on_message_expiration = dead_lettering_on_message_expiration , dead_lettering_on_filter_evaluation_exceptions = dead_lettering_on_filter_evaluation_exceptions , max_delivery_count = max_delivery_count , enable_batched_operations = enable_batched_operations ) try : return self . mgmt_client . create_subscription ( topic_name , subscription_name , subscription = sub_properties , fail_on_exist = True ) except requests . exceptions . ConnectionError as e : raise ServiceBusConnectionError ( "Namespace: {} not found" . format ( self . service_namespace ) , e )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neherlab/treetime/blob/f6cdb58d19243a18ffdaa2b2ec71872fa00e65c0/treetime/vcf_utils.py#L6-L269<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def read_vcf ( vcf_file , ref_file ) : #Programming Note:  # Note on VCF Format  # -------------------  # 'Insertion where there are also deletions' (special handling)  #     Ex:  #       REF     ALT         Seq1    Seq2  #       GC      GCC,G       1/1     2/2  #     Insertions formatted differently - don't know how many bp match  #     the Ref (unlike simple insert below). Could be mutations, also.  # 'Deletion'  #     Ex:  #       REF     ALT  #       GC      G  #     Alt does not have to be 1 bp - any length shorter than Ref.  # 'Insertion'  #     Ex:  #       REF     ALT  #       A       ATT  #     First base always matches Ref.  # 'No indel'  #     Ex:  #       REF     ALT  #       A       G  #define here, so that all sub-functions can access them  sequences = defaultdict ( dict ) insertions = defaultdict ( dict ) #Currently not used, but kept in case of future use.  #TreeTime handles 2-3 base ambig codes, this will allow that.  def getAmbigCode ( bp1 , bp2 , bp3 = "" ) : bps = [ bp1 , bp2 , bp3 ] bps . sort ( ) key = "" . join ( bps ) return { 'CT' : 'Y' , 'AG' : 'R' , 'AT' : 'W' , 'CG' : 'S' , 'GT' : 'K' , 'AC' : 'M' , 'AGT' : 'D' , 'ACG' : 'V' , 'ACT' : 'H' , 'CGT' : 'B' } [ key ] #Parses a 'normal' (not hetero or no-call) call depending if insertion+deletion, insertion,  #deletion, or single bp subsitution  def parseCall ( snps , ins , pos , ref , alt ) : #Insertion where there are also deletions (special handling)  if len ( ref ) > 1 and len ( alt ) > len ( ref ) : for i in range ( len ( ref ) ) : #if the pos doesn't match, store in sequences  if ref [ i ] != alt [ i ] : snps [ pos + i ] = alt [ i ] if alt [ i ] != '.' else 'N' #'.' = no-call  #if about to run out of ref, store rest:  if ( i + 1 ) >= len ( ref ) : ins [ pos + i ] = alt [ i : ] #Deletion  elif len ( ref ) > 1 : for i in range ( len ( ref ) ) : #if ref is longer than alt, these are deletion positions  if i + 1 > len ( alt ) : snps [ pos + i ] = '-' #if not, there may be mutations  else : if ref [ i ] != alt [ i ] : snps [ pos + i ] = alt [ i ] if alt [ i ] != '.' else 'N' #'.' = no-call  #Insertion  elif len ( alt ) > 1 : ins [ pos ] = alt #No indel  else : snps [ pos ] = alt #Parses a 'bad' (hetero or no-call) call depending on what it is  def parseBadCall ( snps , ins , pos , ref , ALT ) : #Deletion  #   REF     ALT     Seq1    Seq2    Seq3  #   GCC     G       1/1     0/1     ./.  # Seq1 (processed by parseCall, above) will become 'G--'  # Seq2 will become 'GNN'  # Seq3 will become 'GNN'  if len ( ref ) > 1 : #Deleted part becomes Ns  if gen [ 0 ] == '0' or gen [ 0 ] == '.' : if gen [ 0 ] == '0' : #if het, get first bp  alt = str ( ALT [ int ( gen [ 2 ] ) - 1 ] ) else : #if no-call, there is no alt, so just put Ns after 1st ref base  alt = ref [ 0 ] for i in range ( len ( ref ) ) : #if ref is longer than alt, these are deletion positions  if i + 1 > len ( alt ) : snps [ pos + i ] = 'N' #if not, there may be mutations  else : if ref [ i ] != alt [ i ] : snps [ pos + i ] = alt [ i ] if alt [ i ] != '.' else 'N' #'.' = no-call  #If not deletion, need to know call type  #if het, see if proposed alt is 1bp mutation  elif gen [ 0 ] == '0' : alt = str ( ALT [ int ( gen [ 2 ] ) - 1 ] ) if len ( alt ) == 1 : #alt = getAmbigCode(ref,alt) #if want to allow ambig  alt = 'N' #if you want to disregard ambig  snps [ pos ] = alt #else a het-call insertion, so ignore.  #else it's a no-call; see if all alts have a length of 1  #(meaning a simple 1bp mutation)  elif len ( ALT ) == len ( "" . join ( ALT ) ) : alt = 'N' snps [ pos ] = alt #else a no-call insertion, so ignore.  #House code is *much* faster than pyvcf because we don't care about all info  #about coverage, quality, counts, etc, which pyvcf goes to effort to parse  #(and it's not easy as there's no standard ordering). Custom code can completely  #ignore all of this.  import gzip from Bio import SeqIO import numpy as np nsamp = 0 posLoc = 0 refLoc = 0 altLoc = 0 sampLoc = 9 #Use different openers depending on whether compressed  opn = gzip . open if vcf_file . endswith ( ( '.gz' , '.GZ' ) ) else open with opn ( vcf_file , mode = 'rt' ) as f : for line in f : if line [ 0 ] != '#' : #actual data - most common so first in 'if-list'!  line = line . strip ( ) dat = line . split ( '\t' ) POS = int ( dat [ posLoc ] ) REF = dat [ refLoc ] ALT = dat [ altLoc ] . split ( ',' ) calls = np . array ( dat [ sampLoc : ] ) #get samples that differ from Ref at this site  recCalls = { } for sname , sa in zip ( samps , calls ) : if ':' in sa : #if proper VCF file (followed by quality/coverage info)  gt = sa . split ( ':' ) [ 0 ] else : #if 'pseudo' VCF file (nextstrain output, or otherwise stripped)  gt = sa if gt == '0' or gt == '1' : #for haploid calls in VCF  gt = '0/0' if gt == '0' else '1/1' #ignore if ref call: '.' or '0/0', depending on VCF  if ( '/' in gt and gt != '0/0' ) or ( '|' in gt and gt != '0|0' ) : recCalls [ sname ] = gt #store the position and the alt  for seq , gen in recCalls . items ( ) : ref = REF pos = POS - 1 #VCF numbering starts from 1, but Reference seq numbering  #will be from 0 because it's python!  #Accepts only calls that are 1/1, 2/2 etc. Rejects hets and no-calls  if gen [ 0 ] != '0' and gen [ 2 ] != '0' and gen [ 0 ] != '.' and gen [ 2 ] != '.' : alt = str ( ALT [ int ( gen [ 0 ] ) - 1 ] ) #get the index of the alternate  if seq not in sequences . keys ( ) : sequences [ seq ] = { } parseCall ( sequences [ seq ] , insertions [ seq ] , pos , ref , alt ) #If is heterozygote call (0/1) or no call (./.)  else : #alt will differ here depending on het or no-call, must pass original  parseBadCall ( sequences [ seq ] , insertions [ seq ] , pos , ref , ALT ) elif line [ 0 ] == '#' and line [ 1 ] == 'C' : #header line, get all the information  header = line . strip ( ) . split ( '\t' ) posLoc = header . index ( "POS" ) refLoc = header . index ( 'REF' ) altLoc = header . index ( 'ALT' ) sampLoc = header . index ( 'FORMAT' ) + 1 samps = header [ sampLoc : ] samps = [ x . strip ( ) for x in samps ] #ensure no leading/trailing spaces  nsamp = len ( samps ) #else you are a comment line, ignore.  #Gather all variable positions  positions = set ( ) for seq , muts in sequences . items ( ) : positions . update ( muts . keys ( ) ) #One or more seqs are same as ref! (No non-ref calls) So haven't been 'seen' yet  if nsamp > len ( sequences ) : missings = set ( samps ) . difference ( sequences . keys ( ) ) for s in missings : sequences [ s ] = { } refSeq = SeqIO . read ( ref_file , format = 'fasta' ) refSeq = refSeq . upper ( ) #convert to uppercase to avoid unknown chars later  refSeqStr = str ( refSeq . seq ) compress_seq = { 'reference' : refSeqStr , 'sequences' : sequences , 'insertions' : insertions , 'positions' : sorted ( positions ) } return compress_seq

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/LLNL/scraper/blob/881a316e4c04dfa5a9cf491b7c7f9f997a7c56ea/scraper/tfs/__init__.py#L21-L30<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_tfs_connection ( url , token ) : if token is None : token = os . environ . get ( 'TFS_API_TOKEN' , None ) tfs_credentials = BasicAuthentication ( '' , token ) tfs_connection = VssConnection ( base_url = url , creds = tfs_credentials ) return tfs_connection

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/dagcircuit/dagcircuit.py#L1393-L1425<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def nodes_on_wire ( self , wire , only_ops = False ) : current_node = self . input_map . get ( wire , None ) if not current_node : raise DAGCircuitError ( 'The given wire %s is not present in the circuit' % str ( wire ) ) more_nodes = True while more_nodes : more_nodes = False # allow user to just get ops on the wire - not the input/output nodes if current_node . type == 'op' or not only_ops : yield current_node # find the adjacent node that takes the wire being looked at as input for node , edges in self . _multi_graph . adj [ current_node ] . items ( ) : if any ( wire == edge [ 'wire' ] for edge in edges . values ( ) ) : current_node = node more_nodes = True break

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neurosynth/neurosynth/blob/948ce7edce15d7df693446e76834e0c23bfe8f11/neurosynth/base/dataset.py#L425-L429<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_feature_counts ( self , threshold = 0.001 ) : counts = np . sum ( self . get_feature_data ( ) >= threshold , 0 ) return dict ( zip ( self . get_feature_names ( ) , list ( counts ) ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/core/shellapp.py#L297-L311<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _run_startup_files ( self ) : startup_dir = self . profile_dir . startup_dir startup_files = glob . glob ( os . path . join ( startup_dir , '*.py' ) ) startup_files += glob . glob ( os . path . join ( startup_dir , '*.ipy' ) ) if not startup_files : return self . log . debug ( "Running startup files from %s..." , startup_dir ) try : for fname in sorted ( startup_files ) : self . _exec_file ( fname ) except : self . log . warn ( "Unknown error in handling startup files:" ) self . shell . showtraceback ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/zqfang/GSEApy/blob/673e9ec1391e3b14d3e8a4353117151fd2cb9345/gseapy/__main__.py#L271-L285<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def add_plot_parser ( subparsers ) : argparser_replot = subparsers . add_parser ( "replot" , help = "Reproduce GSEA desktop output figures." ) group_replot = argparser_replot . add_argument_group ( "Input arguments" ) group_replot . add_argument ( "-i" , "--indir" , action = "store" , dest = "indir" , required = True , metavar = 'GSEA_dir' , help = "The GSEA desktop results directroy that you want to reproduce the figure " ) add_output_option ( group_replot ) #add_output_group( argparser_plot ) group_replot . add_argument ( "-w" , "--weight" , action = 'store' , dest = 'weight' , default = 1.0 , type = float , metavar = 'float' , help = 'Weighted_score of rank_metrics. Please Use the same value in GSEA. Choose from (0, 1, 1.5, 2),default: 1' , ) return

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Nekmo/amazon-dash/blob/0e2bdc24ff8ea32cecb2f5f54f5cc1c0f99c197b/amazon_dash/config.py#L185-L199<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def only_root_write ( path ) : s = os . stat ( path ) for ug , bp in [ ( s . st_uid , bitperm ( s , 'w' , 'usr' ) ) , ( s . st_gid , bitperm ( s , 'w' , 'grp' ) ) ] : # User id (is not root) and bit permission if ug and bp : return False if bitperm ( s , 'w' , 'oth' ) : return False return True

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/treycucco/pyebnf/blob/3634ddabbe5d73508bcc20f4a591f86a46634e1d/pyebnf/primitive.py#L184-L208<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def compressed ( self , new_type = None , * , include_ignored = False ) : values = [ ] consumed = 0 ignored = None for i , child in enumerate ( self . children ) : consumed += child . consumed if i == 0 and not include_ignored : ignored = child . ignored if child . is_value : if include_ignored : values . append ( "{0}{1}" . format ( child . ignored or "" , child . value ) ) else : values . append ( child . value ) else : values . append ( child . compressed ( include_ignored = include_ignored ) . value ) return ParseNode ( new_type or self . node_type , children = [ "" . join ( values ) ] , consumed = consumed , ignored = ignored , position = self . position )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/quantum_info/operators/operator.py#L210-L228<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def add ( self , other ) : if not isinstance ( other , Operator ) : other = Operator ( other ) if self . dim != other . dim : raise QiskitError ( "other operator has different dimensions." ) return Operator ( self . data + other . data , self . input_dims ( ) , self . output_dims ( ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/OpenKMIP/PyKMIP/blob/b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e/kmip/services/kmip_client.py#L741-L817<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def encrypt ( self , data , unique_identifier = None , cryptographic_parameters = None , iv_counter_nonce = None , credential = None ) : operation = Operation ( OperationEnum . ENCRYPT ) request_payload = payloads . EncryptRequestPayload ( unique_identifier = unique_identifier , data = data , cryptographic_parameters = cryptographic_parameters , iv_counter_nonce = iv_counter_nonce ) batch_item = messages . RequestBatchItem ( operation = operation , request_payload = request_payload ) request = self . _build_request_message ( credential , [ batch_item ] ) response = self . _send_and_receive_message ( request ) batch_item = response . batch_items [ 0 ] payload = batch_item . response_payload result = { } if payload : result [ 'unique_identifier' ] = payload . unique_identifier result [ 'data' ] = payload . data result [ 'iv_counter_nonce' ] = payload . iv_counter_nonce result [ 'result_status' ] = batch_item . result_status . value try : result [ 'result_reason' ] = batch_item . result_reason . value except Exception : result [ 'result_reason' ] = batch_item . result_reason try : result [ 'result_message' ] = batch_item . result_message . value except Exception : result [ 'result_message' ] = batch_item . result_message return result

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/rss.py#L180-L190<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def setup_cmd_parser ( cls ) : parser = BackendCommandArgumentParser ( cls . BACKEND . CATEGORIES , archive = True ) # Required arguments parser . parser . add_argument ( 'url' , help = "URL of the RSS feed" ) return parser

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/scrapinghub/dateparser/blob/11a761c99d3ee522a3c63756b70c106a579e8b5c/dateparser/__init__.py#L11-L56<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse ( date_string , date_formats = None , languages = None , locales = None , region = None , settings = None ) : parser = _default_parser if any ( [ languages , locales , region , not settings . _default ] ) : parser = DateDataParser ( languages = languages , locales = locales , region = region , settings = settings ) data = parser . get_date_data ( date_string , date_formats ) if data : return data [ 'date_obj' ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SmokinCaterpillar/pypet/blob/97ad3e80d46dbdea02deeb98ea41f05a19565826/pypet/trajectory.py#L3567-L3589<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def f_get_derived_parameters ( self , fast_access = False , copy = True ) : return self . _return_item_dictionary ( self . _derived_parameters , fast_access , copy )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/rocky/python3-trepan/blob/14e91bc0acce090d67be145b1ac040cab92ac5f3/trepan/inout/scriptin.py#L41-L51<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def open ( self , inp , opts = None ) : if isinstance ( inp , io . TextIOWrapper ) : self . input = inp elif isinstance ( inp , 'string' . __class__ ) : # FIXME self . name = inp self . input = open ( inp , 'r' ) else : raise IOError ( "Invalid input type (%s) for %s" % ( inp . __class__ . __name__ , inp ) ) return

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/message/message_handler_mix_in.py#L76-L93<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _register_by_id_managed_msg ( self , msgid , line , is_disabled = True ) : try : message_definitions = self . msgs_store . get_message_definitions ( msgid ) for message_definition in message_definitions : if msgid == message_definition . msgid : MessagesHandlerMixIn . __by_id_managed_msgs . append ( ( self . current_name , message_definition . msgid , message_definition . symbol , line , is_disabled , ) ) except UnknownMessageError : pass

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/parse/variant/transcript.py#L9-L201<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse_transcripts ( raw_transcripts , allele = None ) : for entry in raw_transcripts : transcript = { } # There can be several functional annotations for one variant functional_annotations = entry . get ( 'CONSEQUENCE' , '' ) . split ( '&' ) transcript [ 'functional_annotations' ] = functional_annotations # Get the transcript id (ensembl gene id) transcript_id = entry . get ( 'FEATURE' , '' ) . split ( ':' ) [ 0 ] transcript [ 'transcript_id' ] = transcript_id # Add the hgnc gene identifiers # The HGNC ID is prefered and will be used if it exists hgnc_id = entry . get ( 'HGNC_ID' ) if hgnc_id : hgnc_id = hgnc_id . split ( ':' ) [ - 1 ] transcript [ 'hgnc_id' ] = int ( hgnc_id ) else : transcript [ 'hgnc_id' ] = None hgnc_symbol = entry . get ( 'SYMBOL' ) if hgnc_symbol : transcript [ 'hgnc_symbol' ] = hgnc_symbol else : transcript [ 'hgnc_symbol' ] = None ########### Fill it with the available information ########### ### Protein specific annotations ### ## Protein ID ## transcript [ 'protein_id' ] = entry . get ( 'ENSP' ) ## Polyphen prediction ## polyphen_prediction = entry . get ( 'POLYPHEN' ) # Default is 'unknown' prediction_term = 'unknown' if polyphen_prediction : prediction_term = polyphen_prediction . split ( '(' ) [ 0 ] transcript [ 'polyphen_prediction' ] = prediction_term ## Sift prediction ## # Check with other key if it does not exist sift_prediction = entry . get ( 'SIFT' ) # Default is 'unknown' prediction_term = 'unknown' if not sift_prediction : sift_prediction = entry . get ( 'SIFT_PRED' ) if sift_prediction : prediction_term = sift_prediction . split ( '(' ) [ 0 ] transcript [ 'sift_prediction' ] = prediction_term transcript [ 'swiss_prot' ] = entry . get ( 'SWISSPROT' ) or 'unknown' if entry . get ( 'DOMAINS' , None ) : pfam_domains = entry [ 'DOMAINS' ] . split ( '&' ) for annotation in pfam_domains : annotation = annotation . split ( ':' ) domain_name = annotation [ 0 ] domain_id = annotation [ 1 ] if domain_name == 'Pfam_domain' : transcript [ 'pfam_domain' ] = domain_id elif domain_name == 'PROSITE_profiles' : transcript [ 'prosite_profile' ] = domain_id elif domain_name == 'SMART_domains' : transcript [ 'smart_domain' ] = domain_id coding_sequence_entry = entry . get ( 'HGVSC' , '' ) . split ( ':' ) protein_sequence_entry = entry . get ( 'HGVSP' , '' ) . split ( ':' ) coding_sequence_name = None if len ( coding_sequence_entry ) > 1 : coding_sequence_name = coding_sequence_entry [ - 1 ] transcript [ 'coding_sequence_name' ] = coding_sequence_name protein_sequence_name = None if len ( protein_sequence_entry ) > 1 : protein_sequence_name = protein_sequence_entry [ - 1 ] transcript [ 'protein_sequence_name' ] = protein_sequence_name transcript [ 'biotype' ] = entry . get ( 'BIOTYPE' ) transcript [ 'exon' ] = entry . get ( 'EXON' ) transcript [ 'intron' ] = entry . get ( 'INTRON' ) if entry . get ( 'STRAND' ) : if entry [ 'STRAND' ] == '1' : transcript [ 'strand' ] = '+' elif entry [ 'STRAND' ] == '-1' : transcript [ 'strand' ] = '-' else : transcript [ 'strand' ] = None functional = [ ] regional = [ ] for annotation in functional_annotations : functional . append ( annotation ) regional . append ( SO_TERMS [ annotation ] [ 'region' ] ) transcript [ 'functional_annotations' ] = functional transcript [ 'region_annotations' ] = regional # Check if the transcript is marked cannonical by vep transcript [ 'is_canonical' ] = ( entry . get ( 'CANONICAL' ) == 'YES' ) # Check if the CADD score is available on transcript level cadd_phred = entry . get ( 'CADD_PHRED' ) if cadd_phred : transcript [ 'cadd' ] = float ( cadd_phred ) # Check frequencies # There are different keys for different versions of VEP # We only support version 90+ thousandg_freqs = [ ] gnomad_freqs = [ ] try : # The keys for VEP v90+: # 'AF' or '1000GAF' - 1000G all populations combined # 'xxx_AF' - 1000G (or NHLBI-ESP) individual populations # 'gnomAD_AF' - gnomAD exomes, all populations combined # 'gnomAD_xxx_AF' - gnomAD exomes, individual populations # 'MAX_AF' - Max of all populations (1000G, gnomAD exomes, ESP) # https://www.ensembl.org/info/docs/tools/vep/vep_formats.html # Loop over all keys to find frequency entries for key in entry : #All frequencies endswith AF if not key . endswith ( 'AF' ) : continue value = entry [ key ] if not value : continue # This is the 1000G max af information if ( key == 'AF' or key == '1000GAF' ) : transcript [ 'thousand_g_maf' ] = float ( value ) continue if key == 'GNOMAD_AF' : transcript [ 'gnomad_maf' ] = float ( value ) continue if key == 'EXAC_MAX_AF' : transcript [ 'exac_max' ] = float ( value ) transcript [ 'exac_maf' ] = float ( value ) continue if 'GNOMAD' in key : gnomad_freqs . append ( float ( value ) ) else : thousandg_freqs . append ( float ( value ) ) if thousandg_freqs : transcript [ 'thousandg_max' ] = max ( thousandg_freqs ) if gnomad_freqs : transcript [ 'gnomad_max' ] = max ( gnomad_freqs ) except Exception as err : LOG . debug ( "Something went wrong when parsing frequencies" ) LOG . debug ( "Only splitted and normalised VEP v90+ is supported" ) clinsig = entry . get ( 'CLIN_SIG' ) if clinsig : transcript [ 'clinsig' ] = clinsig . split ( '&' ) transcript [ 'dbsnp' ] = [ ] transcript [ 'cosmic' ] = [ ] variant_ids = entry . get ( 'EXISTING_VARIATION' ) if variant_ids : for variant_id in variant_ids . split ( '&' ) : if variant_id . startswith ( 'rs' ) : transcript [ 'dbsnp' ] . append ( variant_id ) elif variant_id . startswith ( 'COSM' ) : transcript [ 'cosmic' ] . append ( int ( variant_id [ 4 : ] ) ) yield transcript

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/nbformat/v3/nbbase.py#L194-L205<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def new_author ( name = None , email = None , affiliation = None , url = None ) : author = NotebookNode ( ) if name is not None : author . name = unicode ( name ) if email is not None : author . email = unicode ( email ) if affiliation is not None : author . affiliation = unicode ( affiliation ) if url is not None : author . url = unicode ( url ) return author

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/librosa/librosa/blob/180e8e6eb8f958fa6b20b8cba389f7945d508247/librosa/util/matching.py#L63-L113<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def __match_intervals ( intervals_from , intervals_to , strict = True ) : # pragma: no cover # sort index of the interval starts start_index = np . argsort ( intervals_to [ : , 0 ] ) # sort index of the interval ends end_index = np . argsort ( intervals_to [ : , 1 ] ) # and sorted values of starts start_sorted = intervals_to [ start_index , 0 ] # and ends end_sorted = intervals_to [ end_index , 1 ] search_ends = np . searchsorted ( start_sorted , intervals_from [ : , 1 ] , side = 'right' ) search_starts = np . searchsorted ( end_sorted , intervals_from [ : , 0 ] , side = 'left' ) output = np . empty ( len ( intervals_from ) , dtype = numba . uint32 ) for i in range ( len ( intervals_from ) ) : query = intervals_from [ i ] # Find the intervals that start after our query ends after_query = search_ends [ i ] # And the intervals that end after our query begins before_query = search_starts [ i ] # Candidates for overlapping have to (end after we start) and (begin before we end) candidates = set ( start_index [ : after_query ] ) & set ( end_index [ before_query : ] ) # Proceed as before if len ( candidates ) > 0 : output [ i ] = __match_interval_overlaps ( query , intervals_to , candidates ) elif strict : # Numba only lets us use compile-time constants in exception messages raise ParameterError else : # Find the closest interval # (start_index[after_query] - query[1]) is the distance to the next interval # (query[0] - end_index[before_query]) dist_before = np . inf dist_after = np . inf if search_starts [ i ] > 0 : dist_before = query [ 0 ] - end_sorted [ search_starts [ i ] - 1 ] if search_ends [ i ] + 1 < len ( intervals_to ) : dist_after = start_sorted [ search_ends [ i ] + 1 ] - query [ 1 ] if dist_before < dist_after : output [ i ] = end_index [ search_starts [ i ] - 1 ] else : output [ i ] = start_index [ search_ends [ i ] + 1 ] return output

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ingolemo/python-lenses/blob/a3a6ed0a31f6674451e542e7380a8aa16e6f8edf/lenses/optics/base.py#L128-L136<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def apply ( self , f , pure , state ) : return self . func ( Functorisor ( pure , f ) , state )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/DiscordBotList/DBL-Python-Library/blob/c1461ae0acc644cdeedef8fd6b5e36f76d81c1aa/dbl/client.py#L96-L115<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>async def post_guild_count ( self , shard_count : int = None , shard_no : int = None ) : await self . http . post_guild_count ( self . bot_id , self . guild_count ( ) , shard_count , shard_no )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ingolemo/python-lenses/blob/a3a6ed0a31f6674451e542e7380a8aa16e6f8edf/lenses/optics/base.py#L188-L200<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def over ( self , state , fn ) : # type: (S, Callable[[A], B]) -> T if not self . _is_kind ( Setter ) : raise TypeError ( 'Must be an instance of Setter to .over()' ) pure = lambda a : Identity ( a ) func = lambda a : Identity ( fn ( a ) ) return self . apply ( func , pure , state ) . unwrap ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/utils/acmg.py#L57-L104<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def is_likely_pathogenic ( pvs , ps_terms , pm_terms , pp_terms ) : if pvs : # Likely Pathogenic (i): if pm_terms : return True if ps_terms : # Likely Pathogenic (ii): if pm_terms : return True # Likely Pathogenic (iii): if len ( pp_terms ) >= 2 : return True if pm_terms : # Likely Pathogenic (iv): if len ( pm_terms ) >= 3 : return True # Likely Pathogenic (v): elif len ( pm_terms ) >= 2 : if len ( pp_terms ) >= 2 : return True # Likely Pathogenic (vi): elif len ( pp_terms ) >= 4 : return True return False

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/pulse/timeslots.py#L72-L81<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def shift ( self , time : int ) -> 'Interval' : return Interval ( self . _begin + time , self . _end + time )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/uogbuji/amara3-xml/blob/88c18876418cffc89bb85b4a3193e5002b6b39a6/pylib/uxml/uxpath/functions.py#L141-L147<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def contains ( ctx , full , part ) : full = next ( string_arg ( ctx , full ) , '' ) part = next ( string_arg ( ctx , part ) , '' ) yield part in full

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chrisrink10/basilisp/blob/3d82670ee218ec64eb066289c82766d14d18cc92/src/basilisp/lang/reader.py#L818-L824<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _read_syntax_quoted ( ctx : ReaderContext ) -> ReaderForm : start = ctx . reader . advance ( ) assert start == "`" with ctx . syntax_quoted ( ) : return _process_syntax_quoted_form ( ctx , _read_next_consuming_comment ( ctx ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/lmjohns3/theanets/blob/79db9f878ef2071f2f576a1cf5d43a752a55894a/theanets/graph.py#L700-L710<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def updates ( self , * * kwargs ) : regs = regularizers . from_kwargs ( self , * * kwargs ) _ , updates = self . build_graph ( regs ) return updates

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/utils/shared_utils.py#L341-L352<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def normalize_slice ( s , total ) : newstart = 0 if s . start is None else max ( 0 , s . start + total ) if s . start < 0 else min ( s . start , total ) newstop = total if s . stop is None else max ( 0 , s . stop + total ) if s . stop < 0 else min ( s . stop , total ) newstep = 1 if s . step is None else s . step return slice ( newstart , newstop , newstep )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/lib/inputhook.py#L272-L296<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def enable_gtk ( self , app = None ) : import gtk try : gtk . set_interactive ( True ) self . _current_gui = GUI_GTK except AttributeError : # For older versions of gtk, use our own ctypes version from IPython . lib . inputhookgtk import inputhook_gtk self . set_inputhook ( inputhook_gtk ) self . _current_gui = GUI_GTK

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/terminal/ipapp.py#L368-L382<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def load_default_config ( ipython_dir = None ) : if ipython_dir is None : ipython_dir = get_ipython_dir ( ) profile_dir = os . path . join ( ipython_dir , 'profile_default' ) cl = PyFileConfigLoader ( default_config_file_name , profile_dir ) try : config = cl . load_config ( ) except ConfigFileNotFound : # no config found config = Config ( ) return config

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chrisrink10/basilisp/blob/3d82670ee218ec64eb066289c82766d14d18cc92/src/basilisp/lang/compiler/optimizer.py#L18-L29<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def visit_ExceptHandler ( self , node : ast . ExceptHandler ) -> Optional [ ast . AST ] : new_node = self . generic_visit ( node ) assert isinstance ( new_node , ast . ExceptHandler ) return ast . copy_location ( ast . ExceptHandler ( type = new_node . type , name = new_node . name , body = _filter_dead_code ( new_node . body ) , ) , new_node , )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neherlab/treetime/blob/f6cdb58d19243a18ffdaa2b2ec71872fa00e65c0/treetime/gtr.py#L734-L818<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def optimal_t_compressed ( self , seq_pair , multiplicity , profiles = False , tol = 1e-10 ) : def _neg_prob ( t , seq_pair , multiplicity ) : """             Probability to observe a child given the the parent state, transition             matrix, and the time of evolution (branch length).              Parameters             ----------               t : double                 Branch length (time between sequences)               parent :  numpy.array                 Parent sequence               child : numpy.array                 Child sequence               tm :  GTR                 Model of evolution              Returns             -------               prob : double                 Negative probability of the two given sequences                 to be separated by the time t.             """ if profiles : res = - 1.0 * self . prob_t_profiles ( seq_pair , multiplicity , t ** 2 , return_log = True ) return res else : return - 1.0 * self . prob_t_compressed ( seq_pair , multiplicity , t ** 2 , return_log = True ) try : from scipy . optimize import minimize_scalar opt = minimize_scalar ( _neg_prob , bounds = [ - np . sqrt ( ttconf . MAX_BRANCH_LENGTH ) , np . sqrt ( ttconf . MAX_BRANCH_LENGTH ) ] , args = ( seq_pair , multiplicity ) , tol = tol ) new_len = opt [ "x" ] ** 2 if 'success' not in opt : opt [ 'success' ] = True self . logger ( "WARNING: the optimization result does not contain a 'success' flag:" + str ( opt ) , 4 , warn = True ) except : import scipy print ( 'legacy scipy' , scipy . __version__ ) from scipy . optimize import fminbound new_len = fminbound ( _neg_prob , - np . sqrt ( ttconf . MAX_BRANCH_LENGTH ) , np . sqrt ( ttconf . MAX_BRANCH_LENGTH ) , args = ( seq_pair , multiplicity ) ) new_len = new_len ** 2 opt = { 'success' : True } if new_len > .9 * ttconf . MAX_BRANCH_LENGTH : self . logger ( "WARNING: GTR.optimal_t_compressed -- The branch length seems to be very long!" , 4 , warn = True ) if opt [ "success" ] != True : # return hamming distance: number of state pairs where state differs/all pairs new_len = np . sum ( multiplicity [ seq_pair [ : , 1 ] != seq_pair [ : , 0 ] ] ) / np . sum ( multiplicity ) return new_len

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/lensacom/sparkit-learn/blob/0498502107c1f7dcf33cda0cdb6f5ba4b42524b7/splearn/decomposition/truncated_svd.py#L310-L328<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def transform ( self , Z ) : X = Z [ : , 'X' ] if isinstance ( Z , DictRDD ) else Z check_rdd ( X , ( sp . spmatrix , np . ndarray ) ) mapper = self . broadcast ( super ( SparkTruncatedSVD , self ) . transform , Z . context ) return Z . transform ( mapper , column = 'X' , dtype = np . ndarray )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/spotify/pyschema/blob/7e6c3934150bcb040c628d74ace6caf5fcf867df/pyschema/source_generation.py#L193-L224<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _class_source ( schema , indent ) : def_pattern = ( "class {class_name}(pyschema.Record):\n" "{indent}# WARNING: This class was generated by pyschema.to_python_source\n" "{indent}# there is a risk that any modification made to this class will be overwritten\n" "{optional_namespace_def}" "{field_defs}\n" ) if hasattr ( schema , '_namespace' ) : optional_namespace_def = "{indent}_namespace = {namespace!r}\n" . format ( namespace = schema . _namespace , indent = indent ) else : optional_namespace_def = "" field_defs = [ "{indent}{field_name} = {field!r}" . format ( field_name = field_name , field = field , indent = indent ) for field_name , field in schema . _fields . iteritems ( ) ] if not field_defs : field_defs = [ "{indent}pass" . format ( indent = indent ) ] return def_pattern . format ( class_name = schema . _schema_name , optional_namespace_def = optional_namespace_def , field_defs = "\n" . join ( field_defs ) , indent = indent )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/gnosis/gnosis-py/blob/2a9a5d75a375fc9813ac04df133e6910c82f9d49/gnosis/safe/safe_service.py#L544-L548<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def estimate_tx_gas_with_web3 ( self , safe_address : str , to : str , value : int , data : bytes ) -> int : return self . ethereum_client . estimate_gas ( safe_address , to , value , data , block_identifier = 'pending' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/kadrlica/pymodeler/blob/f426c01416fd4b8fc3afeeb6d3b5d1cb0cb8f8e3/pymodeler/model.py#L377-L384<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def clear_derived ( self ) : for p in self . params . values ( ) : if isinstance ( p , Derived ) : p . clear_value ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/boundary/pulse-api-cli/blob/b01ca65b442eed19faac309c9d62bbc3cb2c098f/boundary/metric_export.py#L69-L82<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def filter ( self ) : if self . filter_expression is not None : new_metrics = [ ] metrics = self . metrics [ 'result' ] for m in metrics : if self . filter_expression . search ( m [ 'name' ] ) : new_metrics . append ( m ) else : new_metrics = self . metrics [ 'result' ] self . metrics = self . extract_dictionary ( new_metrics )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/wheel/metadata.py#L207-L214<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def requires_to_requires_dist ( requirement ) : requires_dist = [ ] for op , ver in requirement . specs : requires_dist . append ( op + ver ) if not requires_dist : return '' return " (%s)" % ',' . join ( requires_dist )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/mcmc/eight_schools_hmc.py#L63-L129<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def benchmark_eight_schools_hmc ( num_results = int ( 5e3 ) , num_burnin_steps = int ( 3e3 ) , num_leapfrog_steps = 3 , step_size = 0.4 ) : num_schools = 8 treatment_effects = tf . constant ( [ 28 , 8 , - 3 , 7 , - 1 , 1 , 18 , 12 ] , dtype = np . float32 , name = 'treatment_effects' ) treatment_stddevs = tf . constant ( [ 15 , 10 , 16 , 11 , 9 , 11 , 10 , 18 ] , dtype = np . float32 , name = 'treatment_stddevs' ) def unnormalized_posterior_log_prob ( avg_effect , avg_stddev , school_effects_standard ) : """Eight-schools unnormalized log posterior.""" return eight_schools_joint_log_prob ( treatment_effects , treatment_stddevs , avg_effect , avg_stddev , school_effects_standard ) if tf . executing_eagerly ( ) : sample_chain = tf . function ( tfp . mcmc . sample_chain ) else : sample_chain = tfp . mcmc . sample_chain def computation ( ) : """The benchmark computation.""" _ , kernel_results = sample_chain ( num_results = num_results , num_burnin_steps = num_burnin_steps , current_state = ( tf . zeros ( [ ] , name = 'init_avg_effect' ) , tf . zeros ( [ ] , name = 'init_avg_stddev' ) , tf . ones ( [ num_schools ] , name = 'init_school_effects_standard' ) , ) , kernel = tfp . mcmc . HamiltonianMonteCarlo ( target_log_prob_fn = unnormalized_posterior_log_prob , step_size = step_size , num_leapfrog_steps = num_leapfrog_steps ) ) return kernel_results . is_accepted # Let's force evaluation of graph to ensure build time is not part of our time # trial. is_accepted_tensor = computation ( ) if not tf . executing_eagerly ( ) : session = tf . compat . v1 . Session ( ) session . run ( is_accepted_tensor ) start_time = time . time ( ) if tf . executing_eagerly ( ) : is_accepted = computation ( ) else : is_accepted = session . run ( is_accepted_tensor ) wall_time = time . time ( ) - start_time num_accepted = np . sum ( is_accepted ) acceptance_rate = np . float32 ( num_accepted ) / np . float32 ( num_results ) return dict ( iters = ( num_results + num_burnin_steps ) * num_leapfrog_steps , extras = { 'acceptance_rate' : acceptance_rate } , wall_time = wall_time )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/quantum_info/operators/channel/quantum_channel.py#L44-L50<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def is_unitary ( self , atol = None , rtol = None ) : try : op = self . to_operator ( ) return op . is_unitary ( atol = atol , rtol = rtol ) except QiskitError : return False

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/utils/log/es_task_handler.py#L83-L124<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _read ( self , ti , try_number , metadata = None ) : if not metadata : metadata = { 'offset' : 0 } if 'offset' not in metadata : metadata [ 'offset' ] = 0 offset = metadata [ 'offset' ] log_id = self . _render_log_id ( ti , try_number ) logs = self . es_read ( log_id , offset ) next_offset = offset if not logs else logs [ - 1 ] . offset metadata [ 'offset' ] = next_offset # end_of_log_mark may contain characters like '\n' which is needed to # have the log uploaded but will not be stored in elasticsearch. metadata [ 'end_of_log' ] = False if not logs else logs [ - 1 ] . message == self . end_of_log_mark . strip ( ) cur_ts = pendulum . now ( ) # Assume end of log after not receiving new log for 5 min, # as executor heartbeat is 1 min and there might be some # delay before Elasticsearch makes the log available. if 'last_log_timestamp' in metadata : last_log_ts = timezone . parse ( metadata [ 'last_log_timestamp' ] ) if cur_ts . diff ( last_log_ts ) . in_minutes ( ) >= 5 : metadata [ 'end_of_log' ] = True if offset != next_offset or 'last_log_timestamp' not in metadata : metadata [ 'last_log_timestamp' ] = str ( cur_ts ) message = '\n' . join ( [ log . message for log in logs ] ) return message , metadata

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/bicv/LogGabor/blob/dea9560d8752cc9aa040ac3fd895cf9bb72b61f4/LogGabor/LogGabor.py#L123-L143<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def band ( self , sf_0 , B_sf , force = False ) : if sf_0 == 0. : return 1. elif self . pe . use_cache and not force : tag = str ( sf_0 ) + '_' + str ( B_sf ) try : return self . cache [ 'band' ] [ tag ] except : if self . pe . verbose > 50 : print ( 'doing band cache for tag ' , tag ) self . cache [ 'band' ] [ tag ] = self . band ( sf_0 , B_sf , force = True ) return self . cache [ 'band' ] [ tag ] else : # see http://en.wikipedia.org/wiki/Log-normal_distribution env = 1. / self . f * np . exp ( - .5 * ( np . log ( self . f / sf_0 ) ** 2 ) / B_sf ** 2 ) return env

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/server/blueprints/cases/views.py#L162-L192<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def matchmaker_match ( institute_id , case_name , target ) : institute_obj , case_obj = institute_and_case ( store , institute_id , case_name ) # check that only authorized users can run matches user_obj = store . user ( current_user . email ) if 'mme_submitter' not in user_obj [ 'roles' ] : flash ( 'unauthorized request' , 'warning' ) return redirect ( request . referrer ) # Required params for sending an add request to MME: mme_base_url = current_app . config . get ( 'MME_URL' ) mme_accepts = current_app . config . get ( 'MME_ACCEPTS' ) mme_token = current_app . config . get ( 'MME_TOKEN' ) nodes = current_app . mme_nodes if not mme_base_url or not mme_token or not mme_accepts : flash ( 'An error occurred reading matchmaker connection parameters. Please check config file!' , 'danger' ) return redirect ( request . referrer ) match_results = controllers . mme_match ( case_obj , target , mme_base_url , mme_token , nodes , mme_accepts ) ok_responses = 0 for match_results in match_results : match_results [ 'status_code' ] == 200 ok_responses += 1 if ok_responses : flash ( "Match request sent. Look for eventual matches in 'Matches' page." , 'info' ) else : flash ( 'An error occurred while sending match request.' , 'danger' ) return redirect ( request . referrer )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/classes.py#L1382-L1444<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _check_first_arg_for_type ( self , node , metaclass = 0 ) : # don't care about functions with unknown argument (builtins) if node . args . args is None : return first_arg = node . args . args and node . argnames ( ) [ 0 ] self . _first_attrs . append ( first_arg ) first = self . _first_attrs [ - 1 ] # static method if node . type == "staticmethod" : if ( first_arg == "self" or first_arg in self . config . valid_classmethod_first_arg or first_arg in self . config . valid_metaclass_classmethod_first_arg ) : self . add_message ( "bad-staticmethod-argument" , args = first , node = node ) return self . _first_attrs [ - 1 ] = None # class / regular method with no args elif not node . args . args : self . add_message ( "no-method-argument" , node = node ) # metaclass elif metaclass : # metaclass __new__ or classmethod if node . type == "classmethod" : self . _check_first_arg_config ( first , self . config . valid_metaclass_classmethod_first_arg , node , "bad-mcs-classmethod-argument" , node . name , ) # metaclass regular method else : self . _check_first_arg_config ( first , self . config . valid_classmethod_first_arg , node , "bad-mcs-method-argument" , node . name , ) # regular class else : # class method if node . type == "classmethod" or node . name == "__class_getitem__" : self . _check_first_arg_config ( first , self . config . valid_classmethod_first_arg , node , "bad-classmethod-argument" , node . name , ) # regular method without self as argument elif first != "self" : self . add_message ( "no-self-argument" , node = node )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/mcmc/eight_schools_hmc.py#L44-L60<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def eight_schools_joint_log_prob ( treatment_effects , treatment_stddevs , avg_effect , avg_stddev , school_effects_standard ) : rv_avg_effect = tfd . Normal ( loc = 0. , scale = 10. ) rv_avg_stddev = tfd . Normal ( loc = 5. , scale = 1. ) rv_school_effects_standard = mvn ( loc = tf . zeros_like ( school_effects_standard ) , scale = tf . ones_like ( school_effects_standard ) ) rv_treatment_effects = mvn ( loc = ( avg_effect + tf . exp ( avg_stddev ) * school_effects_standard ) , scale = treatment_stddevs ) return ( rv_avg_effect . log_prob ( avg_effect ) + rv_avg_stddev . log_prob ( avg_stddev ) + rv_school_effects_standard . log_prob ( school_effects_standard ) + rv_treatment_effects . log_prob ( treatment_effects ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/capitalone/giraffez/blob/6b4d27eb1a1eaf188c6885c7364ef27e92b1b957/giraffez/load.py#L322-L339<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def tables ( self ) : if self . table is None : raise GiraffeError ( "Target table has not been set." ) return [ "{}_wt" . format ( self . table ) , "{}_log" . format ( self . table ) , "{}_e1" . format ( self . table ) , "{}_e2" . format ( self . table ) , ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/UCBerkeleySETI/blimpy/blob/b8822d3e3e911944370d84371a91fa0c29e9772e/blimpy/file_wrapper.py#L418-L435<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def read_data ( self , f_start = None , f_stop = None , t_start = None , t_stop = None ) : self . _setup_selection_range ( f_start = f_start , f_stop = f_stop , t_start = t_start , t_stop = t_stop ) #check if selection is small enough. if self . isheavy ( ) : logger . warning ( "Selection size of %.2f GB, exceeding our size limit %.2f GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection." % ( self . _calc_selection_size ( ) / ( 1024. ** 3 ) , self . MAX_DATA_ARRAY_SIZE / ( 1024. ** 3 ) ) ) self . data = np . array ( [ 0 ] , dtype = self . _d_type ) return None #Convert input frequencies into what their corresponding channel number would be. self . _setup_chans ( ) #Update frequencies ranges from channel number. self . _setup_freqs ( ) self . data = self . h5 [ "data" ] [ self . t_start : self . t_stop , : , self . chan_start_idx : self . chan_stop_idx ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/oscarbranson/latools/blob/cd25a650cfee318152f234d992708511f7047fbe/latools/filtering/classifier_obj.py#L220-L245<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def map_clusters ( self , size , sampled , clusters ) : ids = np . zeros ( size , dtype = int ) ids [ : ] = - 2 ids [ sampled ] = clusters return ids

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/core/interactiveshell.py#L2377-L2380<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def ex ( self , cmd ) : with self . builtin_trap : exec cmd in self . user_global_ns , self . user_ns

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mental32/spotify.py/blob/bb296cac7c3dd289908906b7069bd80f43950515/spotify/models/artist.py#L119-L135<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>async def top_tracks ( self , country : str = 'US' ) -> List [ Track ] : from . track import Track top = await self . __client . http . artist_top_tracks ( self . id , country = country ) return list ( Track ( self . __client , item ) for item in top [ 'tracks' ] )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SmokinCaterpillar/pypet/blob/97ad3e80d46dbdea02deeb98ea41f05a19565826/pypet/brian2/network.py#L667-L696<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def run_network ( self , traj ) : # Check if the network was pre-built if self . _pre_built : if self . _pre_run and hasattr ( self . _network , 'restore' ) : self . _network . restore ( 'pre_run' ) # Temprorary fix for https://github.com/brian-team/brian2/issues/681 self . _network . store ( 'pre_run' ) self . _run_network ( traj ) else : self . _run_network ( traj )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/imports.py#L55-L64<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _qualified_names ( modname ) : names = modname . split ( "." ) return [ "." . join ( names [ 0 : i + 1 ] ) for i in range ( len ( names ) ) ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/iotaledger/iota.lib.py/blob/97cdd1e241498446b46157b79b2a1ea2ec6d387a/iota/transaction/base.py#L310-L341<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def as_json_compatible ( self ) : # type: () -> dict return { 'hash_' : self . hash , 'signature_message_fragment' : self . signature_message_fragment , 'address' : self . address , 'value' : self . value , 'legacy_tag' : self . legacy_tag , 'timestamp' : self . timestamp , 'current_index' : self . current_index , 'last_index' : self . last_index , 'bundle_hash' : self . bundle_hash , 'trunk_transaction_hash' : self . trunk_transaction_hash , 'branch_transaction_hash' : self . branch_transaction_hash , 'tag' : self . tag , 'attachment_timestamp' : self . attachment_timestamp , 'attachment_timestamp_lower_bound' : self . attachment_timestamp_lower_bound , 'attachment_timestamp_upper_bound' : self . attachment_timestamp_upper_bound , 'nonce' : self . nonce , }

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/calston/tensor/blob/7c0c99708b5dbff97f3895f705e11996b608549d/tensor/protocol/riemann.py#L12-L37<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def encodeEvent ( self , event ) : pbevent = proto_pb2 . Event ( time = int ( event . time ) , state = event . state , service = event . service , host = event . hostname , description = event . description , tags = event . tags , ttl = event . ttl , ) if event . metric is not None : # I have no idea what I'm doing if isinstance ( event . metric , int ) : pbevent . metric_sint64 = event . metric pbevent . metric_f = float ( event . metric ) else : pbevent . metric_d = float ( event . metric ) pbevent . metric_f = float ( event . metric ) if event . attributes is not None : for key , value in event . attributes . items ( ) : attribute = pbevent . attributes . add ( ) attribute . key , attribute . value = key , value return pbevent

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/OpenKMIP/PyKMIP/blob/b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e/kmip/services/server/crypto/engine.py#L792-L880<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _decrypt_asymmetric ( self , decryption_algorithm , decryption_key , cipher_text , padding_method , hashing_algorithm = None ) : if decryption_algorithm == enums . CryptographicAlgorithm . RSA : if padding_method == enums . PaddingMethod . OAEP : hash_algorithm = self . _encryption_hash_algorithms . get ( hashing_algorithm ) if hash_algorithm is None : raise exceptions . InvalidField ( "The hashing algorithm '{0}' is not supported for " "asymmetric decryption." . format ( hashing_algorithm ) ) padding_method = asymmetric_padding . OAEP ( mgf = asymmetric_padding . MGF1 ( algorithm = hash_algorithm ( ) ) , algorithm = hash_algorithm ( ) , label = None ) elif padding_method == enums . PaddingMethod . PKCS1v15 : padding_method = asymmetric_padding . PKCS1v15 ( ) else : raise exceptions . InvalidField ( "The padding method '{0}' is not supported for asymmetric " "decryption." . format ( padding_method ) ) backend = default_backend ( ) try : private_key = backend . load_der_private_key ( decryption_key , None ) except Exception : try : private_key = backend . load_pem_private_key ( decryption_key , None ) except Exception : raise exceptions . CryptographicFailure ( "The private key bytes could not be loaded." ) plain_text = private_key . decrypt ( cipher_text , padding_method ) return plain_text else : raise exceptions . InvalidField ( "The cryptographic algorithm '{0}' is not supported for " "asymmetric decryption." . format ( decryption_algorithm ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/schul-cloud/resources-api-v1/blob/58b2d7ba13669fa013ef81c0ffcffbf6b3fdb52d/generators/python_client/schul_cloud_resources_api_v1/auth.py#L27-L31<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def basic ( username , password ) : none ( ) _config . username = username _config . password = password

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/expr.py#L382-L409<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _tabulate ( self , tablefmt = "simple" , rollups = False , rows = 10 ) : if not self . is_valid ( ) : self . fill ( rows = rows ) # Pretty print cached data d = collections . OrderedDict ( ) # If also printing the rollup stats, build a full row-header if rollups : col = next ( iter ( viewvalues ( self . _data ) ) ) # Get a sample column lrows = len ( col [ 'data' ] ) # Cached rows being displayed d [ "" ] = [ "type" , "mins" , "mean" , "maxs" , "sigma" , "zeros" , "missing" ] + list ( map ( str , range ( lrows ) ) ) # For all columns... for k , v in viewitems ( self . _data ) : x = v [ 'data' ] # Data to display t = v [ "type" ] # Column type if t == "enum" : domain = v [ 'domain' ] # Map to cat strings as needed x = [ "" if math . isnan ( idx ) else domain [ int ( idx ) ] for idx in x ] elif t == "time" : x = [ "" if math . isnan ( z ) else time . strftime ( "%Y-%m-%d %H:%M:%S" , time . gmtime ( z / 1000 ) ) for z in x ] if rollups : # Rollups, if requested mins = v [ 'mins' ] [ 0 ] if v [ 'mins' ] and v [ "type" ] != "enum" else None maxs = v [ 'maxs' ] [ 0 ] if v [ 'maxs' ] and v [ "type" ] != "enum" else None #Cross check type with mean and sigma. Set to None if of type enum. if v [ 'type' ] == "enum" : v [ 'mean' ] = v [ 'sigma' ] = v [ 'zero_count' ] = None x = [ v [ 'type' ] , mins , v [ 'mean' ] , maxs , v [ 'sigma' ] , v [ 'zero_count' ] , v [ 'missing_count' ] ] + x d [ k ] = x # Insert into ordered-dict return tabulate . tabulate ( d , headers = "keys" , tablefmt = tablefmt )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/3DLIRIOUS/MeshLabXML/blob/177cce21e92baca500f56a932d66bd9a33257af8/meshlabxml/mlx.py#L623-L691<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def begin ( script = 'TEMP3D_default.mlx' , file_in = None , mlp_in = None ) : script_file = open ( script , 'w' ) script_file . write ( '' . join ( [ '<!DOCTYPE FilterScript>\n' , '<FilterScript>\n' ] ) ) script_file . close ( ) current_layer = - 1 last_layer = - 1 stl = False # Process project files first if mlp_in is not None : # make a list if it isn't already if not isinstance ( mlp_in , list ) : mlp_in = [ mlp_in ] for val in mlp_in : tree = ET . parse ( val ) #root = tree.getroot() for elem in tree . iter ( tag = 'MLMesh' ) : filename = ( elem . attrib [ 'filename' ] ) current_layer += 1 last_layer += 1 # If the mesh file extension is stl, change to that layer and # run clean.merge_vert if os . path . splitext ( filename ) [ 1 ] [ 1 : ] . strip ( ) . lower ( ) == 'stl' : layers . change ( script , current_layer ) clean . merge_vert ( script ) stl = True # Process separate input files next if file_in is not None : # make a list if it isn't already if not isinstance ( file_in , list ) : file_in = [ file_in ] for val in file_in : current_layer += 1 last_layer += 1 # If the mesh file extension is stl, change to that layer and # run clean.merge_vert if os . path . splitext ( val ) [ 1 ] [ 1 : ] . strip ( ) . lower ( ) == 'stl' : layers . change ( script , current_layer ) clean . merge_vert ( script ) stl = True # If some input files were stl, we need to change back to the last layer if stl : layers . change ( script , last_layer ) # Change back to the last layer elif last_layer == - 1 : # If no input files are provided, create a dummy file # with a single vertex and delete it first in the script. # This works around the fact that meshlabserver will # not run without an input file. file_in = [ 'TEMP3D.xyz' ] file_in_descriptor = open ( file_in [ 0 ] , 'w' ) file_in_descriptor . write ( '0 0 0' ) file_in_descriptor . close ( ) layers . delete ( script ) return current_layer , last_layer

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/sts/seasonal.py#L628-L691<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def build_constrained_seasonal_transition_noise ( drift_scale , num_seasons , is_last_day_of_season ) : # Conceptually, this method takes the noise covariance on effects L @ L' # computed by `build_seasonal_transition_noise`, with scale factor #       L = [ 0, 0, ..., 0 #             ... #             0, 0, ..., drift_scale], # and transforms it to act on the constrained-residual representation. # # The resulting noise covariance M @ M' is equivalent to #    M @ M' = effects_to_residuals @ LL' @ residuals_to_effects # where `@` is matrix multiplication. However because this matrix is # rank-deficient, we can't take its Cholesky decomposition directly, so we'll # construct its lower-triangular scale factor `M` by hand instead. # # Concretely, let `M = P @ R @ L` be the scale factor in the # transformed space, with matrices `R`, `P` applying the reparameterization # and zero-mean constraint respectively as defined in the # "Mathematical Details" section of `ConstrainedSeasonalStateSpaceModel`. It's # easy to see (*) that the implied covariance # `M @ M' = P @ R @ L @ L' @ R' @ P'` is just the constant matrix #  `M @ M' = [ 1, 1, ..., 1, 0 #              1, 1, ..., 1, 0 #              ... #              1, 1, ..., 1, 0 #              0, 0, ..., 0, 0] * (drift_scale / num_seasons)**2` # with zeros in the final row and column. So we can directly construct # the lower-triangular factor #  `Q = [ 1, 0, ...  0 #         1, 0, ..., 0 #         ... #         1, 0, ..., 0 #         0, 0, ..., 0 ] * drift_scale/num_seasons` # such that Q @ Q' = M @ M'. In practice, we don't reify the final row and # column full of zeroes, i.e., we construct # `Q[:num_seasons-1, :num_seasons-1]` as the scale-TriL covariance factor. # # (*) Argument: `L` is zero everywhere but the last column, so `R @ L` will be # too. Since the last column of `R` is the constant `-1/num_seasons`, `R @ L` # is simply the matrix with constant `-drift_scale/num_seasons` in the final # column (except the final row, which is negated) and zero in all other # columns, and `M = P @ R @ L` additionally zeroes out the final row. Then # M @ M' is just the outer product of that final column with itself (since all # other columns are zero), which gives the matrix shown above. drift_scale_tril_nonzeros = tf . concat ( [ tf . ones ( [ num_seasons - 1 , 1 ] , dtype = drift_scale . dtype ) , tf . zeros ( [ num_seasons - 1 , num_seasons - 2 ] , dtype = drift_scale . dtype ) ] , axis = - 1 ) drift_scale_tril = ( drift_scale_tril_nonzeros * drift_scale [ ... , tf . newaxis , tf . newaxis ] / num_seasons ) # Inject transition noise iff it is the last day of the season. def seasonal_transition_noise ( t ) : noise_scale_tril = dist_util . pick_scalar_condition ( is_last_day_of_season ( t ) , drift_scale_tril , tf . zeros_like ( drift_scale_tril ) ) return tfd . MultivariateNormalTriL ( loc = tf . zeros ( num_seasons - 1 , dtype = drift_scale . dtype ) , scale_tril = noise_scale_tril ) return seasonal_transition_noise

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Azure/azure-sdk-for-python/blob/d7306fde32f60a293a7567678692bdad31e4b667/azure-servicemanagement-legacy/azure/servicemanagement/servicemanagementservice.py#L1304-L1320<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_role ( self , service_name , deployment_name , role_name ) : _validate_not_none ( 'service_name' , service_name ) _validate_not_none ( 'deployment_name' , deployment_name ) _validate_not_none ( 'role_name' , role_name ) return self . _perform_get ( self . _get_role_path ( service_name , deployment_name , role_name ) , PersistentVMRole )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/parse/panel.py#L38-L75<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_panel_info ( panel_lines = None , panel_id = None , institute = None , version = None , date = None , display_name = None ) : panel_info = { 'panel_id' : panel_id , 'institute' : institute , 'version' : version , 'date' : date , 'display_name' : display_name , } if panel_lines : for line in panel_lines : line = line . rstrip ( ) if not line . startswith ( '##' ) : break info = line [ 2 : ] . split ( '=' ) field = info [ 0 ] value = info [ 1 ] if not panel_info . get ( field ) : panel_info [ field ] = value panel_info [ 'date' ] = get_date ( panel_info [ 'date' ] ) return panel_info

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/bin/cli.py#L88-L103<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def sigquit_handler ( sig , frame ) : print ( "Dumping stack traces for all threads in PID {}" . format ( os . getpid ( ) ) ) id_to_name = dict ( [ ( th . ident , th . name ) for th in threading . enumerate ( ) ] ) code = [ ] for thread_id , stack in sys . _current_frames ( ) . items ( ) : code . append ( "\n# Thread: {}({})" . format ( id_to_name . get ( thread_id , "" ) , thread_id ) ) for filename , line_number , name , line in traceback . extract_stack ( stack ) : code . append ( 'File: "{}", line {}, in {}' . format ( filename , line_number , name ) ) if line : code . append ( "  {}" . format ( line . strip ( ) ) ) print ( "\n" . join ( code ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/pmacosta/peng/blob/976935377adaa3de26fc5677aceb2cdfbd6f93a7/peng/functions.py#L700-L761<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def remove_extra_delims ( expr , ldelim = "(" , rdelim = ")" ) : op_group = "" for item1 in _OP_PREC : if isinstance ( item1 , list ) : for item2 in item1 : op_group += item2 else : op_group += item1 iobj = zip ( [ expr , ldelim , rdelim ] , [ "expr" , "ldelim" , "rdelim" ] ) for item , desc in iobj : if not isinstance ( item , str ) : raise RuntimeError ( "Argument `{0}` is not valid" . format ( desc ) ) if ( len ( ldelim ) != 1 ) or ( ( len ( ldelim ) == 1 ) and ( ldelim in op_group ) ) : raise RuntimeError ( "Argument `ldelim` is not valid" ) if ( len ( rdelim ) != 1 ) or ( ( len ( rdelim ) == 1 ) and ( rdelim in op_group ) ) : raise RuntimeError ( "Argument `rdelim` is not valid" ) if expr . count ( ldelim ) != expr . count ( rdelim ) : raise RuntimeError ( "Mismatched delimiters" ) if not expr : return expr vchars = ( "abcdefghijklmnopqrstuvwxyz" "ABCDEFGHIJKLMNOPQRSTUVWXYZ" ".0123456789" r"_()[]\{\}" + rdelim + ldelim + op_group ) if any ( [ item not in vchars for item in expr ] ) or ( "__" in expr ) : raise RuntimeError ( "Argument `expr` is not valid" ) expr = _remove_consecutive_delims ( expr , ldelim = ldelim , rdelim = rdelim ) expr = expr . replace ( ldelim + rdelim , "" ) return _remove_extra_delims ( expr , ldelim = ldelim , rdelim = rdelim )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/willkg/markus/blob/0cfbe67fb7ccfa7488b0120d21ddc0cdc1f8ed33/markus/backends/logging.py#L86-L88<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def histogram ( self , stat , value , tags = None ) : self . _log ( 'histogram' , stat , value , tags )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/core/inputsplitter.py#L682-L685<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _tr_quote ( line_info ) : return '%s%s("%s")' % ( line_info . pre , line_info . ifun , '", "' . join ( line_info . the_rest . split ( ) ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/scripts/logscrapedaily.py#L516-L589<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def grab_java_message ( ) : global g_temp_filename global g_current_testname global g_java_start_text global g_ok_java_messages global g_java_general_bad_messages # store bad java messages not associated with running a unit test global g_java_general_bad_message_types global g_failure_occurred global g_java_message_type global g_all_java_message_type global g_toContinue java_messages = [ ] # store all bad java messages associated with running a unit test java_message_types = [ ] # store all bad java message types associated with running a unit test if os . path . isfile ( g_temp_filename ) : # open temp file containing content of some java_*_0.out.txt java_file = open ( g_temp_filename , 'r' ) g_toContinue = False # denote if a multi-line message starts tempMessage = "" messageType = "" for each_line in java_file : if ( g_java_start_text in each_line ) : startStr , found , endStr = each_line . partition ( g_java_start_text ) if len ( found ) > 0 : if len ( g_current_testname ) > 0 : # a new unit test is being started.  Save old info and move on associate_test_with_java ( g_current_testname , java_messages , java_message_types ) g_current_testname = endStr . strip ( ) # record the test name java_messages = [ ] java_message_types = [ ] temp_strings = each_line . strip ( ) . split ( ) if ( len ( temp_strings ) >= 6 ) and ( temp_strings [ 5 ] in g_all_java_message_type ) : if g_toContinue == True : # at the end of last message fragment addJavaMessages ( tempMessage , messageType , java_messages , java_message_types ) tempMessage = "" messageType = "" # start of new message fragment g_toContinue = False else : # non standard output.  Continuation of last java message, add it to bad java message list if g_toContinue : tempMessage += each_line # add more java message here # if len(g_current_testname) == 0: #     addJavaMessages(each_line.strip(),"",java_messages,java_message_types) # else: #     addJavaMessages(each_line.strip(),"",java_messages,java_message_types) if ( ( len ( temp_strings ) > 5 ) and ( temp_strings [ 5 ] in g_java_message_type ) ) : # find a bad java message startStr , found , endStr = each_line . partition ( temp_strings [ 5 ] ) # can be WARN,ERRR,FATAL,TRACE if found and ( len ( endStr . strip ( ) ) > 0 ) : tempMessage += endStr messageType = temp_strings [ 5 ] #                    if (tempMessage not in g_ok_java_messages["general"]):  # found new bad messages that cannot be ignored g_toContinue = True # add tempMessage to bad java message list #                        addJavaMessages(tempMessage,temp_strings[5],java_messages,java_message_types) java_file . close ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/eyeseast/python-frontmatter/blob/c318e583c48599eb597e0ad59c5d972258c3febc/frontmatter/default_handlers.py#L238-L242<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def export ( self , metadata , * * kwargs ) : kwargs . setdefault ( 'indent' , 4 ) metadata = json . dumps ( metadata , * * kwargs ) return u ( metadata )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ralphbean/bugwarrior/blob/b2a5108f7b40cb0c437509b64eaa28f941f7ac8b/bugwarrior/services/activecollab2.py#L46-L68<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_issue_generator ( self , user_id , project_id , project_name ) : user_tasks_data = self . call_api ( "/projects/" + six . text_type ( project_id ) + "/user-tasks" ) for key , task in enumerate ( user_tasks_data ) : assigned_task = self . get_task_dict ( project_id , key , task ) if assigned_task : log . debug ( " Adding '" + assigned_task [ 'description' ] + "' to task list." ) yield assigned_task

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/LordSputnik/mutagen/blob/38e62c8dc35c72b16554f5dbe7c0fde91acc3411/mutagen/flac.py#L702-L721<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def load ( self , filename ) : self . metadata_blocks = [ ] self . tags = None self . cuesheet = None self . seektable = None self . filename = filename fileobj = StrictFileObject ( open ( filename , "rb" ) ) try : self . __check_header ( fileobj ) while self . __read_metadata_block ( fileobj ) : pass finally : fileobj . close ( ) try : self . metadata_blocks [ 0 ] . length except ( AttributeError , IndexError ) : raise FLACNoHeaderError ( "Stream info block not found" )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/boto/s3transfer/blob/2aead638c8385d8ae0b1756b2de17e8fad45fffa/s3transfer/manager.py#L629-L655<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def wait ( self ) : try : transfer_coordinator = None for transfer_coordinator in self . tracked_transfer_coordinators : transfer_coordinator . result ( ) except KeyboardInterrupt : logger . debug ( 'Received KeyboardInterrupt in wait()' ) # If Keyboard interrupt is raised while waiting for # the result, then exit out of the wait and raise the # exception if transfer_coordinator : logger . debug ( 'On KeyboardInterrupt was waiting for %s' , transfer_coordinator ) raise except Exception : # A general exception could have been thrown because # of result(). We just want to ignore this and continue # because we at least know that the transfer coordinator # has completed. pass

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/theduke/django-baseline/blob/7be8b956e53c70b35f34e1783a8fe8f716955afb/django_baseline/templatetags/helpers.py#L127-L135<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def mul ( value , arg ) : try : return valid_numeric ( value ) * valid_numeric ( arg ) except ( ValueError , TypeError ) : try : return value * arg except Exception : return ''

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/zmq/pylab/backend_inline.py#L116-L156<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def draw_if_interactive ( ) : # signal that the current active figure should be sent at the end of # execution.  Also sets the _draw_called flag, signaling that there will be # something to send.  At the end of the code execution, a separate call to # flush_figures() will act upon these values fig = Gcf . get_active ( ) . canvas . figure # Hack: matplotlib FigureManager objects in interacive backends (at least # in some of them) monkeypatch the figure object and add a .show() method # to it.  This applies the same monkeypatch in order to support user code # that might expect `.show()` to be part of the official API of figure # objects. # For further reference: # https://github.com/ipython/ipython/issues/1612 # https://github.com/matplotlib/matplotlib/issues/835 if not hasattr ( fig , 'show' ) : # Queue up `fig` for display fig . show = lambda * a : send_figure ( fig ) # If matplotlib was manually set to non-interactive mode, this function # should be a no-op (otherwise we'll generate duplicate plots, since a user # who set ioff() manually expects to make separate draw/show calls). if not matplotlib . is_interactive ( ) : return # ensure current figure will be drawn, and each subsequent call # of draw_if_interactive() moves the active figure to ensure it is # drawn last try : show . _to_draw . remove ( fig ) except ValueError : # ensure it only appears in the draw list once pass # Queue up the figure for drawing in next show() call show . _to_draw . append ( fig ) show . _draw_called = True

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/rwl/godot/blob/013687c9e8983d2aa2ceebb8a76c5c4f1e37c90f/godot/component/ellipse.py#L137-L143<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _draw_bounds ( self , gc ) : dx , dy = self . bounds x , y = self . position gc . rect ( x , y , dx , dy ) gc . stroke_path ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/deepmipt/DeepPavlov/blob/f3e4a69a3764d25d2f5bad4f1f1aebc872b00f9c/deeppavlov/models/squad/utils.py#L144-L183<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def dot_attention ( inputs , memory , mask , att_size , keep_prob = 1.0 , scope = "dot_attention" ) : with tf . variable_scope ( scope ) : BS , IL , IH = tf . unstack ( tf . shape ( inputs ) ) BS , ML , MH = tf . unstack ( tf . shape ( memory ) ) d_inputs = tf . nn . dropout ( inputs , keep_prob = keep_prob , noise_shape = [ BS , 1 , IH ] ) d_memory = tf . nn . dropout ( memory , keep_prob = keep_prob , noise_shape = [ BS , 1 , MH ] ) with tf . variable_scope ( "attention" ) : inputs_att = tf . layers . dense ( d_inputs , att_size , use_bias = False , activation = tf . nn . relu ) memory_att = tf . layers . dense ( d_memory , att_size , use_bias = False , activation = tf . nn . relu ) logits = tf . matmul ( inputs_att , tf . transpose ( memory_att , [ 0 , 2 , 1 ] ) ) / ( att_size ** 0.5 ) mask = tf . tile ( tf . expand_dims ( mask , axis = 1 ) , [ 1 , IL , 1 ] ) att_weights = tf . nn . softmax ( softmax_mask ( logits , mask ) ) outputs = tf . matmul ( att_weights , memory ) res = tf . concat ( [ inputs , outputs ] , axis = 2 ) with tf . variable_scope ( "gate" ) : dim = res . get_shape ( ) . as_list ( ) [ - 1 ] d_res = tf . nn . dropout ( res , keep_prob = keep_prob , noise_shape = [ BS , 1 , IH + MH ] ) gate = tf . layers . dense ( d_res , dim , use_bias = False , activation = tf . nn . sigmoid ) return res * gate

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/validation/jsonschema/schema_validation.py#L112-L145<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def validate_json_against_schema ( json_dict , schema , err_msg = None ) : try : if isinstance ( schema , str ) : schema_name = schema schema = _SCHEMAS [ schema_name ] validator = _get_validator ( schema_name ) validator . validate ( json_dict ) else : jsonschema . validate ( json_dict , schema ) except jsonschema . ValidationError as err : if err_msg is None : err_msg = "JSON failed validation. Set Qiskit log level to DEBUG " "for further information." newerr = SchemaValidationError ( err_msg ) newerr . __cause__ = _SummaryValidationError ( err ) logger . debug ( '%s' , _format_causes ( err ) ) raise newerr

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/OpenKMIP/PyKMIP/blob/b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e/kmip/core/messages/payloads/create.py#L95-L161<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def read ( self , input_buffer , kmip_version = enums . KMIPVersion . KMIP_1_0 ) : super ( CreateRequestPayload , self ) . read ( input_buffer , kmip_version = kmip_version ) local_buffer = utils . BytearrayStream ( input_buffer . read ( self . length ) ) if self . is_tag_next ( enums . Tags . OBJECT_TYPE , local_buffer ) : self . _object_type = primitives . Enumeration ( enums . ObjectType , tag = enums . Tags . OBJECT_TYPE ) self . _object_type . read ( local_buffer , kmip_version = kmip_version ) else : raise exceptions . InvalidKmipEncoding ( "The Create request payload encoding is missing the object " "type." ) if kmip_version < enums . KMIPVersion . KMIP_2_0 : if self . is_tag_next ( enums . Tags . TEMPLATE_ATTRIBUTE , local_buffer ) : self . _template_attribute = objects . TemplateAttribute ( ) self . _template_attribute . read ( local_buffer , kmip_version = kmip_version ) else : raise exceptions . InvalidKmipEncoding ( "The Create request payload encoding is missing the " "template attribute." ) else : # NOTE (ph) For now, leave attributes natively in TemplateAttribute # form and just convert to the KMIP 2.0 Attributes form as needed # for encoding/decoding purposes. Changing the payload to require # the new Attributes structure will trigger a bunch of second-order # effects across the client and server codebases that is beyond # the scope of updating the Create payloads to support KMIP 2.0. if self . is_tag_next ( enums . Tags . ATTRIBUTES , local_buffer ) : attributes = objects . Attributes ( ) attributes . read ( local_buffer , kmip_version = kmip_version ) value = objects . convert_attributes_to_template_attribute ( attributes ) self . _template_attribute = value else : raise exceptions . InvalidKmipEncoding ( "The Create request payload encoding is missing the " "attributes structure." ) self . is_oversized ( local_buffer )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/qt/console/console_widget.py#L1036-L1051<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _create_page_control ( self ) : if self . custom_page_control : control = self . custom_page_control ( ) elif self . kind == 'plain' : control = QtGui . QPlainTextEdit ( ) elif self . kind == 'rich' : control = QtGui . QTextEdit ( ) control . installEventFilter ( self ) viewport = control . viewport ( ) viewport . installEventFilter ( self ) control . setReadOnly ( True ) control . setUndoRedoEnabled ( False ) control . setVerticalScrollBarPolicy ( QtCore . Qt . ScrollBarAlwaysOn ) return control

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Microsoft/botbuilder-python/blob/274663dd91c811bae6ac4488915ba5880771b0a7/libraries/botbuilder-dialogs/botbuilder/dialogs/choices/channel.py#L14-L39<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def supports_suggested_actions ( channel_id : str , button_cnt : int = 100 ) -> bool : max_actions = { # https://developers.facebook.com/docs/messenger-platform/send-messages/quick-replies Channels . facebook : 10 , Channels . skype : 10 , # https://developers.line.biz/en/reference/messaging-api/#items-object Channels . line : 13 , # https://dev.kik.com/#/docs/messaging#text-response-object Channels . kik : 20 , Channels . telegram : 100 , Channels . slack : 100 , Channels . emulator : 100 , Channels . direct_line : 100 , Channels . webchat : 100 , } return button_cnt <= max_actions [ channel_id ] if channel_id in max_actions else False

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/iotaledger/iota.lib.py/blob/97cdd1e241498446b46157b79b2a1ea2ec6d387a/iota/api.py#L791-L836<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_transfers ( self , start = 0 , stop = None , inclusion_states = False ) : # type: (int, Optional[int], bool) -> dict return extended . GetTransfersCommand ( self . adapter ) ( seed = self . seed , start = start , stop = stop , inclusionStates = inclusion_states , )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/shopkick/flawless/blob/c54b63ca1991c153e6f75080536f6df445aacc64/flawless/server/service.py#L419-L423<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _get_entry ( self , entry , entry_tree ) : for e in entry_tree [ entry . filename ] : if entry == e : return e

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/snare/scruffy/blob/0fedc08cfdb6db927ff93c09f25f24ce5a04c541/scruffy/file.py#L84-L91<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def path ( self ) : if self . _parent : return os . path . join ( self . _parent . path , self . _fpath ) else : return self . _fpath

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/zmq/kernelmanager.py#L843-L881<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def restart_kernel ( self , now = False , * * kw ) : if self . _launch_args is None : raise RuntimeError ( "Cannot restart the kernel. " "No previous call to 'start_kernel'." ) else : # Stop currently running kernel. if self . has_kernel : if now : self . kill_kernel ( ) else : self . shutdown_kernel ( restart = True ) # Start new kernel. self . _launch_args . update ( kw ) self . start_kernel ( * * self . _launch_args ) # FIXME: Messages get dropped in Windows due to probable ZMQ bug # unless there is some delay here. if sys . platform == 'win32' : time . sleep ( 0.2 )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/rocky/python3-trepan/blob/14e91bc0acce090d67be145b1ac040cab92ac5f3/trepan/lib/stack.py#L31-L37<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def count_frames ( frame , count_start = 0 ) : count = - count_start while frame : count += 1 frame = frame . f_back return count

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/OpenKMIP/PyKMIP/blob/b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e/kmip/pie/client.py#L1546-L1579<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _build_key_wrapping_specification ( self , value ) : if value is None : return None if not isinstance ( value , dict ) : raise TypeError ( "Key wrapping specification must be a dictionary." ) encryption_key_info = self . _build_encryption_key_information ( value . get ( 'encryption_key_information' ) ) mac_signature_key_info = self . _build_mac_signature_key_information ( value . get ( 'mac_signature_key_information' ) ) key_wrapping_specification = cobjects . KeyWrappingSpecification ( wrapping_method = value . get ( 'wrapping_method' ) , encryption_key_information = encryption_key_info , mac_signature_key_information = mac_signature_key_info , attribute_names = value . get ( 'attribute_names' ) , encoding_option = value . get ( 'encoding_option' ) ) return key_wrapping_specification

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jazzband/django-ddp/blob/1e1954b06fe140346acea43582515991685e4e01/dddp/__init__.py#L19-L42<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def greenify ( ) : # don't greenify twice. if _GREEN : return _GREEN [ True ] = True from gevent . monkey import patch_all , saved if ( 'threading' in sys . modules ) and ( 'threading' not in saved ) : import warnings warnings . warn ( 'threading module loaded before patching!' ) patch_all ( ) try : # Use psycopg2 by default import psycopg2 del psycopg2 except ImportError : # Fallback to psycopg2cffi if required (eg: pypy) from psycopg2cffi import compat compat . register ( ) from psycogreen . gevent import patch_psycopg patch_psycopg ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/IEMLdev/ieml/blob/4c842ba7e6165e2f1b4a4e2e98759f9f33af5f25/ieml/grammar/parser/parser.py#L73-L82<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse ( self , s ) : with self . lock : try : return self . parser . parse ( s , lexer = self . lexer ) except InvalidIEMLObjectArgument as e : raise CannotParse ( s , str ( e ) ) except CannotParse as e : e . s = s raise e

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/account.py#L466-L487<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def remove_item ( self , * * kwargs ) : path = self . _get_id_path ( 'remove_item' ) kwargs . update ( { 'session_id' : self . session_id } ) payload = { 'media_id' : kwargs . pop ( 'media_id' , None ) , } response = self . _POST ( path , kwargs , payload ) self . _set_attrs_to_values ( response ) return response

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/connectordb/connectordb-python/blob/2092b0cb30898139a247176bcf433d5a4abde7cb/connectordb/_device.py#L33-L44<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def streams ( self ) : result = self . db . read ( self . path , { "q" : "ls" } ) if result is None or result . json ( ) is None : return [ ] streams = [ ] for s in result . json ( ) : strm = self [ s [ "name" ] ] strm . metadata = s streams . append ( strm ) return streams

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/scheibler/khard/blob/0f69430c2680f1ff5f073a977a3c5b753b96cc17/khard/khard.py#L715-L757<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def new_subcommand ( selected_address_books , input_from_stdin_or_file , open_editor ) : # ask for address book, in which to create the new contact selected_address_book = choose_address_book_from_list ( "Select address book for new contact" , selected_address_books ) if selected_address_book is None : print ( "Error: address book list is empty" ) sys . exit ( 1 ) # if there is some data in stdin if input_from_stdin_or_file : # create new contact from stdin try : new_contact = CarddavObject . from_user_input ( selected_address_book , input_from_stdin_or_file , config . get_supported_private_objects ( ) , config . get_preferred_vcard_version ( ) , config . localize_dates ( ) ) except ValueError as err : print ( err ) sys . exit ( 1 ) else : new_contact . write_to_file ( ) if open_editor : modify_existing_contact ( new_contact ) else : print ( "Creation successful\n\n%s" % new_contact . print_vcard ( ) ) else : create_new_contact ( selected_address_book )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Jaymon/pyt/blob/801581fd0ae238158134bde1c937fa199fa626b2/pyt/__init__.py#L60-L70<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def is_single_module ( ) : ret = False counts = get_counts ( ) if counts [ "modules" ] == 1 : ret = True elif counts [ "modules" ] < 1 : ret = is_single_class ( ) return ret

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/solvebio/solvebio-python/blob/b29614643043afd19c1d8074e8f25c6700d51a73/solvebio/cli/main.py#L285-L309<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def main ( argv = sys . argv [ 1 : ] ) : parser = SolveArgumentParser ( ) args = parser . parse_solvebio_args ( argv ) if args . api_host : solvebio . api_host = args . api_host if args . api_key : solvebio . api_key = args . api_key if not solvebio . api_key : # If nothing is set (via command line or environment) # look in local credentials try : from . credentials import get_credentials solvebio . api_key = get_credentials ( ) except : pass # Update the client host and token client . set_host ( ) client . set_token ( ) return args . func ( args )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/JIC-CSB/jicbioimage.illustrate/blob/d88ddf81ee3eb3949677e2ef746af8169ce88092/jicbioimage/illustrate/__init__.py#L65-L86<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def draw_cross ( self , position , color = ( 255 , 0 , 0 ) , radius = 4 ) : y , x = position for xmod in np . arange ( - radius , radius + 1 , 1 ) : xpos = x + xmod if xpos < 0 : continue # Negative indices will draw on the opposite side. if xpos >= self . shape [ 1 ] : continue # Out of bounds. self [ int ( y ) , int ( xpos ) ] = color for ymod in np . arange ( - radius , radius + 1 , 1 ) : ypos = y + ymod if ypos < 0 : continue # Negative indices will draw on the opposite side. if ypos >= self . shape [ 0 ] : continue # Out of bounds. self [ int ( ypos ) , int ( x ) ] = color

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/quantum_info/operators/base_operator.py#L315-L326<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _automatic_dims ( cls , dims , size ) : if dims is None : dims = size elif np . product ( dims ) != size : raise QiskitError ( "dimensions do not match size." ) if isinstance ( dims , ( int , np . integer ) ) : num_qubits = int ( np . log2 ( dims ) ) if 2 ** num_qubits == size : return num_qubits * ( 2 , ) return ( dims , ) return tuple ( dims )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/utils/io.py#L134-L139<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def close ( self ) : self . flush ( ) setattr ( sys , self . channel , self . ostream ) self . file . close ( ) self . _closed = True

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neherlab/treetime/blob/f6cdb58d19243a18ffdaa2b2ec71872fa00e65c0/treetime/gtr.py#L946-L962<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def expQt ( self , t ) : eLambdaT = np . diag ( self . _exp_lt ( t ) ) # vector length = a Qs = self . v . dot ( eLambdaT . dot ( self . v_inv ) ) # This is P(nuc1 | given nuc_2) return np . maximum ( 0 , Qs )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/parse/variant/headers.py#L40-L60<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse_vep_header ( vcf_obj ) : vep_header = [ ] if 'CSQ' in vcf_obj : # This is a dictionary csq_info = vcf_obj [ 'CSQ' ] format_info = parse_header_format ( csq_info [ 'Description' ] ) vep_header = [ key . upper ( ) for key in format_info . split ( '|' ) ] return vep_header

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L228-L233<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def names ( self ) : if not self . _ex . _cache . names_valid ( ) : self . _ex . _cache . flush ( ) self . _frame ( fill_cache = True ) return list ( self . _ex . _cache . names )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ambitioninc/python-logentries-api/blob/77ff1a7a2995d7ea2725b74e34c0f880f4ee23bc/logentries_api/special_alerts.py#L379-L396<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def list_tags ( self ) : url = 'https://logentries.com/rest/{account_id}/api/tags/' . format ( account_id = self . account_id ) return self . _api_get ( url = url ) . get ( 'tags' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tnkteja/myhelp/blob/fb3a4809d448ad14d5b2e6ddf2e7e89ad52b71cb/virtualEnvironment/lib/python2.7/site-packages/pip/req/req_set.py#L480-L563<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def install ( self , install_options , global_options = ( ) , * args , * * kwargs ) : to_install = [ r for r in self . requirements . values ( ) [ : : - 1 ] if not r . satisfied_by ] # DISTRIBUTE TO SETUPTOOLS UPGRADE HACK (1 of 3 parts) # move the distribute-0.7.X wrapper to the end because it does not # install a setuptools package. by moving it to the end, we ensure it's # setuptools dependency is handled first, which will provide the # setuptools package # TODO: take this out later distribute_req = pkg_resources . Requirement . parse ( "distribute>=0.7" ) for req in to_install : if ( req . name == 'distribute' and req . installed_version is not None and req . installed_version in distribute_req ) : to_install . remove ( req ) to_install . append ( req ) if to_install : logger . info ( 'Installing collected packages: %s' , ', ' . join ( [ req . name for req in to_install ] ) , ) with indent_log ( ) : for requirement in to_install : # DISTRIBUTE TO SETUPTOOLS UPGRADE HACK (1 of 3 parts) # when upgrading from distribute-0.6.X to the new merged # setuptools in py2, we need to force setuptools to uninstall # distribute. In py3, which is always using distribute, this # conversion is already happening in distribute's # pkg_resources. It's ok *not* to check if setuptools>=0.7 # because if someone were actually trying to ugrade from # distribute to setuptools 0.6.X, then all this could do is # actually help, although that upgade path was certainly never # "supported" # TODO: remove this later if requirement . name == 'setuptools' : try : # only uninstall distribute<0.7. For >=0.7, setuptools # will also be present, and that's what we need to # uninstall distribute_requirement = pkg_resources . Requirement . parse ( "distribute<0.7" ) existing_distribute = pkg_resources . get_distribution ( "distribute" ) if existing_distribute in distribute_requirement : requirement . conflicts_with = existing_distribute except pkg_resources . DistributionNotFound : # distribute wasn't installed, so nothing to do pass if requirement . conflicts_with : logger . info ( 'Found existing installation: %s' , requirement . conflicts_with , ) with indent_log ( ) : requirement . uninstall ( auto_confirm = True ) try : requirement . install ( install_options , global_options , * args , * * kwargs ) except : # if install did not succeed, rollback previous uninstall if ( requirement . conflicts_with and not requirement . install_succeeded ) : requirement . rollback_uninstall ( ) raise else : if ( requirement . conflicts_with and requirement . install_succeeded ) : requirement . commit_uninstall ( ) requirement . remove_temporary_source ( ) self . successfully_installed = to_install

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/apache/airflow/blob/b69c686ad8a0c89b9136bb4b31767257eb7b2597/airflow/contrib/hooks/gcp_sql_hook.py#L282-L310<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def export_instance ( self , instance , body , project_id = None ) : try : response = self . get_conn ( ) . instances ( ) . export ( project = project_id , instance = instance , body = body ) . execute ( num_retries = self . num_retries ) operation_name = response [ "name" ] self . _wait_for_operation_to_complete ( project_id = project_id , operation_name = operation_name ) except HttpError as ex : raise AirflowException ( 'Exporting instance {} failed: {}' . format ( instance , ex . content ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/MaxStrange/AudioSegment/blob/1daefb8de626ddff3ff7016697c3ad31d262ecd6/algorithms/eventdetection.py#L9-L44<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _get_filter_indices ( seg , start_as_yes , prob_raw_yes , ms_per_input , model , transition_matrix , model_stats ) : filter_triggered = 1 if start_as_yes else 0 prob_raw_no = 1.0 - prob_raw_yes for segment , _timestamp in seg . generate_frames_as_segments ( ms_per_input ) : yield filter_triggered observation = int ( round ( model . predict ( segment ) ) ) assert observation == 1 or observation == 0 , "The given model did not output a 1 or a 0, output: " + str ( observation ) prob_hyp_yes_given_last_hyp = 1.0 - transition_matrix [ 0 ] if filter_triggered else transition_matrix [ 1 ] prob_hyp_no_given_last_hyp = transition_matrix [ 0 ] if filter_triggered else 1.0 - transition_matrix [ 1 ] prob_hyp_yes_given_data = model_stats [ 0 ] if observation == 1 else model_stats [ 1 ] prob_hyp_no_given_data = 1.0 - model_stats [ 0 ] if observation == 1 else 1.0 - model_stats [ 1 ] hypothesis_yes = prob_raw_yes * prob_hyp_yes_given_last_hyp * prob_hyp_yes_given_data hypothesis_no = prob_raw_no * prob_hyp_no_given_last_hyp * prob_hyp_no_given_data # make a list of ints - each is 0 or 1. The number of 1s is hypotheis_yes * 100 # the number of 0s is hypothesis_no * 100 distribution = [ 1 for i in range ( int ( round ( hypothesis_yes * 100 ) ) ) ] distribution . extend ( [ 0 for i in range ( int ( round ( hypothesis_no * 100 ) ) ) ] ) # shuffle random . shuffle ( distribution ) filter_triggered = random . choice ( distribution )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/parse/panel.py#L295-L333<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse_panel_app_gene ( app_gene , hgnc_map ) : gene_info = { } confidence_level = app_gene [ 'LevelOfConfidence' ] # Return empty gene if not confident gene if not confidence_level == 'HighEvidence' : return gene_info hgnc_symbol = app_gene [ 'GeneSymbol' ] # Returns a set of hgnc ids hgnc_ids = get_correct_ids ( hgnc_symbol , hgnc_map ) if not hgnc_ids : LOG . warning ( "Gene %s does not exist in database. Skipping gene..." , hgnc_symbol ) return gene_info if len ( hgnc_ids ) > 1 : LOG . warning ( "Gene %s has unclear identifier. Choose random id" , hgnc_symbol ) gene_info [ 'hgnc_symbol' ] = hgnc_symbol for hgnc_id in hgnc_ids : gene_info [ 'hgnc_id' ] = hgnc_id gene_info [ 'reduced_penetrance' ] = INCOMPLETE_PENETRANCE_MAP . get ( app_gene [ 'Penetrance' ] ) inheritance_models = [ ] for model in MODELS_MAP . get ( app_gene [ 'ModeOfInheritance' ] , [ ] ) : inheritance_models . append ( model ) gene_info [ 'inheritance_models' ] = inheritance_models return gene_info

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/blockstack/zone-file-py/blob/c1078c8c3c28f0881bc9a3af53d4972c4a6862d0/blockstack_zones/parse_zone_file.py#L362-L382<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse_lines ( text , ignore_invalid = False ) : json_zone_file = defaultdict ( list ) record_lines = text . split ( "\n" ) parser = make_parser ( ) for record_line in record_lines : record_token = tokenize_line ( record_line ) try : json_zone_file = parse_line ( parser , record_token , json_zone_file ) except InvalidLineException : if ignore_invalid : continue else : raise return json_zone_file

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Nic30/hwt/blob/8cbb399e326da3b22c233b98188a9d08dec057e6/hwt/synthesizer/interfaceLevel/propDeclrCollector.py#L289-L296<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _registerArray ( self , name , items ) : items . _parent = self items . _name = name for i , item in enumerate ( items ) : setattr ( self , "%s_%d" % ( name , i ) , item )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/hivetech/dna/blob/50ad00031be29765b2576fa407d35a36e0608de9/python/dna/time_utils.py#L42-L49<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _detect_timezone ( ) : default_timezone = 'America/New_York' locale_code = locale . getdefaultlocale ( ) return default_timezone if not locale_code [ 0 ] else str ( pytz . country_timezones [ locale_code [ 0 ] [ - 2 : ] ] [ 0 ] )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/providers/baseprovider.py#L28-L48<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_backend ( self , name = None , * * kwargs ) : backends = self . backends ( name , * * kwargs ) if len ( backends ) > 1 : raise QiskitBackendNotFoundError ( 'More than one backend matches the criteria' ) elif not backends : raise QiskitBackendNotFoundError ( 'No backend matches the criteria' ) return backends [ 0 ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/lxml/html/__init__.py#L283-L294<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def cssselect ( self , expr , translator = 'html' ) : # Do the import here to make the dependency optional. from lxml . cssselect import CSSSelector return CSSSelector ( expr , translator = translator ) ( self )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/rwl/godot/blob/013687c9e8983d2aa2ceebb8a76c5c4f1e37c90f/godot/xdot_parser.py#L280-L285<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def proc_font ( self , tokens ) : size = int ( tokens [ "s" ] ) self . pen . font = "%s %d" % ( tokens [ "b" ] , size ) return [ ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/xmikos/soapy_power/blob/46e12659b8d08af764dc09a1f31b0e85a68f808f/soapypower/writer.py#L170-L188<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def write ( self , psd_data_or_future , time_start , time_stop , samples ) : try : # Wait for result of future f_array , pwr_array = psd_data_or_future . result ( ) except AttributeError : f_array , pwr_array = psd_data_or_future try : step = f_array [ 1 ] - f_array [ 0 ] row = [ time_stop . strftime ( '%Y-%m-%d' ) , time_stop . strftime ( '%H:%M:%S' ) , f_array [ 0 ] , f_array [ - 1 ] + step , step , samples ] row += list ( pwr_array ) self . output . write ( '{}\n' . format ( ', ' . join ( str ( x ) for x in row ) ) ) self . output . flush ( ) except Exception as e : logging . exception ( 'Error writing to output file:' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/deepmipt/DeepPavlov/blob/f3e4a69a3764d25d2f5bad4f1f1aebc872b00f9c/deeppavlov/core/layers/tf_layers.py#L475-L501<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def multiplicative_self_attention ( units , n_hidden = None , n_output_features = None , activation = None ) : n_input_features = units . get_shape ( ) . as_list ( ) [ 2 ] if n_hidden is None : n_hidden = n_input_features if n_output_features is None : n_output_features = n_input_features queries = tf . layers . dense ( expand_tile ( units , 1 ) , n_hidden , kernel_initializer = INITIALIZER ( ) ) keys = tf . layers . dense ( expand_tile ( units , 2 ) , n_hidden , kernel_initializer = INITIALIZER ( ) ) scores = tf . reduce_sum ( queries * keys , axis = 3 , keep_dims = True ) attention = tf . nn . softmax ( scores , dim = 2 ) attended_units = tf . reduce_sum ( attention * expand_tile ( units , 1 ) , axis = 2 ) output = tf . layers . dense ( attended_units , n_output_features , activation , kernel_initializer = INITIALIZER ( ) ) return output

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/reingart/gui2py/blob/aca0a05f6fcde55c94ad7cc058671a06608b01a4/gui/tools/designer.py#L267-L301<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def mouse_up ( self , evt , wx_obj = None ) : self . resizing = False if self . current : wx_obj = self . current if self . parent . wx_obj . HasCapture ( ) : self . parent . wx_obj . ReleaseMouse ( ) self . current = None if self . overlay : # When the mouse is released we reset the overlay and it  # restores the former content to the window.  dc = wx . ClientDC ( wx_obj ) odc = wx . DCOverlay ( self . overlay , dc ) odc . Clear ( ) del odc self . overlay . Reset ( ) self . overlay = None pos = evt . GetPosition ( ) # convert to relative client coordinates of the container: if evt . GetEventObject ( ) != wx_obj : pos = evt . GetEventObject ( ) . ClientToScreen ( pos ) # frame pos = wx_obj . ScreenToClient ( pos ) # panel # finish the multiple selection using the mouse: rect = wx . RectPP ( self . pos , pos ) for obj in wx_obj . obj : # only check child controls (not menubar/statusbar) if isinstance ( obj , Control ) : obj_rect = obj . wx_obj . GetRect ( ) if rect . ContainsRect ( obj_rect ) : self . select ( obj , keep_selection = True ) self . pos = None if self . inspector and wx_obj : self . inspector . inspect ( wx_obj . obj ) if DEBUG : print "SELECTION" , self . selection

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/MartinHjelmare/leicacam/blob/1df37bccd34884737d3b5e169fae71dd2f21f1e2/leicacam/cam.py#L118-L138<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _prepare_send ( self , commands ) : if isinstance ( commands , bytes ) : msg = self . prefix_bytes + commands else : msg = tuples_as_bytes ( self . prefix + commands ) debug ( b'> ' + msg ) return msg

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ekzhu/datasketch/blob/b3e4129987890a2beb04f2c0b6dc618ae35f2e14/datasketch/lshensemble_partition.py#L57-L72<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _compute_nfp_real ( l , u , counts , sizes ) : if l > u : raise ValueError ( "l must be less or equal to u" ) return np . sum ( ( float ( sizes [ u ] ) - sizes [ l : u + 1 ] ) / float ( sizes [ u ] ) * counts [ l : u + 1 ] )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/LionelAuroux/pyrser/blob/f153a97ef2b6bf915a1ed468c0252a9a59b754d5/pyrser/type_system/scope.py#L515-L524<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def callInjector ( self , old : Node , trans : Translator ) -> Node : if self . astTranslatorInjector is None : if self . parent is not None : # TODO: think if we forward for all StateScope # forward to parent scope return self . parent ( ) . callInjector ( old , trans ) else : raise TypeError ( "Must define an Translator Injector" ) return self . astTranslatorInjector ( old , trans )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ethereum/py_ecc/blob/2088796c59574b256dc8e18f8c9351bc3688ca71/py_ecc/bls/utils.py#L189-L219<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def decompress_G2 ( p : G2Compressed ) -> G2Uncompressed : z1 , z2 = p # b_flag == 1 indicates the infinity point b_flag1 = ( z1 % POW_2_383 ) // POW_2_382 if b_flag1 == 1 : return Z2 x1 = z1 % POW_2_381 x2 = z2 # x1 is the imaginary part, x2 is the real part x = FQ2 ( [ x2 , x1 ] ) y = modular_squareroot_in_FQ2 ( x ** 3 + b2 ) if y is None : raise ValueError ( "Failed to find a modular squareroot" ) # Choose the y whose leftmost bit of the imaginary part is equal to the a_flag1 # If y_im happens to be zero, then use the bit of y_re a_flag1 = ( z1 % POW_2_382 ) // POW_2_381 y_re , y_im = y . coeffs if ( y_im > 0 and ( y_im * 2 ) // q != a_flag1 ) or ( y_im == 0 and ( y_re * 2 ) // q != a_flag1 ) : y = FQ2 ( ( y * - 1 ) . coeffs ) if not is_on_curve ( ( x , y , FQ2 ( [ 1 , 0 ] ) ) , b2 ) : raise ValueError ( "The given point is not on the twisted curve over FQ**2" ) return ( x , y , FQ2 ( [ 1 , 0 ] ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/AkihikoITOH/capybara/blob/e86c2173ea386654f4ae061148e8fbe3f25e715c/capybara/virtualenv/lib/python2.7/site-packages/werkzeug/debug/tbtools.py#L260-L264<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def exception ( self ) : buf = traceback . format_exception_only ( self . exc_type , self . exc_value ) rv = '' . join ( buf ) . strip ( ) return rv . decode ( 'utf-8' , 'replace' ) if PY2 else rv

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyProphet/pyprophet/blob/f546ad171750cd7685afbde6785fe71f82cadb35/pyprophet/main.py#L304-L319<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def export_compound ( infile , outfile , format , outcsv , max_rs_peakgroup_qvalue ) : if format == "score_plots" : export_score_plots ( infile ) else : if outfile is None : if outcsv : outfile = infile . split ( ".osw" ) [ 0 ] + ".csv" else : outfile = infile . split ( ".osw" ) [ 0 ] + ".tsv" else : outfile = outfile export_compound_tsv ( infile , outfile , format , outcsv , max_rs_peakgroup_qvalue )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-bindings/bin/pymagic.py#L24-L32<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def locate_files ( root_dir ) : all_files = [ ] root_dir = os . path . abspath ( root_dir ) for dir_name , subdirs , files in os . walk ( root_dir ) : for f in files : if f . endswith ( ".py" ) : all_files . append ( os . path . join ( dir_name , f ) ) return all_files

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/xtuml/pyxtuml/blob/7dd9343b9a0191d1db1887ab9288d0a026608d9a/xtuml/consistency_check.py#L133-L149<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def check_link_integrity ( m , link ) : res = 0 for inst in link . from_metaclass . select_many ( ) : q_set = list ( link . navigate ( inst ) ) if ( len ( q_set ) < 1 and not link . conditional ) or ( ( len ( q_set ) > 1 and not link . many ) ) : res += 1 logger . warning ( 'integrity violation in ' '%s --(%s)--> %s' % ( pretty_from_link ( inst , link ) , link . rel_id , pretty_to_link ( inst , link ) ) ) return res

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2non/pook/blob/e64094e41e4d89d98d2d29af7608ef27dc50cf19/pook/regex.py#L28-L41<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def isregex ( value ) : if not value : return False return any ( ( isregex_expr ( value ) , isinstance ( value , retype ) ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/opencast/pyCA/blob/c89b168d4780d157e1b3f7676628c1b131956a88/pyca/ui/jsonapi.py#L36-L46<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def internal_state ( ) : data = { 'services' : { 'capture' : ServiceStatus . str ( get_service_status ( Service . CAPTURE ) ) , 'ingest' : ServiceStatus . str ( get_service_status ( Service . INGEST ) ) , 'schedule' : ServiceStatus . str ( get_service_status ( Service . SCHEDULE ) ) , 'agentstate' : ServiceStatus . str ( get_service_status ( Service . AGENTSTATE ) ) } } return make_response ( jsonify ( { 'meta' : data } ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mcs07/MolVS/blob/d815fe52d160abcecbcbf117e6437bf727dbd8ad/molvs/standardize.py#L281-L286<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def canonicalize_tautomer ( self ) : return TautomerCanonicalizer ( transforms = self . tautomer_transforms , scores = self . tautomer_scores , max_tautomers = self . max_tautomers )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Azure/azure-sdk-for-python/blob/d7306fde32f60a293a7567678692bdad31e4b667/azure-servicemanagement-legacy/azure/servicemanagement/_serialization.py#L141-L164<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_entry_properties_from_node ( entry , include_id , id_prefix_to_skip = None , use_title_as_id = False ) : properties = { } etag = entry . getAttributeNS ( METADATA_NS , 'etag' ) if etag : properties [ 'etag' ] = etag for updated in _MinidomXmlToObject . get_child_nodes ( entry , 'updated' ) : properties [ 'updated' ] = updated . firstChild . nodeValue for name in _MinidomXmlToObject . get_children_from_path ( entry , 'author' , 'name' ) : if name . firstChild is not None : properties [ 'author' ] = name . firstChild . nodeValue if include_id : if use_title_as_id : for title in _MinidomXmlToObject . get_child_nodes ( entry , 'title' ) : properties [ 'name' ] = title . firstChild . nodeValue else : # TODO: check if this is used for id in _MinidomXmlToObject . get_child_nodes ( entry , 'id' ) : properties [ 'name' ] = _get_readable_id ( id . firstChild . nodeValue , id_prefix_to_skip ) return properties

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/LLNL/scraper/blob/881a316e4c04dfa5a9cf491b7c7f9f997a7c56ea/scripts/stars.py#L15-L40<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_stargazers ( url , session = None ) : headers = { 'Accept' : 'application/vnd.github.v3.star+json' } url = url + '?per_page=100&page=%s' page = 1 gazers = [ ] response = github . get ( url % page , headers = headers ) gazers . extend ( response . json ( ) ) #{rel: url for url, rel in LINK_REGEX.findall(r.headers['Link'])} while json_data : gazers . extend ( json_data ) page += 1 json_data = github . get ( url % page , headers = headers ) . json ( ) return gazers

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/variables.py#L1374-L1572<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def visit_name ( self , node ) : stmt = node . statement ( ) if stmt . fromlineno is None : # name node from an astroid built from live code, skip assert not stmt . root ( ) . file . endswith ( ".py" ) return name = node . name frame = stmt . scope ( ) # if the name node is used as a function default argument's value or as # a decorator, then start from the parent frame of the function instead # of the function frame - and thus open an inner class scope if ( utils . is_default_argument ( node ) or utils . is_func_decorator ( node ) or utils . is_ancestor_name ( frame , node ) ) : start_index = len ( self . _to_consume ) - 2 else : start_index = len ( self . _to_consume ) - 1 # iterates through parent scopes, from the inner to the outer base_scope_type = self . _to_consume [ start_index ] . scope_type # pylint: disable=too-many-nested-blocks; refactoring this block is a pain. for i in range ( start_index , - 1 , - 1 ) : current_consumer = self . _to_consume [ i ] # if the current scope is a class scope but it's not the inner # scope, ignore it. This prevents to access this scope instead of # the globals one in function members when there are some common # names. The only exception is when the starting scope is a # comprehension and its direct outer scope is a class if ( current_consumer . scope_type == "class" and i != start_index and not ( base_scope_type == "comprehension" and i == start_index - 1 ) ) : if self . _ignore_class_scope ( node ) : continue # the name has already been consumed, only check it's not a loop # variable used outside the loop # avoid the case where there are homonyms inside function scope and # comprehension current scope (avoid bug #1731) if name in current_consumer . consumed and not ( current_consumer . scope_type == "comprehension" and self . _has_homonym_in_upper_function_scope ( node , i ) ) : defnode = utils . assign_parent ( current_consumer . consumed [ name ] [ 0 ] ) self . _check_late_binding_closure ( node , defnode ) self . _loopvar_name ( node , name ) break found_node = current_consumer . get_next_to_consume ( node ) if found_node is None : continue # checks for use before assignment defnode = utils . assign_parent ( current_consumer . to_consume [ name ] [ 0 ] ) if defnode is not None : self . _check_late_binding_closure ( node , defnode ) defstmt = defnode . statement ( ) defframe = defstmt . frame ( ) # The class reuses itself in the class scope. recursive_klass = ( frame is defframe and defframe . parent_of ( node ) and isinstance ( defframe , astroid . ClassDef ) and node . name == defframe . name ) if ( recursive_klass and utils . is_inside_lambda ( node ) and ( not utils . is_default_argument ( node ) or node . scope ( ) . parent . scope ( ) is not defframe ) ) : # Self-referential class references are fine in lambda's -- # As long as they are not part of the default argument directly # under the scope of the parent self-referring class. # Example of valid default argument: # class MyName3: #     myattr = 1 #     mylambda3 = lambda: lambda a=MyName3: a # Example of invalid default argument: # class MyName4: #     myattr = 1 #     mylambda4 = lambda a=MyName4: lambda: a # If the above conditional is True, # there is no possibility of undefined-variable # Also do not consume class name # (since consuming blocks subsequent checks) # -- quit break maybee0601 , annotation_return , use_outer_definition = self . _is_variable_violation ( node , name , defnode , stmt , defstmt , frame , defframe , base_scope_type , recursive_klass , ) if use_outer_definition : continue if ( maybee0601 and not utils . is_defined_before ( node ) and not astroid . are_exclusive ( stmt , defstmt , ( "NameError" , ) ) ) : # Used and defined in the same place, e.g `x += 1` and `del x` defined_by_stmt = defstmt is stmt and isinstance ( node , ( astroid . DelName , astroid . AssignName ) ) if ( recursive_klass or defined_by_stmt or annotation_return or isinstance ( defstmt , astroid . Delete ) ) : if not utils . node_ignores_exception ( node , NameError ) : # Handle postponed evaluation of annotations if not ( self . _postponed_evaluation_enabled and isinstance ( stmt , ( astroid . AnnAssign , astroid . FunctionDef , astroid . Arguments , ) , ) and name in node . root ( ) . locals ) : self . add_message ( "undefined-variable" , args = name , node = node ) elif base_scope_type != "lambda" : # E0601 may *not* occurs in lambda scope. # Handle postponed evaluation of annotations if not ( self . _postponed_evaluation_enabled and isinstance ( stmt , ( astroid . AnnAssign , astroid . FunctionDef ) ) ) : self . add_message ( "used-before-assignment" , args = name , node = node ) elif base_scope_type == "lambda" : # E0601 can occur in class-level scope in lambdas, as in # the following example: #   class A: #      x = lambda attr: f + attr #      f = 42 if isinstance ( frame , astroid . ClassDef ) and name in frame . locals : if isinstance ( node . parent , astroid . Arguments ) : if stmt . fromlineno <= defstmt . fromlineno : # Doing the following is fine: #   class A: #      x = 42 #      y = lambda attr=x: attr self . add_message ( "used-before-assignment" , args = name , node = node ) else : self . add_message ( "undefined-variable" , args = name , node = node ) elif current_consumer . scope_type == "lambda" : self . add_message ( "undefined-variable" , node = node , args = name ) current_consumer . mark_as_consumed ( name , found_node ) # check it's not a loop variable used outside the loop self . _loopvar_name ( node , name ) break else : # we have not found the name, if it isn't a builtin, that's an # undefined name ! if not ( name in astroid . Module . scope_attrs or utils . is_builtin ( name ) or name in self . config . additional_builtins ) : if not utils . node_ignores_exception ( node , NameError ) : self . add_message ( "undefined-variable" , args = name , node = node )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/open-mmlab/mmcv/blob/0d77f61450aab4dde8b8585a577cc496acb95d7f/mmcv/utils/timer.py#L63-L71<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def since_start ( self ) : if not self . _is_running : raise TimerError ( 'timer is not running' ) self . _t_last = time ( ) return self . _t_last - self . _t_start

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tek/ribosome/blob/b2ce9e118faa46d93506cbbb5f27ecfbd4e8a1cc/ribosome/nvim/io/compute.py#L242-L245<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def nvim_io_recover ( self , io : NvimIORecover [ A ] ) -> NvimIO [ B ] : return eval_step ( self . vim ) ( io . map ( lambda a : a ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/h2o.py#L978-L1006<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def download_pojo ( model , path = "" , get_jar = True , jar_name = "" ) : assert_is_type ( model , ModelBase ) assert_is_type ( path , str ) assert_is_type ( get_jar , bool ) if not model . have_pojo : raise H2OValueError ( "Export to POJO not supported" ) if path == "" : java_code = api ( "GET /3/Models.java/%s" % model . model_id ) print ( java_code ) return None else : filename = api ( "GET /3/Models.java/%s" % model . model_id , save_to = path ) if get_jar : if jar_name == "" : api ( "GET /3/h2o-genmodel.jar" , save_to = os . path . join ( path , "h2o-genmodel.jar" ) ) else : api ( "GET /3/h2o-genmodel.jar" , save_to = os . path . join ( path , jar_name ) ) return filename

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jazzband/django-ddp/blob/1e1954b06fe140346acea43582515991685e4e01/dddp/logging.py#L27-L67<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def emit ( self , record ) : if getattr ( this , 'subs' , { } ) . get ( LOGS_NAME , False ) : self . format ( record ) this . send ( { 'msg' : ADDED , 'collection' : LOGS_NAME , 'id' : meteor_random_id ( '/collection/%s' % LOGS_NAME ) , 'fields' : { attr : { # typecasting methods for specific attributes 'args' : lambda args : [ repr ( arg ) for arg in args ] , 'created' : datetime . datetime . fromtimestamp , 'exc_info' : stacklines_or_none , } . get ( attr , lambda val : val # default typecasting method ) ( getattr ( record , attr , None ) ) for attr in ( 'args' , 'asctime' , 'created' , 'exc_info' , 'filename' , 'funcName' , 'levelname' , 'levelno' , 'lineno' , 'module' , 'msecs' , 'message' , 'name' , 'pathname' , 'process' , 'processName' , 'relativeCreated' , 'thread' , 'threadName' , ) } , } )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyProphet/pyprophet/blob/f546ad171750cd7685afbde6785fe71f82cadb35/pyprophet/stats.py#L56-L59<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def lookup_values_from_error_table ( scores , err_df ) : ix = find_nearest_matches ( np . float32 ( err_df . cutoff . values ) , np . float32 ( scores ) ) return err_df . pvalue . iloc [ ix ] . values , err_df . svalue . iloc [ ix ] . values , err_df . pep . iloc [ ix ] . values , err_df . qvalue . iloc [ ix ] . values

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/inveniosoftware/invenio-migrator/blob/6902c6968a39b747d15e32363f43b7dffe2622c2/invenio_migrator/ext.py#L79-L85<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def init_app ( self , app ) : self . init_config ( app . config ) state = _InvenioMigratorState ( app ) app . extensions [ 'invenio-migrator' ] = state app . cli . add_command ( dumps ) return state

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/OpenKMIP/PyKMIP/blob/b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e/kmip/services/server/crypto/engine.py#L882-L944<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _create_rsa_key_pair ( self , length , public_exponent = 65537 ) : self . logger . info ( "Generating an RSA key pair with length: {0}, and " "public_exponent: {1}" . format ( length , public_exponent ) ) try : private_key = rsa . generate_private_key ( public_exponent = public_exponent , key_size = length , backend = default_backend ( ) ) public_key = private_key . public_key ( ) private_bytes = private_key . private_bytes ( serialization . Encoding . DER , serialization . PrivateFormat . PKCS8 , serialization . NoEncryption ( ) ) public_bytes = public_key . public_bytes ( serialization . Encoding . DER , serialization . PublicFormat . PKCS1 ) except Exception as e : self . logger . exception ( e ) raise exceptions . CryptographicFailure ( "An error occurred while generating the RSA key pair. " "See the server log for more information." ) public_key = { 'value' : public_bytes , 'format' : enums . KeyFormatType . PKCS_1 , 'public_exponent' : public_exponent } private_key = { 'value' : private_bytes , 'format' : enums . KeyFormatType . PKCS_8 , 'public_exponent' : public_exponent } return public_key , private_key

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/vaexio/vaex/blob/a45b672f8287afca2ada8e36b74b604b9b28dd85/packages/vaex-core/vaex/ext/readcol.py#L45-L221<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def readcol ( filename , skipline = 0 , skipafter = 0 , names = False , fsep = None , twod = True , fixedformat = None , asdict = False , comment = '#' , verbose = True , nullval = None , asStruct = False , namecomment = True , removeblanks = False , header_badchars = None , asRecArray = False ) : with open ( filename , 'r' ) as f : f = f . readlines ( ) null = [ f . pop ( 0 ) for i in range ( skipline ) ] commentfilter = make_commentfilter ( comment ) if not asStruct : asStruct = asRecArray if namecomment is False and ( names or asdict or asStruct ) : while 1 : line = f . pop ( 0 ) if line [ 0 ] != comment : nameline = line if header_badchars : for c in header_badchars : nameline = nameline . replace ( c , ' ' ) nms = nameline . split ( fsep ) break elif len ( f ) == 0 : raise Exception ( "No uncommented lines found." ) else : if names or asdict or asStruct : # can specify name line if type ( names ) == type ( 1 ) : nameline = f . pop ( names ) else : nameline = f . pop ( 0 ) if nameline [ 0 ] == comment : nameline = nameline [ 1 : ] if header_badchars : for c in header_badchars : nameline = nameline . replace ( c , ' ' ) nms = list ( [ name . strip ( ) for name in nameline . split ( fsep ) ] ) null = [ f . pop ( 0 ) for i in range ( skipafter ) ] if fixedformat : myreadff = lambda x : readff ( x , fixedformat ) splitarr = list ( map ( myreadff , f ) ) splitarr = list ( filter ( commentfilter , splitarr ) ) else : fstrip = list ( map ( str . strip , f ) ) fseps = [ fsep for i in range ( len ( f ) ) ] splitarr = list ( map ( str . split , fstrip , fseps ) ) if removeblanks : for i in range ( splitarr . count ( [ '' ] ) ) : splitarr . remove ( [ '' ] ) splitarr = list ( filter ( commentfilter , splitarr ) ) # check to make sure each line has the same number of columns to avoid # "ValueError: setting an array element with a sequence." nperline = list ( map ( len , splitarr ) ) if hasmode : ncols , nrows = mode ( nperline ) if nrows != len ( splitarr ) : if verbose : print ( "Removing %i rows that don't match most common length %i.  \                          \n%i rows read into array." % ( len ( splitarr ) - nrows , ncols , nrows ) ) for i in range ( len ( splitarr ) - 1 , - 1 , - 1 ) : # need to go backwards if nperline [ i ] != ncols : splitarr . pop ( i ) try : x = numpy . asarray ( splitarr , dtype = 'float' ) except ValueError : if verbose : print ( "WARNING: reading as string array because %s array failed" % 'float' ) try : x = numpy . asarray ( splitarr , dtype = 'S' ) except ValueError : if hasmode : raise Exception ( "ValueError when converting data to array." + "  You have scipy.mode on your system, so this is " + "probably not an issue of differing row lengths." ) else : raise Exception ( "Conversion to array error.  You probably " + "have different row lengths and scipy.mode was not " + "imported." ) if nullval is not None : x [ x == nullval ] = numpy . nan x = get_autotype ( x ) if asdict or asStruct : mydict = OrderedDict ( zip ( nms , x . T ) ) for k , v in mydict . items ( ) : mydict [ k ] = get_autotype ( v ) if asdict : return mydict elif asRecArray : return Struct ( mydict ) . as_recarray ( ) elif asStruct : return Struct ( mydict ) elif names and twod : return nms , x elif names : # if not returning a twod array, try to return each vector as the spec. type return nms , [ get_autotype ( x . T [ i ] ) for i in range ( x . shape [ 1 ] ) ] else : if twod : return x else : return [ get_autotype ( x . T [ i ] ) for i in range ( x . shape [ 1 ] ) ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/elliterate/capybara.py/blob/0c6ae449cc37e4445ec3cd6af95674533beedc6c/capybara/queries/selector_query.py#L215-L269<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def matches_filters ( self , node ) : visible = self . visible if self . options [ "text" ] : if isregex ( self . options [ "text" ] ) : regex = self . options [ "text" ] elif self . exact_text is True : regex = re . compile ( r"\A{}\Z" . format ( re . escape ( self . options [ "text" ] ) ) ) else : regex = toregex ( self . options [ "text" ] ) text = normalize_text ( node . all_text if visible == "all" else node . visible_text ) if not regex . search ( text ) : return False if isinstance ( self . exact_text , ( bytes_ , str_ ) ) : regex = re . compile ( r"\A{}\Z" . format ( re . escape ( self . exact_text ) ) ) text = normalize_text ( node . all_text if visible == "all" else node . visible_text ) if not regex . search ( text ) : return False if visible == "visible" : if not node . visible : return False elif visible == "hidden" : if node . visible : return False for name , node_filter in iter ( self . _node_filters . items ( ) ) : if name in self . filter_options : if not node_filter . matches ( node , self . filter_options [ name ] ) : return False elif node_filter . has_default : if not node_filter . matches ( node , node_filter . default ) : return False if self . options [ "filter" ] and not self . options [ "filter" ] ( node ) : return False return True

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/OpenMath/py-openmath/blob/4906aa9ccf606f533675c28823772e07c30fd220/openmath/convert.py#L136-L149<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def to_python ( self , omobj ) : # general overrides if omobj . __class__ in self . _omclass_to_py : return self . _omclass_to_py [ omobj . __class__ ] ( omobj ) # oms elif isinstance ( omobj , om . OMSymbol ) : return self . _lookup_to_python ( omobj . cdbase , omobj . cd , omobj . name ) # oma elif isinstance ( omobj , om . OMApplication ) : elem = self . to_python ( omobj . elem ) arguments = [ self . to_python ( x ) for x in omobj . arguments ] return elem ( * arguments ) raise ValueError ( 'Cannot convert object of class %s to Python.' % omobj . __class__ . __name__ )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/qt/console/rich_ipython_widget.py#L181-L191<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _add_image ( self , image ) : document = self . _control . document ( ) name = str ( image . cacheKey ( ) ) document . addResource ( QtGui . QTextDocument . ImageResource , QtCore . QUrl ( name ) , image ) format = QtGui . QTextImageFormat ( ) format . setName ( name ) return format

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/vaexio/vaex/blob/a45b672f8287afca2ada8e36b74b604b9b28dd85/packages/vaex-core/vaex/dataframe.py#L3300-L3320<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def add_variable ( self , name , expression , overwrite = True , unique = True ) : if unique or overwrite or name not in self . variables : existing_names = self . get_column_names ( virtual = False ) + list ( self . variables . keys ( ) ) name = vaex . utils . find_valid_name ( name , used = [ ] if not unique else existing_names ) self . variables [ name ] = expression self . signal_variable_changed . emit ( self , name , "add" ) if unique : return name

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/URXtech/cmph-cffi/blob/85298572e51675cd0c7ef1052ed9989b0e57f0cc/cmph/__init__.py#L252-L273<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def lookup ( self , key ) : assert self . _mph key = convert_to_bytes ( key ) box = ffi . new ( 'char[]' , key ) try : result = _cmph . cmph_search ( self . _mph , box , len ( key ) ) return result finally : del box

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/qasm/qasmparser.py#L856-L861<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def p_reset ( self , program ) : program [ 0 ] = node . Reset ( [ program [ 2 ] ] ) self . verify_reg ( program [ 2 ] , 'qreg' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/sundarnagarajan/cffi_utils/blob/1d5ab2d2fcb962372228033106bc23f1d73d31fa/cffi_utils/py2to3.py#L201-L214<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def fromBytes ( x ) : if isinstance ( x , unicode ) : return x if isinstance ( x , bytearray ) : x = bytes ( x ) elif isinstance ( x , bytes ) : pass else : return x # unchanged (int etc) return decode ( x , DEF_ENCODING )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chaoss/grimoirelab-perceval/blob/41c908605e88b7ebc3a536c643fa0f212eaf9e0e/perceval/backends/core/stackexchange.py#L94-L112<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def fetch_items ( self , category , * * kwargs ) : from_date = kwargs [ 'from_date' ] logger . info ( "Looking for questions at site '%s', with tag '%s' and updated from '%s'" , self . site , self . tagged , str ( from_date ) ) whole_pages = self . client . get_questions ( from_date ) for whole_page in whole_pages : questions = self . parse_questions ( whole_page ) for question in questions : yield question

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Loudr/asana-hub/blob/af996ce890ed23d8ede5bf68dcd318e3438829cb/asana_hub/tool.py#L84-L95<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _list_select ( cls , lst , prompt , offset = 0 ) : inp = raw_input ( "select %s: " % prompt ) assert inp , "value required." try : return lst [ int ( inp ) + offset ] except ValueError : return inp except IndexError : assert False , "bad value."

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/zmq/kernelmanager.py#L323-L359<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def history ( self , raw = True , output = False , hist_access_type = 'range' , * * kwargs ) : content = dict ( raw = raw , output = output , hist_access_type = hist_access_type , * * kwargs ) msg = self . session . msg ( 'history_request' , content ) self . _queue_send ( msg ) return msg [ 'header' ] [ 'msg_id' ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/RRZE-HPC/kerncraft/blob/c60baf8043e4da8d8d66da7575021c2f4c6c78af/kerncraft/models/ecm.py#L339-L357<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def conv_cy ( self , cy_cl ) : if not isinstance ( cy_cl , PrefixedUnit ) : cy_cl = PrefixedUnit ( cy_cl , '' , 'cy/CL' ) clock = self . machine [ 'clock' ] element_size = self . kernel . datatypes_size [ self . kernel . datatype ] elements_per_cacheline = int ( self . machine [ 'cacheline size' ] ) // element_size it_s = clock / cy_cl * elements_per_cacheline it_s . unit = 'It/s' flops_per_it = sum ( self . kernel . _flops . values ( ) ) performance = it_s * flops_per_it performance . unit = 'FLOP/s' cy_it = cy_cl * elements_per_cacheline cy_it . unit = 'cy/It' return { 'It/s' : it_s , 'cy/CL' : cy_cl , 'cy/It' : cy_it , 'FLOP/s' : performance }

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/grid/metrics.py#L30-L45<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def F1 ( self , thresholds = None , train = False , valid = False , xval = False ) : return { model . model_id : model . F1 ( thresholds , train , valid , xval ) for model in self . models }

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Jasily/jasily-python/blob/1c821a120ebbbbc3c5761f5f1e8a73588059242a/jasily/data/fullvars.py#L32-L51<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def fullvars ( obj ) : try : return vars ( obj ) except TypeError : pass # __slots__ slotsnames = set ( ) for cls in type ( obj ) . __mro__ : __slots__ = getattr ( cls , '__slots__' , None ) if __slots__ : if isinstance ( __slots__ , str ) : slotsnames . add ( __slots__ ) else : slotsnames . update ( __slots__ ) return _SlotsProxy ( obj , slotsnames )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jazzband/django-ddp/blob/1e1954b06fe140346acea43582515991685e4e01/dddp/main.py#L194-L229<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def start ( self ) : self . logger . debug ( 'PostgresGreenlet start' ) self . _stop_event . clear ( ) self . print ( '=> Discovering DDP endpoints...' ) if self . verbosity > 1 : for api_path in sorted ( self . api . api_path_map ( ) ) : print ( '    %s' % api_path ) # start greenlets self . pgworker . start ( ) self . print ( '=> Started PostgresGreenlet.' ) for server in self . servers : thread = gevent . spawn ( server . serve_forever ) gevent . sleep ( ) # yield to thread in case it can't start self . threads . append ( thread ) if thread . dead : # thread died, stop everything and re-raise the exception. self . stop ( ) thread . get ( ) if isinstance ( server , geventwebsocket . WebSocketServer ) : self . print ( '=> App running at: %s://%s:%d/' % ( 'https' if server . ssl_enabled else 'http' , server . server_host , server . server_port , ) , ) elif isinstance ( server , gevent . backdoor . BackdoorServer ) : self . print ( '=> Debug service running at: telnet://%s:%d/' % ( server . server_host , server . server_port , ) , ) self . print ( '=> Started your app (%s).' % self . wsgi_name )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/quantum_info/operators/quaternion.py#L82-L101<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def to_zyz ( self ) : mat = self . to_matrix ( ) euler = np . zeros ( 3 , dtype = float ) if mat [ 2 , 2 ] < 1 : if mat [ 2 , 2 ] > - 1 : euler [ 0 ] = math . atan2 ( mat [ 1 , 2 ] , mat [ 0 , 2 ] ) euler [ 1 ] = math . acos ( mat [ 2 , 2 ] ) euler [ 2 ] = math . atan2 ( mat [ 2 , 1 ] , - mat [ 2 , 0 ] ) else : euler [ 0 ] = - math . atan2 ( mat [ 1 , 0 ] , mat [ 1 , 1 ] ) euler [ 1 ] = np . pi else : euler [ 0 ] = math . atan2 ( mat [ 1 , 0 ] , mat [ 1 , 1 ] ) return euler

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/trp07/messages/blob/7789ebc960335a59ea5d319fceed3dd349023648/messages/_config.py#L228-L233<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_auth_from_user ( msg_type ) : auth = [ ] for k , v in CONFIG [ msg_type ] [ "auth" ] . items ( ) : auth . append ( ( k , getpass ( v + ": " ) ) ) return OrderedDict ( auth )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/geopython/OWSLib/blob/96d47842401a129f1e86fa9f66dccef5a5a6872c/owslib/feature/schema.py#L55-L64<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _get_elements ( complex_type , root ) : found_elements = [ ] element = findall ( root , '{%s}complexType' % XS_NAMESPACE , attribute_name = 'name' , attribute_value = complex_type ) [ 0 ] found_elements = findall ( element , '{%s}element' % XS_NAMESPACE ) return found_elements

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/external/pexpect/_pexpect.py#L1786-L1819<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def search ( self , buffer , freshlen , searchwindowsize = None ) : absurd_match = len ( buffer ) first_match = absurd_match # 'freshlen' doesn't help here -- we cannot predict the # length of a match, and the re module provides no help. if searchwindowsize is None : searchstart = 0 else : searchstart = max ( 0 , len ( buffer ) - searchwindowsize ) for index , s in self . _searches : match = s . search ( buffer , searchstart ) if match is None : continue n = match . start ( ) if n < first_match : first_match = n the_match = match best_index = index if first_match == absurd_match : return - 1 self . start = first_match self . match = the_match self . end = self . match . end ( ) return best_index

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/visualization/interactive/iplot_paulivec.py#L25-L36<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def process_data ( rho ) : result = dict ( ) num = int ( np . log2 ( len ( rho ) ) ) labels = list ( map ( lambda x : x . to_label ( ) , pauli_group ( num ) ) ) values = list ( map ( lambda x : np . real ( np . trace ( np . dot ( x . to_matrix ( ) , rho ) ) ) , pauli_group ( num ) ) ) for position , label in enumerate ( labels ) : result [ label ] = values [ position ] return result

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Nic30/hwt/blob/8cbb399e326da3b22c233b98188a9d08dec057e6/hwt/hdl/operator.py#L110-L127<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def withRes ( opDef , operands , resT , outputs = [ ] ) : op = Operator ( opDef , operands ) out = RtlSignal ( getCtxFromOps ( operands ) , None , resT ) out . _const = arr_all ( op . operands , isConst ) out . drivers . append ( op ) out . origin = op op . result = out op . registerSignals ( outputs ) if out . _const : out . staticEval ( ) return out

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/html/notebook/notebookmanager.py#L251-L266<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def increment_filename ( self , basename ) : i = 0 while True : name = u'%s%i' % ( basename , i ) path = self . get_path_by_name ( name ) if not os . path . isfile ( path ) : break else : i = i + 1 return path , name

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/bjoernricks/python-quilt/blob/fae88237f601848cc34d073584d9dcb409f01777/quilt/push.py#L111-L129<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def apply_next_patch ( self , force = False , quiet = False ) : self . _check ( ) top = self . db . top_patch ( ) if not top : patch = self . series . first_patch ( ) else : patch = self . series . patch_after ( top ) if not patch : raise AllPatchesApplied ( self . series , top ) self . applying ( patch ) self . _apply_patch ( patch , force , quiet ) self . db . save ( ) self . applied ( self . db . top_patch ( ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Qiskit/qiskit-terra/blob/d4f58d903bc96341b816f7c35df936d6421267d1/qiskit/transpiler/passmanager.py#L237-L247<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def remove_flow_controller ( cls , name ) : if name not in cls . registered_controllers : raise KeyError ( "Flow controller not found: %s" % name ) del cls . registered_controllers [ name ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Clinical-Genomics/scout/blob/90a551e2e1653a319e654c2405c2866f93d0ebb9/scout/server/blueprints/variants/controllers.py#L722-L746<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def clinsig_human ( variant_obj ) : for clinsig_obj in variant_obj [ 'clnsig' ] : # The clinsig objects allways have a accession if isinstance ( clinsig_obj [ 'accession' ] , int ) : # New version link = "https://www.ncbi.nlm.nih.gov/clinvar/variation/{}" else : # Old version link = "https://www.ncbi.nlm.nih.gov/clinvar/{}" human_str = 'not provided' if clinsig_obj . get ( 'value' ) : try : # Old version int ( clinsig_obj [ 'value' ] ) human_str = CLINSIG_MAP . get ( clinsig_obj [ 'value' ] , 'not provided' ) except ValueError : # New version human_str = clinsig_obj [ 'value' ] clinsig_obj [ 'human' ] = human_str clinsig_obj [ 'link' ] = link . format ( clinsig_obj [ 'accession' ] ) yield clinsig_obj

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ncolony/ncolony/blob/6ac71bda1de6706fb34244ae4972e36db5f062d3/ncolony/beatcheck.py#L33-L42<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def check ( path , start , now ) : return [ child . basename ( ) for child in path . children ( ) if _isbad ( child , start , now ) ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/snowplow/snowplow-python-analytics-sdk/blob/0ddca91e3f6d8bed88627fa557790aa4868bdace/snowplow_analytics_sdk/json_shredder.py#L37-L56<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def extract_schema ( uri ) : match = re . match ( SCHEMA_URI_REGEX , uri ) if match : return { 'vendor' : match . group ( 1 ) , 'name' : match . group ( 2 ) , 'format' : match . group ( 3 ) , 'version' : match . group ( 4 ) } else : raise SnowplowEventTransformationException ( [ "Schema {} does not conform to regular expression {}" . format ( uri , SCHEMA_URI ) ] )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/zqfang/GSEApy/blob/673e9ec1391e3b14d3e8a4353117151fd2cb9345/gseapy/gsea.py#L384-L438<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def run ( self ) : assert self . permutation_type in [ "phenotype" , "gene_set" ] assert self . min_size <= self . max_size # Start Analysis self . _logger . info ( "Parsing data files for GSEA............................." ) # phenotype labels parsing phenoPos , phenoNeg , cls_vector = gsea_cls_parser ( self . classes ) # select correct expression genes and values. dat = self . load_data ( cls_vector ) # data frame must have length > 1 assert len ( dat ) > 1 # ranking metrics calculation. dat2 = ranking_metric ( df = dat , method = self . method , pos = phenoPos , neg = phenoNeg , classes = cls_vector , ascending = self . ascending ) self . ranking = dat2 # filtering out gene sets and build gene sets dictionary gmt = self . load_gmt ( gene_list = dat2 . index . values , gmt = self . gene_sets ) self . _logger . info ( "%04d gene_sets used for further statistical testing....." % len ( gmt ) ) self . _logger . info ( "Start to run GSEA...Might take a while.................." ) # cpu numbers self . _set_cores ( ) # compute ES, NES, pval, FDR, RES dataset = dat if self . permutation_type == 'phenotype' else dat2 gsea_results , hit_ind , rank_ES , subsets = gsea_compute_tensor ( data = dataset , gmt = gmt , n = self . permutation_num , weighted_score_type = self . weighted_score_type , permutation_type = self . permutation_type , method = self . method , pheno_pos = phenoPos , pheno_neg = phenoNeg , classes = cls_vector , ascending = self . ascending , processes = self . _processes , seed = self . seed ) self . _logger . info ( "Start to generate GSEApy reports and figures............" ) res_zip = zip ( subsets , list ( gsea_results ) , hit_ind , rank_ES ) self . _save_results ( zipdata = res_zip , outdir = self . outdir , module = self . module , gmt = gmt , rank_metric = dat2 , permutation_type = self . permutation_type ) # reorder datarame for heatmap self . _heatmat ( df = dat . loc [ dat2 . index ] , classes = cls_vector , pheno_pos = phenoPos , pheno_neg = phenoNeg ) # Plotting if not self . _noplot : self . _plotting ( rank_metric = dat2 , results = self . results , graph_num = self . graph_num , outdir = self . outdir , figsize = self . figsize , format = self . format , pheno_pos = phenoPos , pheno_neg = phenoNeg ) self . _logger . info ( "Congratulations. GSEApy ran successfully.................\n" ) if self . _outdir is None : self . _tmpdir . cleanup ( ) return

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mozilla-iot/webthing-python/blob/65d467c89ed79d0bbc42b8b3c8f9e5a320edd237/webthing/thing.py#L322-L346<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def perform_action ( self , action_name , input_ = None ) : if action_name not in self . available_actions : return None action_type = self . available_actions [ action_name ] if 'input' in action_type [ 'metadata' ] : try : validate ( input_ , action_type [ 'metadata' ] [ 'input' ] ) except ValidationError : return None action = action_type [ 'class' ] ( self , input_ = input_ ) action . set_href_prefix ( self . href_prefix ) self . action_notify ( action ) self . actions [ action_name ] . append ( action ) return action

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/OpenKMIP/PyKMIP/blob/b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e/kmip/core/primitives.py#L710-L738<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def read_value ( self , istream , kmip_version = enums . KMIPVersion . KMIP_1_0 ) : try : value = unpack ( '!Q' , istream . read ( self . LENGTH ) ) [ 0 ] except Exception : self . logger . error ( "Error reading boolean value from buffer" ) raise if value == 1 : self . value = True elif value == 0 : self . value = False else : raise ValueError ( "expected: 0 or 1, observed: {0}" . format ( value ) ) self . validate ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/zqfang/GSEApy/blob/673e9ec1391e3b14d3e8a4353117151fd2cb9345/gseapy/parser.py#L237-L295<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def query ( self , dataset = 'hsapiens_gene_ensembl' , attributes = [ ] , filters = { } , filename = None ) : if not attributes : attributes = [ 'ensembl_gene_id' , 'external_gene_name' , 'entrezgene' , 'go_id' ] # i=0 # while (self.host is None) and (i < 3): #     self.host = self.ghosts[i] #     i +=1  self . new_query ( ) # 'mmusculus_gene_ensembl' self . add_dataset_to_xml ( dataset ) for at in attributes : self . add_attribute_to_xml ( at ) # add filters if filters : for k , v in filters . items ( ) : if isinstance ( v , list ) : v = "," . join ( v ) self . add_filter_to_xml ( k , v ) xml_query = self . get_xml ( ) results = super ( Biomart , self ) . query ( xml_query ) df = pd . read_csv ( StringIO ( results ) , header = None , sep = "\t" , names = attributes , index_col = None ) # save file to cache path. if filename is None : mkdirs ( DEFAULT_CACHE_PATH ) filename = os . path . join ( DEFAULT_CACHE_PATH , "{}.background.genes.txt" . format ( dataset ) ) df . to_csv ( filename , sep = "\t" , index = False ) return df

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mental32/spotify.py/blob/bb296cac7c3dd289908906b7069bd80f43950515/spotify/http.py#L354-L377<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def categories ( self , limit = 20 , offset = 0 , country = None , locale = None ) : route = Route ( 'GET' , '/browse/categories' ) payload = { 'limit' : limit , 'offset' : offset } if country : payload [ 'country' ] = country if locale : payload [ 'locale' ] = locale return self . request ( route , params = payload )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SmokinCaterpillar/pypet/blob/97ad3e80d46dbdea02deeb98ea41f05a19565826/pypet/storageservice.py#L3480-L3514<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _ann_store_annotations ( self , item_with_annotations , node , overwrite = False ) : # If we overwrite delete all annotations first if overwrite is True or overwrite == 'v_annotations' : annotated = self . _all_get_from_attrs ( node , HDF5StorageService . ANNOTATED ) if annotated : current_attrs = node . _v_attrs for attr_name in current_attrs . _v_attrnames : if attr_name . startswith ( HDF5StorageService . ANNOTATION_PREFIX ) : delattr ( current_attrs , attr_name ) delattr ( current_attrs , HDF5StorageService . ANNOTATED ) self . _hdf5file . flush ( ) # Only store annotations if the item has some if not item_with_annotations . v_annotations . f_is_empty ( ) : anno_dict = item_with_annotations . v_annotations . _dict current_attrs = node . _v_attrs changed = False for field_name in anno_dict : val = anno_dict [ field_name ] field_name_with_prefix = HDF5StorageService . ANNOTATION_PREFIX + field_name if field_name_with_prefix not in current_attrs : # Only store *new* annotations, if they already exist on disk, skip storage setattr ( current_attrs , field_name_with_prefix , val ) changed = True if changed : setattr ( current_attrs , HDF5StorageService . ANNOTATED , True ) self . _hdf5file . flush ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Numergy/yoda/blob/109f0e9441130488b0155f05883ef6531cf46ee9/yoda/workspace.py#L49-L55<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def remove ( self , name ) : if not ( self . exists ( name ) ) : raise ValueError ( "Workspace `%s` doesn't exists." % name ) self . config [ "workspaces" ] . pop ( name , 0 ) self . config . write ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/lepture/flask-oauthlib/blob/9e6f152a5bb360e7496210da21561c3e6d41b0e1/flask_oauthlib/provider/oauth1.py#L828-L839<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def verify_realms ( self , token , realms , request ) : log . debug ( 'Verify realms %r' , realms ) tok = request . request_token or self . _grantgetter ( token = token ) if not tok : return False request . request_token = tok if not hasattr ( tok , 'realms' ) : # realms not enabled return True return set ( tok . realms ) == set ( realms )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/agile-geoscience/striplog/blob/8033b673a151f96c29802b43763e863519a3124c/striplog/canstrat.py#L154-L183<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def parse_canstrat ( text ) : result = { } for row in text . split ( '\n' ) : if not row : continue if len ( row ) < 8 : # Not a real record. continue # Read the metadata for this row/ row_header = _process_row ( row , columns_ ) or { 'card' : None } card = row_header [ 'card' ] # Now we know the card type for this row, we can process it. if card is not None : item = _process_row ( row , columns [ card ] ) this_list = result . get ( card , [ ] ) this_list . append ( item ) result [ card ] = this_list # Flatten if possible. for c , d in result . items ( ) : if len ( d ) == 1 : result [ c ] = d [ 0 ] return result

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ionelmc/python-tblib/blob/00be69aa97e1eb1c09282b1cdb72539c947d4515/src/tblib/__init__.py#L141-L160<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def to_dict ( self ) : if self . tb_next is None : tb_next = None else : tb_next = self . tb_next . to_dict ( ) code = { 'co_filename' : self . tb_frame . f_code . co_filename , 'co_name' : self . tb_frame . f_code . co_name , } frame = { 'f_globals' : self . tb_frame . f_globals , 'f_code' : code , } return { 'tb_frame' : frame , 'tb_lineno' : self . tb_lineno , 'tb_next' : tb_next , }

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/pmacosta/peng/blob/976935377adaa3de26fc5677aceb2cdfbd6f93a7/peng/touchstone.py#L289-L395<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def write_touchstone ( fname , options , data , noise = None , frac_length = 10 , exp_length = 2 ) : # pylint: disable=R0913 # Exceptions definitions exnports = pexdoc . exh . addex ( RuntimeError , "File *[fname]* does not have a valid extension" ) exnoise = pexdoc . exh . addex ( RuntimeError , "Noise data only supported in two-port files" ) expoints = pexdoc . exh . addex ( RuntimeError , "Malformed data" ) # Data validation _ , ext = os . path . splitext ( fname ) ext = ext . lower ( ) nports_regexp = re . compile ( r"\.s(\d+)p" ) match = nports_regexp . match ( ext ) exnports ( not match , edata = { "field" : "fname" , "value" : fname } ) nports = int ( match . groups ( ) [ 0 ] ) exnoise ( bool ( ( nports != 2 ) and noise ) ) nums_per_freq = nports ** 2 expoints ( data [ "points" ] * nums_per_freq != data [ "pars" ] . size ) # npoints = data [ "points" ] par_data = np . resize ( np . copy ( data [ "pars" ] ) , ( npoints , nports , nports ) ) if nports == 2 : par_data = np . transpose ( par_data , ( 0 , 2 , 1 ) ) units_dict = { "ghz" : "GHz" , "mhz" : "MHz" , "khz" : "KHz" , "hz" : "Hz" } options [ "units" ] = units_dict [ options [ "units" ] . lower ( ) ] fspace = 2 + frac_length + ( exp_length + 2 ) # Format data with open ( fname , "w" ) as fobj : fobj . write ( "# {units} {ptype} {pformat} R {z0}\n" . format ( units = options [ "units" ] , ptype = options [ "ptype" ] , pformat = options [ "pformat" ] , z0 = options [ "z0" ] , ) ) for row in _chunk_pars ( data [ "freq" ] , par_data , options [ "pformat" ] ) : row_data = [ to_scientific_string ( item , frac_length , exp_length , bool ( num != 0 ) ) if item is not None else fspace * " " for num , item in enumerate ( row ) ] fobj . write ( " " . join ( row_data ) + "\n" ) if ( nports == 2 ) and noise : fobj . write ( "! Noise data\n" ) for row in _chunk_noise ( noise ) : row_data = [ to_scientific_string ( item , frac_length , exp_length , bool ( num != 0 ) ) for num , item in enumerate ( row ) ] fobj . write ( " " . join ( row_data ) + "\n" )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/LLNL/scraper/blob/881a316e4c04dfa5a9cf491b7c7f9f997a7c56ea/scripts/get_traffic.py#L115-L132<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_traffic ( self ) : print 'Getting traffic.' #Uses the developer API. Note this could change. headers = { 'Accept' : 'application/vnd.github.spiderman-preview' , 'Authorization' : 'token ' + self . token } headers_release = { 'Authorization' : 'token ' + self . token } for repo in self . org_retrieved . iter_repos ( type = 'public' ) : url = ( 'https://api.github.com/repos/' + self . organization_name + '/' + repo . name ) self . get_referrers ( url = url , headers = headers , repo_name = repo . name ) self . get_paths ( url = url , headers = headers ) self . get_data ( url = url , headers = headers , dict_to_store = self . views , type = 'views' , repo_name = repo . name ) self . get_data ( url = url , headers = headers , dict_to_store = self . clones , type = 'clones' , repo_name = repo . name ) self . get_releases ( url = url , headers = headers_release , repo_name = repo . name )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/not-na/peng3d/blob/1151be665b26cc8a479f6307086ba919e4d32d85/peng3d/resource.py#L133-L166<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def loadTex ( self , name , category ) : try : img = pyglet . image . load ( self . resourceNameToPath ( name , ".png" ) ) except FileNotFoundError : img = self . getMissingTexture ( ) texreg = self . categoriesTexBin [ category ] . add ( img ) #texreg = texreg.get_transform(True,True) # Mirrors the image due to how pyglets coordinate system works # Strange behavior, sometimes needed and sometimes not self . categories [ category ] [ name ] = texreg target = texreg . target texid = texreg . id texcoords = texreg . tex_coords # Prevents texture bleeding with texture sizes that are powers of 2, else weird lines may appear at certain angles. glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_S , GL_REPEAT ) glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_WRAP_T , GL_REPEAT ) glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MAG_FILTER , GL_NEAREST ) glTexParameteri ( GL_TEXTURE_2D , GL_TEXTURE_MIN_FILTER , GL_NEAREST_MIPMAP_LINEAR ) glGenerateMipmap ( GL_TEXTURE_2D ) out = target , texid , texcoords self . categoriesTexCache [ category ] [ name ] = out self . peng . sendEvent ( "peng3d:rsrc.tex.load" , { "peng" : self . peng , "name" : name , "category" : category } ) return out

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/mdgoldberg/sportsref/blob/09f11ac856a23c96d666d1d510bb35d6f050b5c3/sportsref/nfl/boxscores.py#L127-L140<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def week ( self ) : doc = self . get_doc ( ) raw = doc ( 'div#div_other_scores h2 a' ) . attr [ 'href' ] match = re . match ( r'/years/{}/week_(\d+)\.htm' . format ( self . season ( ) ) , raw ) if match : return int ( match . group ( 1 ) ) else : return 21

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/openergy/oplus/blob/f095868d1990c1d126e906ada6acbab26348b3d3/oplus/epm/record.py#L85-L130<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _update_value_inert ( self , index , value ) : # get field descriptor field_descriptor = self . _table . _dev_descriptor . get_field_descriptor ( index ) # prepare value value = field_descriptor . deserialize ( value , index ) # unregister previous link if relevant if isinstance ( value , Link ) : # de-activate current link if any current_link = self . _data . get ( index ) if current_link is not None : current_link . unregister ( ) # unregister previous hook if relevant if isinstance ( value , RecordHook ) : current_record_hook = self . _data . get ( index ) if current_record_hook is not None : current_record_hook . unregister ( ) # unregister previous external file if relevant if isinstance ( value , ExternalFile ) : current_external_file = self . _data . get ( index ) if current_external_file is not None : current_external_file . _dev_unregister ( ) # if None remove and leave if value in ( None , NONE_RECORD_HOOK , NONE_LINK , NONE_EXTERNAL_FILE ) : # we don't check required, because this method is called by _update_inert which does the job self . _dev_set_none_without_unregistering ( index , check_not_required = False ) return # if relevant, store current pk to signal table old_hook = None if index == 0 and not self . _table . _dev_auto_pk : old_hook = self . _data . get ( 0 ) # we use get, because record may not have a pk yet if it is being created # set value self . _data [ index ] = value # signal pk update if relevant if old_hook is not None : self . _table . _dev_record_pk_was_updated ( old_hook . target_value )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/draios/python-sdc-client/blob/47f83415842048778939b90944f64386a3bcb205/sdcclient/_common.py#L521-L563<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_sysdig_capture ( self , hostname , capture_name , duration , capture_filter = '' , folder = '/' ) : res = self . get_connected_agents ( ) if not res [ 0 ] : return res capture_agent = None for agent in res [ 1 ] : if hostname == agent [ 'hostName' ] : capture_agent = agent break if capture_agent is None : return [ False , hostname + ' not found' ] data = { 'agent' : capture_agent , 'name' : capture_name , 'duration' : duration , 'folder' : folder , 'filters' : capture_filter , 'bucketName' : '' , 'source' : self . product } res = requests . post ( self . url + '/api/sysdig' , headers = self . hdrs , data = json . dumps ( data ) , verify = self . ssl_verify ) return self . _request_result ( res )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/dagster-io/dagster/blob/4119f8c773089de64831b1dfb9e168e353d401dc/python_modules/dagster/dagster/core/execution.py#L346-L371<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def user_code_context_manager ( user_fn , error_cls , msg ) : check . callable_param ( user_fn , 'user_fn' ) check . subclass_param ( error_cls , 'error_cls' , DagsterUserCodeExecutionError ) with user_code_error_boundary ( error_cls , msg ) : thing_or_gen = user_fn ( ) gen = _ensure_gen ( thing_or_gen ) try : thing = next ( gen ) except StopIteration : check . failed ( 'Must yield one item. You did not yield anything.' ) yield thing stopped = False try : next ( gen ) except StopIteration : stopped = True check . invariant ( stopped , 'Must yield one item. Yielded more than one item' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ndrlslz/ternya/blob/c05aec10029e645d63ff04313dbcf2644743481f/ternya/modules.py#L50-L58<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def import_modules ( self ) : modules = self . get_modules ( ) log . info ( "import service modules: " + str ( modules ) ) try : for module in modules : __import__ ( module ) except ImportError as error : raise ImportModulesError ( error . msg )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/katerina7479/pypdflite/blob/ac2501f30d6619eae9dea5644717575ca9263d0a/pypdflite/pdflite.py#L313-L326<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _text_to_string ( self , text ) : if text : for i , j in [ ( "\\" , "\\\\" ) , ( ")" , "\\)" ) , ( "(" , "\\(" ) ] : text = text . replace ( i , j ) text = "(%s)" % text else : text = 'None' return text

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/labstreaminglayer/liblsl-Python/blob/1ff6fe2794f8dba286b7491d1f7a4c915b8a0605/pylsl/pylsl.py#L1003-L1008<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def set_child_value ( self , name , value ) : return XMLElement ( lib . lsl_set_child_value ( self . e , str . encode ( name ) , str . encode ( value ) ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/agile-geoscience/striplog/blob/8033b673a151f96c29802b43763e863519a3124c/striplog/legend.py#L513-L550<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def from_image ( cls , filename , components , ignore = None , col_offset = 0.1 , row_offset = 2 ) : if ignore is None : ignore = [ ] rgb = utils . loglike_from_image ( filename , offset = col_offset ) loglike = np . array ( [ utils . rgb_to_hex ( t ) for t in rgb ] ) # Get the pixels and colour values at 'tops' (i.e. changes). _ , hexes = utils . tops_from_loglike ( loglike , offset = row_offset ) # Reduce to unique colours. hexes_reduced = [ ] for h in hexes : if h not in hexes_reduced : if h not in ignore : hexes_reduced . append ( h ) list_of_Decors = [ ] for i , c in enumerate ( components ) : d = Decor ( { 'colour' : hexes_reduced [ i ] , 'component' : c } ) list_of_Decors . append ( d ) return cls ( list_of_Decors )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PolicyStat/docx2html/blob/2dc4afd1e3a3f2f0b357d0bff903eb58bcc94429/docx2html/core.py#L599-L613<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def whole_line_styled ( p ) : r_tags = p . xpath ( './/w:r' , namespaces = p . nsmap ) tags_are_bold = [ is_bold ( r ) or is_underlined ( r ) for r in r_tags ] tags_are_italics = [ is_italics ( r ) for r in r_tags ] return all ( tags_are_bold ) , all ( tags_are_italics )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ndrlslz/ternya/blob/c05aec10029e645d63ff04313dbcf2644743481f/ternya/ternya.py#L225-L243<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def init_heat_consumer ( self , mq ) : if not self . enable_component_notification ( Openstack . Heat ) : log . debug ( "disable listening heat notification" ) return for i in range ( self . config . heat_mq_consumer_count ) : mq . create_consumer ( self . config . heat_mq_exchange , self . config . heat_mq_queue , ProcessFactory . process ( Openstack . Heat ) ) log . debug ( "enable listening openstack heat notification." )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/jaraco/jaraco.util/blob/f21071c64f165a5cf844db15e39356e1a47f4b02/jaraco/util/dice.py#L32-L42<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def do_dice_roll ( ) : options = get_options ( ) dice = Dice ( options . sides ) rolls = [ dice . roll ( ) for n in range ( options . number ) ] for roll in rolls : print ( 'rolled' , roll ) if options . number > 1 : print ( 'total' , sum ( rolls ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/OpenKMIP/PyKMIP/blob/b51c5b044bd05f8c85a1d65d13a583a4d8fc1b0e/kmip/pie/client.py#L1254-L1317<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def signature_verify ( self , message , signature , uid = None , cryptographic_parameters = None ) : # Check input if not isinstance ( message , six . binary_type ) : raise TypeError ( "Message must be bytes." ) if not isinstance ( signature , six . binary_type ) : raise TypeError ( "Signature must be bytes." ) if uid is not None : if not isinstance ( uid , six . string_types ) : raise TypeError ( "Unique identifier must be a string." ) if cryptographic_parameters is not None : if not isinstance ( cryptographic_parameters , dict ) : raise TypeError ( "Cryptographic parameters must be a dictionary." ) cryptographic_parameters = self . _build_cryptographic_parameters ( cryptographic_parameters ) # Decrypt the provided data and handle the results result = self . proxy . signature_verify ( message , signature , uid , cryptographic_parameters ) status = result . get ( 'result_status' ) if status == enums . ResultStatus . SUCCESS : return result . get ( 'validity_indicator' ) else : raise exceptions . KmipOperationFailure ( status , result . get ( 'result_reason' ) , result . get ( 'result_message' ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/IdentityPython/fedoidcmsg/blob/d30107be02521fa6cdfe285da3b6b0cdd153c8cc/src/fedoidcmsg/entity.py#L76-L89<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def pick_signed_metadata_statements_regex ( self , pattern , context ) : comp_pat = re . compile ( pattern ) sms_dict = self . signer . metadata_statements [ context ] res = [ ] for iss , vals in sms_dict . items ( ) : if comp_pat . search ( iss ) : res . extend ( ( iss , vals ) ) return res

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/respondcreate/django-versatileimagefield/blob/d41e279c39cccffafbe876c67596184704ae8877/versatileimagefield/widgets.py#L66-L106<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_context ( self , name , value , attrs ) : if self . has_template_widget_rendering : context = super ( ClearableFileInputWithImagePreview , self ) . get_context ( name , value , attrs ) else : # Build the context manually. context = { } context [ 'widget' ] = { 'name' : name , 'is_hidden' : self . is_hidden , 'required' : self . is_required , 'value' : self . _format_value ( value ) , 'attrs' : self . build_attrs ( self . attrs , attrs ) , 'template_name' : self . template_name , 'type' : self . input_type , } # It seems Django 1.11's ClearableFileInput doesn't add everything to the 'widget' key, so we can't use it # in MultiWidget. Add it manually here. checkbox_name = self . clear_checkbox_name ( name ) checkbox_id = self . clear_checkbox_id ( checkbox_name ) context [ 'widget' ] . update ( { 'checkbox_name' : checkbox_name , 'checkbox_id' : checkbox_id , 'is_initial' : self . is_initial ( value ) , 'input_text' : self . input_text , 'initial_text' : self . initial_text , 'clear_checkbox_label' : self . clear_checkbox_label , } ) if value and hasattr ( value , "url" ) : context [ 'widget' ] . update ( { 'hidden_field_id' : self . get_hidden_field_id ( name ) , 'point_stage_id' : self . get_point_stage_id ( name ) , 'ppoi_id' : self . get_ppoi_id ( name ) , 'sized_url' : self . get_sized_url ( value ) , 'image_preview_id' : self . image_preview_id ( name ) , } ) return context

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/wanmen.py#L18-L25<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _wanmen_get_title_by_json_topic_part ( json_content , tIndex , pIndex ) : return '_' . join ( [ json_content [ 0 ] [ 'name' ] , json_content [ 0 ] [ 'Topics' ] [ tIndex ] [ 'name' ] , json_content [ 0 ] [ 'Topics' ] [ tIndex ] [ 'Parts' ] [ pIndex ] [ 'name' ] ] )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/funilrys/PyFunceble/blob/cdf69cbde120199171f7158e1c33635753e6e2f5/PyFunceble/database.py#L270-L279<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _backup ( self ) : if PyFunceble . CONFIGURATION [ "inactive_database" ] : # The database subsystem is activated. # We save the current database state into the database file. Dict ( PyFunceble . INTERN [ "inactive_db" ] ) . to_json ( self . inactive_db_path )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/agabrown/PyGaia/blob/ae972b0622a15f713ffae471f925eac25ccdae47/pygaia/errors/photometric.py#L131-L153<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def rpMagnitudeErrorEoM ( G , vmini , nobs = 70 ) : return sqrt ( ( power ( rpMagnitudeError ( G , vmini ) / _scienceMargin , 2 ) + _eomCalibrationFloorRP * _eomCalibrationFloorRP ) / nobs ) * _scienceMargin

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/phfaist/pylatexenc/blob/0c1788d1349e749501e67a6fba54d79e6e0d54f6/pylatexenc/latexwalker.py#L922-L987<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_latex_environment ( self , pos , environmentname = None ) : startpos = pos firsttok = self . get_token ( pos ) if ( firsttok . tok != 'begin_environment' or ( environmentname is not None and firsttok . arg != environmentname ) ) : raise LatexWalkerParseError ( s = self . s , pos = pos , msg = r'get_latex_environment: expected \begin{%s}: %s' % ( environmentname if environmentname is not None else '<environment name>' , firsttok . arg ) ) if ( environmentname is None ) : environmentname = firsttok . arg pos = firsttok . pos + firsttok . len optargs = [ ] args = [ ] # see if the \begin{environment} is immediately followed by some # options.  Important: Don't eat the brace of a commutator!! Don't allow # any space between the environment and the open bracket. optargtuple = None if ( self . s [ pos ] == '[' ) : optargtuple = self . get_latex_maybe_optional_arg ( pos ) if ( optargtuple is not None ) : optargs . append ( optargtuple [ 0 ] ) pos = optargtuple [ 1 ] + optargtuple [ 2 ] else : # Try to see if we have a mandatory argument.  Don't use get_token # as we don't want to skip any space. if self . s [ pos ] == '{' : ( argnode , apos , alen ) = self . get_latex_braced_group ( pos ) args . append ( argnode ) pos = apos + alen ( nodelist , npos , nlen ) = self . get_latex_nodes ( pos , stop_upon_end_environment = environmentname ) return ( LatexEnvironmentNode ( envname = environmentname , nodelist = nodelist , optargs = optargs , args = args ) , startpos , npos + nlen - startpos )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/sts/structural_time_series.py#L111-L132<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _canonicalize_param_vals_as_map ( self , param_vals ) : if hasattr ( param_vals , 'keys' ) : param_map = param_vals else : param_map = { p . name : v for ( p , v ) in zip ( self . parameters , param_vals ) } return param_map

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/urinieto/msaf/blob/9dbb57d77a1310465a65cc40f1641d083ca74385/msaf/algorithms/foote/segmenter.py#L15-L19<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def median_filter ( X , M = 8 ) : for i in range ( X . shape [ 1 ] ) : X [ : , i ] = filters . median_filter ( X [ : , i ] , size = M ) return X

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/xtuml/pyxtuml/blob/7dd9343b9a0191d1db1887ab9288d0a026608d9a/bridgepoint/oal.py#L1742-L1755<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def p_boolean_expression ( self , p ) : p [ 0 ] = BinaryOperationNode ( left = p [ 1 ] , operator = p [ 2 ] , right = p [ 3 ] )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/funilrys/PyFunceble/blob/cdf69cbde120199171f7158e1c33635753e6e2f5/PyFunceble/url.py#L75-L125<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get ( cls ) : # pragma: no cover if Check ( ) . is_url_valid ( ) or PyFunceble . CONFIGURATION [ "local" ] : # * The url is valid. # or # * We are testing in/for a local or private network. if "current_test_data" in PyFunceble . INTERN : PyFunceble . INTERN [ "current_test_data" ] [ "url_syntax_validation" ] = True # We initiate the HTTP status code. PyFunceble . INTERN . update ( { "http_code" : HTTPCode ( ) . get ( ) } ) # We initiate the list of active status code. active_list = [ ] active_list . extend ( PyFunceble . HTTP_CODE [ "list" ] [ "potentially_up" ] ) active_list . extend ( PyFunceble . HTTP_CODE [ "list" ] [ "up" ] ) # We initiate the list of inactive status code. inactive_list = [ ] inactive_list . extend ( PyFunceble . HTTP_CODE [ "list" ] [ "potentially_down" ] ) inactive_list . append ( "*" * 3 ) if PyFunceble . INTERN [ "http_code" ] in active_list : # The extracted HTTP status code is in the list of active list. # We handle and return the up status. return URLStatus ( PyFunceble . STATUS [ "official" ] [ "up" ] ) . handle ( ) if PyFunceble . INTERN [ "http_code" ] in inactive_list : # The extracted HTTP status code is in the list of inactive list. # We handle and return the down status. return URLStatus ( PyFunceble . STATUS [ "official" ] [ "down" ] ) . handle ( ) # The extracted HTTP status code is not in the list of active nor invalid list. if "current_test_data" in PyFunceble . INTERN : # The end-user want more information whith his test. # We update the url_syntax_validation index. PyFunceble . INTERN [ "current_test_data" ] [ "url_syntax_validation" ] = False # We handle and return the invalid down status. return URLStatus ( PyFunceble . STATUS [ "official" ] [ "invalid" ] ) . handle ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/justanr/flask-allows/blob/39fa5c8692836a33646ea43b4081e7c2181ec7c4/src/flask_allows/allows.py#L41-L58<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def init_app ( self , app ) : if not hasattr ( app , "extensions" ) : # pragma: no cover app . extensions = { } app . extensions [ "allows" ] = self @ app . before_request def start_context ( * a , * * k ) : self . overrides . push ( Override ( ) ) self . additional . push ( Additional ( ) ) @ app . after_request def cleanup ( response ) : self . clear_all_overrides ( ) self . clear_all_additional ( ) return response

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/imports.py#L930-L939<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _filter_dependencies_graph ( self , internal ) : graph = collections . defaultdict ( set ) for importee , importers in self . stats [ "dependencies" ] . items ( ) : for importer in importers : package = self . _module_pkg . get ( importer , importer ) is_inside = importee . startswith ( package ) if is_inside and internal or not is_inside and not internal : graph [ importee ] . add ( importer ) return graph

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/dossier/dossier.store/blob/b22ffe2470bba9fcc98a30cb55b437bfa1521e7f/dossier/store/store.py#L298-L317<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def index_scan ( self , idx_name , val ) : idx = self . _index ( idx_name ) [ 'transform' ] key = ( idx ( val ) , idx_name . encode ( 'utf-8' ) ) keys = self . kvl . scan_keys ( self . INDEX_TABLE , ( key , key ) ) return imap ( lambda k : k [ 2 ] , keys )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/ui/django-thumbnails/blob/5cef55e7f167060458709ed760dd43981124796a/thumbnails/files.py#L69-L91<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get ( self , size , create = True ) : if self . _thumbnails is None : self . _refresh_cache ( ) thumbnail = self . _thumbnails . get ( size ) if thumbnail is None : thumbnail = images . get ( self . source_image . name , size , self . metadata_backend , self . storage ) if thumbnail is None : thumbnail = self . create ( size ) self . _thumbnails [ size ] = thumbnail return thumbnail

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/zmq/session.py#L588-L613<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def send_raw ( self , stream , msg_list , flags = 0 , copy = True , ident = None ) : to_send = [ ] if isinstance ( ident , bytes ) : ident = [ ident ] if ident is not None : to_send . extend ( ident ) to_send . append ( DELIM ) to_send . append ( self . sign ( msg_list ) ) to_send . extend ( msg_list ) stream . send_multipart ( msg_list , flags , copy = copy )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/yandex/yandex-tank/blob/d71d63b6ab5de8b8a5ea2b728b6ab9ac0b1ba71b/yandextank/core/tankcore.py#L465-L475<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def mkstemp ( self , suffix , prefix , directory = None ) : if not directory : directory = self . artifacts_dir fd , fname = tempfile . mkstemp ( suffix , prefix , directory ) os . close ( fd ) os . chmod ( fname , 0o644 ) # FIXME: chmod to parent dir's mode? return fname

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/SmokinCaterpillar/pypet/blob/97ad3e80d46dbdea02deeb98ea41f05a19565826/pypet/trajectory.py#L34-L72<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def load_trajectory ( name = None , index = None , as_new = False , load_parameters = pypetconstants . LOAD_DATA , load_derived_parameters = pypetconstants . LOAD_SKELETON , load_results = pypetconstants . LOAD_SKELETON , load_other_data = pypetconstants . LOAD_SKELETON , recursive = True , load_data = None , max_depth = None , force = False , dynamic_imports = None , new_name = 'my_trajectory' , add_time = True , wildcard_functions = None , with_run_information = True , storage_service = storage . HDF5StorageService , * * kwargs ) : if name is None and index is None : raise ValueError ( 'Please specify either a name or an index' ) elif name is not None and index is not None : raise ValueError ( 'Please specify either a name or an index' ) traj = Trajectory ( name = new_name , add_time = add_time , dynamic_imports = dynamic_imports , wildcard_functions = wildcard_functions ) traj . f_load ( name = name , index = index , as_new = as_new , load_parameters = load_parameters , load_derived_parameters = load_derived_parameters , load_results = load_results , load_other_data = load_other_data , recursive = recursive , load_data = load_data , max_depth = max_depth , force = force , with_run_information = with_run_information , storage_service = storage_service , * * kwargs ) return traj

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/PyCQA/pylint/blob/2bf5c61a3ff6ae90613b81679de42c0f19aea600/pylint/checkers/similar.py#L366-L374<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def process_module ( self , node ) : with node . stream ( ) as stream : self . append_stream ( self . linter . current_name , stream , node . file_encoding )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/JukeboxPipeline/jukedj/blob/d4159961c819c26792a278981ee68106ee15f3f3/src/jukedj/models.py#L490-L508<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_all_tasks ( element ) : prj = element . project if isinstance ( element , Asset ) : flag = True else : flag = False deps = prj . department_set . filter ( assetflag = flag ) for d in deps : t = Task ( project = prj , department = d , element = element ) t . full_clean ( ) t . save ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/kmmbvnr/django-any/blob/6f64ebd05476e2149e2e71deeefbb10f8edfc412/django_any/models.py#L213-L235<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def any_file_field ( field , * * kwargs ) : def get_some_file ( path ) : subdirs , files = field . storage . listdir ( path ) if files : result_file = random . choice ( files ) instance = field . storage . open ( "%s/%s" % ( path , result_file ) ) . file return FieldFile ( instance , field , result_file ) for subdir in subdirs : result = get_some_file ( "%s/%s" % ( path , subdir ) ) if result : return result result = get_some_file ( field . upload_to ) if result is None and not field . null : raise TypeError ( "Can't found file in %s for non nullable FileField" % field . upload_to ) return result

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/uw-it-aca/uw-restclients-canvas/blob/9845faf33d49a8f06908efc22640c001116d6ea2/uw_canvas/enrollments.py#L45-L50<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def get_enrollments_for_section_by_sis_id ( self , sis_section_id , params = { } ) : return self . get_enrollments_for_section ( self . _sis_id ( sis_section_id , sis_field = "section" ) , params )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/boto/s3transfer/blob/2aead638c8385d8ae0b1756b2de17e8fad45fffa/s3transfer/__init__.py#L225-L255<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def from_filename ( cls , filename , start_byte , chunk_size , callback = None , enable_callback = True ) : f = open ( filename , 'rb' ) file_size = os . fstat ( f . fileno ( ) ) . st_size return cls ( f , start_byte , chunk_size , file_size , callback , enable_callback )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/openergy/oplus/blob/f095868d1990c1d126e906ada6acbab26348b3d3/oplus/epm/field_descriptor.py#L176-L202<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def detailed_type ( self ) : if self . _detailed_type is None : if ( "reference" in self . tags ) or ( "reference-class-name" in self . tags ) : self . _detailed_type = "reference" elif "type" in self . tags : self . _detailed_type = self . tags [ "type" ] [ 0 ] . lower ( ) # idd is not very rigorous on case elif "key" in self . tags : self . _detailed_type = "choice" elif "object-list" in self . tags : self . _detailed_type = "object-list" elif "external-list" in self . tags : self . _detailed_type = "external-list" elif self . basic_type == "A" : self . _detailed_type = "alpha" elif self . basic_type == "N" : self . _detailed_type = "real" else : raise ValueError ( "Can't find detailed type." ) return self . _detailed_type

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/frontend/qt/console/ipython_widget.py#L257-L262<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _started_channels ( self ) : super ( IPythonWidget , self ) . _started_channels ( ) self . _load_guiref_magic ( ) self . kernel_manager . shell_channel . history ( hist_access_type = 'tail' , n = 1000 )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/funilrys/PyFunceble/blob/cdf69cbde120199171f7158e1c33635753e6e2f5/PyFunceble/core.py#L1225-L1286<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def switch ( cls , variable , custom = False ) : # pylint: disable=inconsistent-return-statements if not custom : # We are not working with custom variable which is not into # the configuration. # We get the current state. current_state = dict . get ( PyFunceble . CONFIGURATION , variable ) else : # We are working with a custom variable which is not into the # configuration current_state = variable if isinstance ( current_state , bool ) : # The current state is a boolean. if current_state : # The current state is equal to True. # We return False. return False # The current state is equal to False. # We return True. return True # The current state is not a boolean. # We set the message to raise. to_print = "Impossible to switch %s. Please post an issue to %s" # We raise an exception inviting the user to report an issue. raise Exception ( to_print % ( repr ( variable ) , PyFunceble . LINKS [ "repo" ] + "/issues." ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/5j9/wikitextparser/blob/1347425814361d7955342c53212edbb27f0ff4b5/wikitextparser/_wikitext.py#L496-L502<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def pprint ( self , indent : str = '    ' , remove_comments = False ) : warn ( 'pprint method is deprecated, use pformat instead.' , DeprecationWarning , ) return self . pformat ( indent , remove_comments )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/assemblerflow/flowcraft/blob/fc3f4bddded1efc76006600016dc71a06dd908c0/flowcraft/generator/engine.py#L1028-L1078<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _get_params_string ( self ) : params_str = "" for p in self . processes : logger . debug ( "[{}] Adding parameters: {}\n" . format ( p . template , p . params ) ) # Add an header with the template name to structure the params # configuration if p . params and p . template != "init" : p . set_param_id ( "_{}" . format ( p . pid ) ) params_str += "\n\t/*" params_str += "\n\tComponent '{}_{}'\n" . format ( p . template , p . pid ) params_str += "\t{}\n" . format ( "-" * ( len ( p . template ) + len ( p . pid ) + 12 ) ) params_str += "\t*/\n" for param , val in p . params . items ( ) : if p . template == "init" : param_id = param else : param_id = "{}_{}" . format ( param , p . pid ) params_str += "\t{} = {}\n" . format ( param_id , val [ "default" ] ) return params_str

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/IdentityPython/fedoidcmsg/blob/d30107be02521fa6cdfe285da3b6b0cdd153c8cc/src/fedoidcmsg/file_system.py#L99-L108<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def keys ( self ) : self . sync ( ) for k in self . db . keys ( ) : try : yield self . key_conv [ 'from' ] ( k ) except KeyError : yield k

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/hustlzp/Flask-Boost/blob/d0308408ebb248dd752b77123b845f8ec637fab2/flask_boost/cli.py#L316-L330<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _rewrite_and_copy ( src_file , dst_file , project_name ) : # Create temp file fh , abs_path = mkstemp ( ) with io . open ( abs_path , 'w' , encoding = 'utf-8' ) as new_file : with io . open ( src_file , 'r' , encoding = 'utf-8' ) as old_file : for line in old_file : new_line = line . replace ( '#{project}' , project_name ) . replace ( '#{project|title}' , project_name . title ( ) ) new_file . write ( new_line ) # Copy to new file shutil . copy ( abs_path , dst_file ) os . close ( fh )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/chrisrink10/basilisp/blob/3d82670ee218ec64eb066289c82766d14d18cc92/src/basilisp/lang/compiler/generator.py#L496-L532<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def statementize ( e : ast . AST ) -> ast . AST : # noinspection PyPep8 if isinstance ( e , ( ast . Assign , ast . AnnAssign , ast . AugAssign , ast . Expr , ast . Raise , ast . Assert , ast . Pass , ast . Import , ast . ImportFrom , ast . If , ast . For , ast . While , ast . Continue , ast . Break , ast . Try , ast . ExceptHandler , ast . With , ast . FunctionDef , ast . Return , ast . Yield , ast . YieldFrom , ast . Global , ast . ClassDef , ast . AsyncFunctionDef , ast . AsyncFor , ast . AsyncWith , ) , ) : return e return ast . Expr ( value = e )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/vaexio/vaex/blob/a45b672f8287afca2ada8e36b74b604b9b28dd85/packages/vaex-core/vaex/dataframe.py#L1855-L1877<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def col ( self ) : class ColumnList ( object ) : pass data = ColumnList ( ) for name in self . get_column_names ( ) : expression = getattr ( self , name , None ) if not isinstance ( expression , Expression ) : expression = Expression ( self , name ) setattr ( data , name , expression ) return data

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/librosa/librosa/blob/180e8e6eb8f958fa6b20b8cba389f7945d508247/librosa/feature/spectral.py#L626-L737<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def spectral_flatness ( y = None , S = None , n_fft = 2048 , hop_length = 512 , win_length = None , window = 'hann' , center = True , pad_mode = 'reflect' , amin = 1e-10 , power = 2.0 ) : if amin <= 0 : raise ParameterError ( 'amin must be strictly positive' ) S , n_fft = _spectrogram ( y = y , S = S , n_fft = n_fft , hop_length = hop_length , power = 1. , win_length = win_length , window = window , center = center , pad_mode = pad_mode ) if not np . isrealobj ( S ) : raise ParameterError ( 'Spectral flatness is only defined ' 'with real-valued input' ) elif np . any ( S < 0 ) : raise ParameterError ( 'Spectral flatness is only defined ' 'with non-negative energies' ) S_thresh = np . maximum ( amin , S ** power ) gmean = np . exp ( np . mean ( np . log ( S_thresh ) , axis = 0 , keepdims = True ) ) amean = np . mean ( S_thresh , axis = 0 , keepdims = True ) return gmean / amean

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/LordSputnik/mutagen/blob/38e62c8dc35c72b16554f5dbe7c0fde91acc3411/mutagen/aiff.py#L261-L301<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def save ( self , filename = None , v2_version = 4 , v23_sep = '/' ) : framedata = self . _prepare_framedata ( v2_version , v23_sep ) framesize = len ( framedata ) if filename is None : filename = self . filename # Unlike the parent ID3.save method, we won't save to a blank file # since we would have to construct a empty AIFF file fileobj = open ( filename , 'rb+' ) iff_file = IFFFile ( fileobj ) try : if u'ID3' not in iff_file : iff_file . insert_chunk ( u'ID3' ) chunk = iff_file [ u'ID3' ] fileobj . seek ( chunk . data_offset ) header = fileobj . read ( 10 ) header = self . _prepare_id3_header ( header , framesize , v2_version ) header , new_size , _ = header data = header + framedata + ( b'\x00' * ( new_size - framesize ) ) # Include ID3 header size in 'new_size' calculation new_size += 10 # Expand the chunk if necessary, including pad byte if new_size > chunk . size : insert_at = chunk . offset + chunk . size insert_size = new_size - chunk . size + new_size % 2 insert_bytes ( fileobj , insert_size , insert_at ) chunk . resize ( new_size ) fileobj . seek ( chunk . data_offset ) fileobj . write ( data ) finally : fileobj . close ( )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Chilipp/sphinx-nbexamples/blob/08e0319ff3c70f8a931dfa8890caf48add4d0470/sphinx_nbexamples/__init__.py#L460-L484<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def create_py ( self , nb , force = False ) : # Although we would love to simply use ``nbconvert.export_python(nb)`` # this causes troubles in other cells processed by the ipython # directive. Instead of getting something like ``Out [5]:``, we get # some weird like '[0;31mOut[[1;31m5[0;31m]: [0m' which look like # color information if we allow the call of nbconvert.export_python if list ( map ( int , re . findall ( '\d+' , nbconvert . __version__ ) ) ) >= [ 4 , 2 ] : py_file = os . path . basename ( self . py_file ) else : py_file = self . py_file try : level = logger . logger . level except AttributeError : level = logger . level spr . call ( [ 'jupyter' , 'nbconvert' , '--to=python' , '--output=' + py_file , '--log-level=%s' % level , self . outfile ] ) with open ( self . py_file ) as f : py_content = f . read ( ) # comment out ipython magics py_content = re . sub ( '^\s*get_ipython\(\).magic.*' , '# \g<0>' , py_content , flags = re . MULTILINE ) with open ( self . py_file , 'w' ) as f : f . write ( py_content )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/lensacom/sparkit-learn/blob/0498502107c1f7dcf33cda0cdb6f5ba4b42524b7/splearn/rdd.py#L50-L69<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _block_tuple ( iterator , dtypes , bsize = - 1 ) : i = 0 blocked_tuple = None for tuple_i in iterator : if blocked_tuple is None : blocked_tuple = tuple ( [ ] for _ in range ( len ( tuple_i ) ) ) if ( bsize > 0 ) and ( i >= bsize ) : yield tuple ( _pack_accumulated ( x , dtype ) for x , dtype in zip ( blocked_tuple , dtypes ) ) blocked_tuple = tuple ( [ ] for _ in range ( len ( tuple_i ) ) ) i = 0 for x_j , x in zip ( tuple_i , blocked_tuple ) : x . append ( x_j ) i += 1 if i > 0 : yield tuple ( _pack_accumulated ( x , dtype ) for x , dtype in zip ( blocked_tuple , dtypes ) )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/backend/connection.py#L503-L515<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def start_logging ( self , dest = None ) : assert_is_type ( dest , None , str , type ( sys . stdout ) ) if dest is None : dest = os . path . join ( tempfile . mkdtemp ( ) , "h2o-connection.log" ) self . _print ( "Now logging all API requests to file %r" % dest ) self . _is_logging = True self . _logging_dest = dest

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/pyca/pyopenssl/blob/1fbe064c50fd030948141d7d630673761525b0d0/src/OpenSSL/SSL.py#L1937-L1947<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def connect ( self , addr ) : _lib . SSL_set_connect_state ( self . _ssl ) return self . _socket . connect ( addr )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tmontaigu/pylas/blob/8335a1a7d7677f0e4bc391bb6fa3c75b42ed5b06/pylas/lasdatas/base.py#L60-L63<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def x ( self ) : return scale_dimension ( self . X , self . header . x_scale , self . header . x_offset )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/pyca/pyopenssl/blob/1fbe064c50fd030948141d7d630673761525b0d0/src/OpenSSL/SSL.py#L1851-L1873<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def bio_read ( self , bufsiz ) : if self . _from_ssl is None : raise TypeError ( "Connection sock was not None" ) if not isinstance ( bufsiz , integer_types ) : raise TypeError ( "bufsiz must be an integer" ) buf = _no_zero_allocator ( "char[]" , bufsiz ) result = _lib . BIO_read ( self . _from_ssl , buf , bufsiz ) if result <= 0 : self . _handle_bio_errors ( self . _from_ssl , result ) return _ffi . buffer ( buf , result ) [ : ]

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/yandex/yandex-tank/blob/d71d63b6ab5de8b8a5ea2b728b6ab9ac0b1ba71b/yandextank/plugins/Console/screen.py#L385-L441<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def render_screen ( self ) : self . term_width , self . term_height = get_terminal_size ( ) self . log . debug ( "Terminal size: %sx%s" , self . term_width , self . term_height ) self . right_panel_width = int ( ( self . term_width - len ( self . RIGHT_PANEL_SEPARATOR ) ) * ( float ( self . info_panel_percent ) / 100 ) ) - 1 if self . right_panel_width > 0 : self . left_panel_width = self . term_width - self . right_panel_width - len ( self . RIGHT_PANEL_SEPARATOR ) - 2 else : self . right_panel_width = 0 self . left_panel_width = self . term_width - 1 self . log . debug ( "Left/right panels width: %s/%s" , self . left_panel_width , self . right_panel_width ) widget_output = [ ] if self . right_panel_width : widget_output = [ ] self . log . debug ( "There are %d info widgets" % len ( self . info_widgets ) ) for index , widget in sorted ( self . info_widgets . iteritems ( ) , key = lambda item : ( item [ 1 ] . get_index ( ) , item [ 0 ] ) ) : self . log . debug ( "Rendering info widget #%s: %s" , index , widget ) widget_out = widget . render ( self ) . strip ( ) if widget_out : widget_output += widget_out . split ( "\n" ) widget_output += [ "" ] left_lines = self . __render_left_panel ( ) self . log . debug ( "Composing final screen output" ) output = [ ] for line_no in range ( 1 , self . term_height ) : line = " " if line_no > 1 and left_lines : left_line = left_lines . pop ( 0 ) left_line_plain = self . markup . clean_markup ( left_line ) left_line += ( ' ' * ( self . left_panel_width - len ( left_line_plain ) ) ) line += left_line else : line += ' ' * self . left_panel_width if self . right_panel_width : line += self . markup . RESET line += self . markup . WHITE line += self . RIGHT_PANEL_SEPARATOR line += self . markup . RESET right_line = self . __get_right_line ( widget_output ) line += right_line output . append ( line ) return self . markup . new_line . join ( output ) + self . markup . new_line

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/h2oai/h2o-3/blob/dd62aaa1e7f680a8b16ee14bc66b0fb5195c2ad8/h2o-py/h2o/frame.py#L1073-L1110<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def set_name ( self , col = None , name = None ) : assert_is_type ( col , None , int , str ) assert_is_type ( name , str ) ncols = self . ncols col_index = None if is_type ( col , int ) : if not ( - ncols <= col < ncols ) : raise H2OValueError ( "Index %d is out of bounds for a frame with %d columns" % ( col , ncols ) ) col_index = ( col + ncols ) % ncols # handle negative indices elif is_type ( col , str ) : if col not in self . names : raise H2OValueError ( "Column %s doesn't exist in the frame." % col ) col_index = self . names . index ( col ) # lookup the name else : assert col is None if ncols != 1 : raise H2OValueError ( "The frame has %d columns; please specify which one to rename" % ncols ) col_index = 0 if name != self . names [ col_index ] and name in self . types : raise H2OValueError ( "Column '%s' already exists in the frame" % name ) oldname = self . names [ col_index ] old_cache = self . _ex . _cache self . _ex = ExprNode ( "colnames=" , self , col_index , name ) # Update-in-place, but still lazy self . _ex . _cache . fill_from ( old_cache ) if self . names is None : self . _frame ( ) . _ex . _cache . fill ( ) else : self . _ex . _cache . _names = self . names [ : col_index ] + [ name ] + self . names [ col_index + 1 : ] self . _ex . _cache . _types [ name ] = self . _ex . _cache . _types . pop ( oldname ) return

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/neithere/argh/blob/dcd3253f2994400a6a58a700c118c53765bc50a4/argh/io.py#L99-L105<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def dump ( raw_data , output_file ) : data = encode_output ( raw_data , output_file ) output_file . write ( data )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/Azure/azure-sdk-for-python/blob/d7306fde32f60a293a7567678692bdad31e4b667/azure-servicebus/azure/servicebus/common/message.py#L360-L375<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def defer ( self ) : self . _is_live ( 'defer' ) try : self . message . modify ( True , True ) except Exception as e : raise MessageSettleFailed ( "defer" , e )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/xmartlabs/benderthon/blob/810b6fb90f56136257e7ed12e5a30d17ad7ce6ba/benderthon/tf_freeze.py#L85-L92<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def save_weights_from_checkpoint ( input_checkpoint , output_path , conv_var_names = None , conv_transpose_var_names = None ) : check_input_checkpoint ( input_checkpoint ) with tf . Session ( ) as sess : restore_from_checkpoint ( sess , input_checkpoint ) save_weights ( sess , output_path , conv_var_names = conv_var_names , conv_transpose_var_names = conv_transpose_var_names )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/gholt/swiftly/blob/5bcc1c65323b1caf1f85adbefd9fc4988c072149/swiftly/client/client.py#L58-L92<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def request ( self , method , path , contents , headers , decode_json = False , stream = False , query = None , cdn = False ) : raise Exception ( 'request method not implemented' )

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/nvdv/vprof/blob/4c3ff78f8920ab10cb9c00b14143452aa09ff6bb/vprof/memory_profiler.py#L21-L33<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def _remove_duplicates ( objects ) : seen , uniq = set ( ) , [ ] for obj in objects : obj_id = id ( obj ) if obj_id in seen : continue seen . add ( obj_id ) uniq . append ( obj ) return uniq

1<CODESPLIT>https://github.com/celiao/tmdbsimple/blob/ff17893110c99771d6398a62c35d36dd9735f4b9/tmdbsimple/base.py#L93-L106<CODESPLIT>https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/optimizer/differential_evolution.py#L120-L211<CODESPLIT>Set attributes to dictionary values .<CODESPLIT>def one_step ( objective_function , population , population_values = None , differential_weight = 0.5 , crossover_prob = 0.9 , seed = None , name = None ) : with tf . compat . v1 . name_scope ( name , 'one_step' , [ population , population_values , differential_weight , crossover_prob ] ) : population , _ = _ensure_list ( population ) if population_values is None : population_values = objective_function ( * population ) population_size = tf . shape ( input = population [ 0 ] ) [ 0 ] seed_stream = distributions . SeedStream ( seed , salt = 'one_step' ) mixing_indices = _get_mixing_indices ( population_size , seed = seed_stream ( ) ) # Construct the mutated solution vectors. There is one for each member of # the population. mutants = _get_mutants ( population , population_size , mixing_indices , differential_weight ) # Perform recombination between the parents and the mutants. candidates = _binary_crossover ( population , population_size , mutants , crossover_prob , seed = seed_stream ( ) ) candidate_values = objective_function ( * candidates ) if population_values is None : population_values = objective_function ( * population ) infinity = tf . zeros_like ( population_values ) + np . inf population_values = tf . where ( tf . math . is_nan ( population_values ) , x = infinity , y = population_values ) to_replace = candidate_values < population_values next_population = [ tf . where ( to_replace , x = candidates_part , y = population_part ) for candidates_part , population_part in zip ( candidates , population ) ] next_values = tf . where ( to_replace , x = candidate_values , y = population_values ) return next_population , next_values

